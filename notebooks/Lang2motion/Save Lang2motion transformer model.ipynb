{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Lang2motion transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor2(vocabulary: vocabulary, tokenizer: tokenizer, maxTextSequenceLength: maxTextSequenceLength, maxMotionLength: maxMotionLength)\n",
    "\n",
    "/// instantiate model\n",
    "let vocabSize = vocabulary.count\n",
    "let nbJoints = 47 // TODO: get value from dataset\n",
    "let nbMixtures = 20\n",
    "let layerCount: Int = 6\n",
    "let modelSize: Int = 256\n",
    "let feedForwardSize: Int = 1024\n",
    "let headCount: Int = 8\n",
    "let dropoutProbability: Double = 0.1\n",
    "\n",
    "var model = LangMotionTransformer(\n",
    "    vocabSize: vocabSize, \n",
    "    nbJoints: nbJoints,\n",
    "    nbMixtures: nbMixtures,\n",
    "    layerCount: layerCount, \n",
    "    modelSize: modelSize, \n",
    "    feedForwardSize: feedForwardSize, \n",
    "    headCount: headCount, \n",
    "    dropoutProbability: dropoutProbability\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play with writer and reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let temporaryDirectory = dataURL.appendingPathComponent(\"CheckpointsTests\", isDirectory: true)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "func setUp() {\n",
    "    // Remove pre-existing test files.\n",
    "    let headerPath = temporaryDirectory.appendingPathComponent(\n",
    "        \"testmodel.ckpt.index\"\n",
    "    ).path\n",
    "    if FileManager.default.fileExists(atPath: headerPath) {\n",
    "        try! FileManager.default.removeItem(atPath: headerPath)\n",
    "    }\n",
    "    let shardPath = temporaryDirectory.appendingPathComponent(\n",
    "        \"testmodel.ckpt.data-00000-of-00001\"\n",
    "    ).path\n",
    "    if FileManager.default.fileExists(atPath: shardPath) {\n",
    "        try! FileManager.default.removeItem(atPath: shardPath)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "setUp()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let vector = Tensor<Float>([1])\n",
    "let matrix = Tensor<Float>([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "let ones = Tensor<Float>(ones: [1, 2, 2, 2, 2, 2, 1])\n",
    "let tensor = Tensor<Float>(\n",
    "    shape: [3, 4, 5], scalars: [Float](stride(from: 0.0, to: 60.0, by: 1.0)))\n",
    "\n",
    "let tensors = [\n",
    "    \"model/vector\": vector, \"model/matrix\": matrix, \"ones\": ones, \"tensor\": tensor,\n",
    "]\n",
    "\n",
    "do {\n",
    "    let writer = CheckpointWriter(tensors: tensors)\n",
    "    try writer.write(to: temporaryDirectory, name: \"testmodel.ckpt\")\n",
    "} catch {\n",
    "    print(\"Checkpoint writing / reading failed with error: \\(error).\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save parts of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public protocol ExportableLayer {\n",
    "    var nameMappings: [String: String] { get }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension LangMotionTransformer: ExportableLayer {\n",
    "    public var nameMappings: [String: String] {        \n",
    "        [\n",
    "            \"encoder\": \"encoder\",\n",
    "            \"decoder\": \"decoder\",\n",
    "            \"embedding\": \"embedding\",\n",
    "            \"positionalEncoding\": \"positionalEncoding\",\n",
    "            \"motionDense\": \"motionDense\",\n",
    "            \"mixtureModel\": \"mixtureModel\",\n",
    "        ]\n",
    "        // modelSize: Int\n",
    "        // nbJoints: Int\n",
    "        // nbMixtures: Int\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Encoder: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"layers\": \"layers\",\n",
    "            \"norm\": \"norm\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Decoder: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"layers\": \"layers\",\n",
    "            \"norm\": \"norm\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Array: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { [\"h\": \"\\(type(of:self))\".components(separatedBy: [\"<\", \">\"])[1] + \"_h\" ] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MotionGaussianMixtureModel: ExportableLayer {\n",
    "    public var nameMappings: [String: String] {\n",
    "        [\n",
    "            \"linearMixtureMeans\": \"linearMixtureMeans\",\n",
    "            \"linearMixtureVars\": \"linearMixtureVars\",\n",
    "            \"linearMixtureWeights\": \"linearMixtureWeights\",\n",
    "            \"linearStop\": \"linearStop\",\n",
    "            // inputSize: Int\n",
    "            // nbJoints: Int\n",
    "            // nbMixtures: Int\n",
    "            // outputSize: Int\n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Embedding: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { [\"embeddings\": \"embeddings\"] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension LayerNorm: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { [\"offset\": \"offset\", \"scale\": \"scale\"] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Dense: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { [\"weight\": \"weight\", \"bias\": \"bias\"] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MultiHeadAttention: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            // sourceSize: Int\n",
    "            // targetSize: Int\n",
    "            // headCount: Int\n",
    "            // eadSize: Int\n",
    "            // queryActivation: Activation<Scalar>\n",
    "            // keyActivation: Activation<Scalar>\n",
    "            // valueActivation: Activation<Scalar>\n",
    "            // matrixResult: Bool\n",
    "\n",
    "            \"queryWeight\": \"queryWeight\",\n",
    "            \"queryBias\": \"queryBias\",\n",
    "            \"keyWeight\": \"keyWeight\",\n",
    "            \"keyBias\": \"keyBias\",\n",
    "            \"valueWeight\": \"valueWeight\",\n",
    "            \"valueBias\": \"valueBias\",\n",
    "            // attentionDropout: Dropout<Scalar>\n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension TransformerEncoderLayer2: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"selfAttention\": \"selfAttention\",\n",
    "            \"feedForward\": \"feedForward\",\n",
    "            \"sublayers\": \"sublayers\",\n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension PositionwiseFeedForward: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"dense1\": \"dense1\",\n",
    "            \"dense2\": \"dense2\",\n",
    "            \"dropout\": \"dropout\",\n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension SublayerConnection: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"norm\": \"norm\",\n",
    "            \"dropout\": \"dropout\",\n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension TransformerDecoderLayer: ExportableLayer {\n",
    "    public var nameMappings: [String: String] { \n",
    "        [\n",
    "            \"selfAttention\": \"selfAttention\",\n",
    "            \"sourceAttention\": \"sourceAttention\",\n",
    "            \"feedForward\": \"feedForward\",\n",
    "            \"sublayers\": \"sublayers\",            \n",
    "        ] \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func recursivelyObtainTensors(\n",
    "    _ obj: Any, scope: String? = nil, tensors: inout [String: Tensor<Float>], separator: String\n",
    ") {\n",
    "    \n",
    "    let m = Mirror(reflecting: obj)\n",
    "    let nameMappings: [String: String]\n",
    "    if let exportableLayer = obj as? ExportableLayer {\n",
    "        nameMappings = exportableLayer.nameMappings\n",
    "    } else {\n",
    "        if (obj is Int) || (obj is Bool) || (obj is Tensor<Float>) || \n",
    "           (obj is Double) || (obj is Float) || (obj is Dropout<Float>) ||\n",
    "           (obj is Parameter<Float>) || (obj is PositionalEncoding)\n",
    "        {}\n",
    "        else {\n",
    "            let s = \"\\(scope!) -> \\(type(of:obj))\"\n",
    "            if !s.contains(\"Tensor\") {\n",
    "                print(s)\n",
    "            }\n",
    "        }\n",
    "        nameMappings = [:]\n",
    "    }\n",
    "\n",
    "    var repeatedLabels: [String: Int] = [:]\n",
    "    func suffix(for label: String) -> String {\n",
    "        if let currentSuffix = repeatedLabels[label] {\n",
    "            repeatedLabels[label] = currentSuffix + 1\n",
    "            return \"\\(currentSuffix + 1)\"\n",
    "        } else {\n",
    "            repeatedLabels[label] = 0\n",
    "            return \"0\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    let hasSuffix = (m.children.first?.label == nil)\n",
    "\n",
    "    var path = scope\n",
    "    for child in m.children {\n",
    "        let label = child.label ?? \"h\"\n",
    "\n",
    "        if let remappedLabel = nameMappings[label] {\n",
    "            let labelSuffix = hasSuffix ? suffix(for: remappedLabel) : \"\"\n",
    "            let conditionalSeparator = remappedLabel == \"\" ? \"\" : separator\n",
    "\n",
    "            path = (scope != nil ? scope! + conditionalSeparator : \"\") + remappedLabel + labelSuffix\n",
    "            if let tensor = child.value as? Tensor<Float> {\n",
    "                tensors[path!] = tensor\n",
    "            }\n",
    "        }\n",
    "        recursivelyObtainTensors(child.value, scope: path, tensors: &tensors, separator: separator)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func writeCheckpoint(to location: URL, name: String) throws {\n",
    "    var tensors = [String: Tensor<Float>]()\n",
    "    recursivelyObtainTensors(model, scope: \"model\", tensors: &tensors, separator: \"/\")\n",
    "    \n",
    "    tensors.keys.sorted().map {print($0)}\n",
    "    \n",
    "    let writer = CheckpointWriter(tensors: tensors)\n",
    "    try writer.write(to: location, name: name)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeCheckpoint(to: temporaryDirectory, name: \"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct LangMotionTransformerConfig { //: Codable {\n",
    "    public let vocabSize: Int\n",
    "    public let nbJoints: Int\n",
    "    public let nbMixtures: Int\n",
    "    public let layerCount: Int\n",
    "    public let modelSize: Int\n",
    "    public let feedForwardSize: Int\n",
    "    public let headCount: Int\n",
    "    public let dropoutProbability: Double\n",
    "\n",
    "//     enum CodingKeys: String, CodingKey {\n",
    "//         case vocabSize = \"vocabSize\"\n",
    "//     }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol InitializableFromPythonCheckpoint {\n",
    "    init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Dense: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            weight: reader.readTensor(name: scope + \"/weight\"),\n",
    "            bias: reader.readTensor(name: scope + \"/bias\"),\n",
    "            activation: identity\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Embedding: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            embeddings: reader.readTensor(name: scope + \"/embeddings\")\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MotionGaussianMixtureModel: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            inputSize: config.modelSize,\n",
    "            nbJoints: config.nbJoints,\n",
    "            nbMixtures: config.nbMixtures,\n",
    "            linearMixtureMeans: Dense<Float>(reader: reader, config: config, scope: scope + \"/linearMixtureMeans\"),\n",
    "            linearMixtureVars: Dense<Float>(reader: reader, config: config, scope: scope + \"/linearMixtureVars\"),\n",
    "            linearMixtureWeights: Dense<Float>(reader: reader, config: config, scope: scope + \"/linearMixtureWeights\"),\n",
    "            linearStop: Dense<Float>(reader: reader, config: config, scope: scope + \"/linearStop\")\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension LayerNorm: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            offset: reader.readTensor(name: scope + \"/offset\"),\n",
    "            scale: reader.readTensor(name: scope + \"/scale\"),\n",
    "            axis: 2,\n",
    "            epsilon: 0.001)\n",
    "        // FIXME: axis & epsilon defaults\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MultiHeadAttention: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            sourceSize: config.modelSize,\n",
    "            targetSize: config.modelSize,\n",
    "            headCount: config.headCount,\n",
    "            headSize: config.modelSize/config.headCount,\n",
    "            queryActivation: identity,\n",
    "            keyActivation: identity,\n",
    "            valueActivation: identity,\n",
    "            attentionDropoutProbability: 0,\n",
    "            matrixResult: false,\n",
    "            queryWeight: reader.readTensor(name: scope + \"/queryWeight\"),\n",
    "            queryBias: reader.readTensor(name: scope + \"/queryBias\"),\n",
    "            keyWeight: reader.readTensor(name: scope + \"/keyWeight\"),\n",
    "            keyBias: reader.readTensor(name: scope + \"/keyBias\"),\n",
    "            valueWeight: reader.readTensor(name: scope + \"/valueWeight\"),\n",
    "            valueBias: reader.readTensor(name: scope + \"/valueBias\")\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension PositionwiseFeedForward: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        self.init(\n",
    "            dense1: Dense<Float>(reader: reader, config: config, scope: scope + \"/dense1\"),\n",
    "            dense2: Dense<Float>(reader: reader, config: config, scope: scope + \"/dense2\"),\n",
    "            dropout: Dropout<Float>(probability: config.dropoutProbability)\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension TransformerEncoderLayer2: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        let _selfAttention = MultiHeadAttention(\n",
    "            reader: reader, config: config, scope: scope + \"/selfAttention\")\n",
    "        let _feedForward = PositionwiseFeedForward(reader: reader, config: config, scope: scope + \"/feedForward\")\n",
    "        // TODO: serialize/deserialize sublayers [SublayerConnection]\n",
    "        self.init(\n",
    "            size: config.modelSize, \n",
    "            selfAttention: _selfAttention, \n",
    "            feedForward: _feedForward, \n",
    "            dropoutProb: config.dropoutProbability\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Encoder: InitializableFromPythonCheckpoint {\n",
    "    public init(reader: CheckpointReader, config: LangMotionTransformerConfig, scope: String) {\n",
    "        let _layers = (0..<config.layerCount).map { i in\n",
    "            TransformerEncoderLayer2(reader: reader, config: config, scope: scope + \"/layers/TransformerEncoderLayer2_h\\(i)\")\n",
    "        }\n",
    "        let _norm = LayerNorm<Float>(reader: reader, config: config, scope: scope + \"/norm\")\n",
    "        self.init(layers: _layers, norm: _norm)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension LangMotionTransformer {\n",
    "    public init(checkpoint: URL) throws {\n",
    "        // Try loading from the given checkpoint.\n",
    "        do {\n",
    "            // config\n",
    "            let _vocabSize: Int = 100\n",
    "            let _nbJoints: Int = 47\n",
    "            let _nbMixtures: Int = 20\n",
    "            let _layerCount: Int = 6 \n",
    "            let _modelSize: Int = 256\n",
    "            let _feedForwardSize: Int = 1024\n",
    "            let _headCount: Int = 8\n",
    "            let _dropoutProbability: Double = 0.1\n",
    "            let config = LangMotionTransformerConfig(\n",
    "                vocabSize: 100,\n",
    "                nbJoints: 47,\n",
    "                nbMixtures: 20,\n",
    "                layerCount: 6,\n",
    "                modelSize: 256,\n",
    "                feedForwardSize: 1024,\n",
    "                headCount: 8,\n",
    "                dropoutProbability: 0.1\n",
    "            )\n",
    "            \n",
    "            // create reader\n",
    "            let auxiliary: [String] = [\n",
    "                \"hparams.json\"\n",
    "            ]\n",
    "\n",
    "            let reader: CheckpointReader = try CheckpointReader(\n",
    "                checkpointLocation: checkpoint.appendingPathComponent(\"model1\"),\n",
    "                modelName: \"model1\",\n",
    "                additionalFiles: auxiliary)\n",
    "            let scope = \"model\"\n",
    "            \n",
    "            print(reader)\n",
    "            \n",
    "            // TODO: load config (values)\n",
    "            // TODO: * load weights\n",
    "            \n",
    "            // create objects            \n",
    "            let _encoder = Encoder(reader: reader, config: config, scope: scope + \"/encoder\")\n",
    "            \n",
    "            // TODO: serialize Decoder\n",
    "            // TODO: deserialize Decoder\n",
    "            let _attention = MultiHeadAttention(sourceSize: _modelSize,\n",
    "                                                targetSize: _modelSize,\n",
    "                                                headCount: _headCount,\n",
    "                                                headSize: _modelSize/_headCount,\n",
    "                                                matrixResult: false)\n",
    "            let _feedForward = PositionwiseFeedForward(dimensionalityModel: _modelSize,\n",
    "                                                       innerLayerDimensionality: _feedForwardSize, \n",
    "                                                       dropProbability: _dropoutProbability)\n",
    "            let _decoder = Decoder(\n",
    "                layer: .init(size: _modelSize, selfAttention: _attention, sourceAttention: _attention, feedForward: _feedForward, dropoutProb: _dropoutProbability), \n",
    "                layerCount: _layerCount)\n",
    "            \n",
    "            let _motionDense = Dense<Float>(reader: reader, config: config, scope: scope + \"/motionDense\")\n",
    "            \n",
    "            let _embedding = Embedding<Float>(reader: reader, config: config, scope: scope + \"/embedding\")\n",
    "            // TODO: serialize PositionalEncoding\n",
    "            // TODO: deserialize PositionalEncoding\n",
    "            let _positionalEncoding = PositionalEncoding(size: _modelSize, dropoutProbability: _dropoutProbability)\n",
    "            let _sourceEmbed = Sequential(_embedding, _positionalEncoding)\n",
    "\n",
    "            let _mixtureModel = MotionGaussianMixtureModel(reader: reader, config: config, scope: scope + \"/mixtureModel\")\n",
    "            \n",
    "            self.init(encoder: _encoder, decoder: _decoder, embedding: _embedding, positionalEncoding: _positionalEncoding, \n",
    "                      motionDense: _motionDense, sourceEmbed: _sourceEmbed, mixtureModel: _mixtureModel, \n",
    "                      modelSize: _modelSize, nbJoints: _nbJoints, nbMixtures: _nbMixtures)\n",
    "        } catch {\n",
    "            // If checkpoint is invalid, throw the error and exit.\n",
    "            print(\"Fail to load LangMotionTransformer from checkpoint. \\(error)\")\n",
    "            throw error\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let readModel = LangMotionTransformer(checkpoint: temporaryDirectory)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "readModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
