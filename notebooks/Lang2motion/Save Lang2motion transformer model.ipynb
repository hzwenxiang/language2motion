{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Lang2motion transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import LangMotionModels\n",
    "import Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor2(vocabulary: vocabulary, tokenizer: tokenizer, maxTextSequenceLength: maxTextSequenceLength, maxMotionLength: maxMotionLength)\n",
    "\n",
    "/// instantiate model\n",
    "let vocabSize = vocabulary.count\n",
    "let nbJoints = 47 // TODO: get value from dataset\n",
    "let nbMixtures = 20\n",
    "let layerCount: Int = 6\n",
    "let modelSize: Int = 256\n",
    "let feedForwardSize: Int = 1024\n",
    "let headCount: Int = 8\n",
    "let dropoutProbability: Double = 0.1\n",
    "\n",
    "var model = LangMotionTransformer(\n",
    "    vocabSize: vocabSize, \n",
    "    nbJoints: nbJoints,\n",
    "    nbMixtures: nbMixtures,\n",
    "    layerCount: layerCount, \n",
    "    modelSize: modelSize, \n",
    "    feedForwardSize: feedForwardSize, \n",
    "    headCount: headCount, \n",
    "    dropoutProbability: dropoutProbability\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play with writer and reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let temporaryDirectory = dataURL.appendingPathComponent(\"CheckpointsTests\", isDirectory: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func setUp() {\n",
    "    // Remove pre-existing test files.\n",
    "    let headerPath = temporaryDirectory.appendingPathComponent(\n",
    "        \"testmodel.ckpt.index\"\n",
    "    ).path\n",
    "    if FileManager.default.fileExists(atPath: headerPath) {\n",
    "        try! FileManager.default.removeItem(atPath: headerPath)\n",
    "    }\n",
    "    let shardPath = temporaryDirectory.appendingPathComponent(\n",
    "        \"testmodel.ckpt.data-00000-of-00001\"\n",
    "    ).path\n",
    "    if FileManager.default.fileExists(atPath: shardPath) {\n",
    "        try! FileManager.default.removeItem(atPath: shardPath)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let vector = Tensor<Float>([1])\n",
    "let matrix = Tensor<Float>([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "let ones = Tensor<Float>(ones: [1, 2, 2, 2, 2, 2, 1])\n",
    "let tensor = Tensor<Float>(\n",
    "    shape: [3, 4, 5], scalars: [Float](stride(from: 0.0, to: 60.0, by: 1.0)))\n",
    "\n",
    "let tensors = [\n",
    "    \"model/vector\": vector, \"model/matrix\": matrix, \"ones\": ones, \"tensor\": tensor,\n",
    "]\n",
    "\n",
    "do {\n",
    "    let writer = CheckpointWriter(tensors: tensors)\n",
    "    try writer.write(to: temporaryDirectory, name: \"testmodel.ckpt\")\n",
    "} catch {\n",
    "    print(\"Checkpoint writing / reading failed with error: \\(error).\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
