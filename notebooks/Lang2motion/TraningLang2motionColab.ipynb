{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TraningLang2motionColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJwHDGwK7aGN"
      },
      "source": [
        "# Train Transformer for the Lang2motion task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XucZWfhQ6rtA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b581ee6a-058f-44b4-c25b-249f3699a197"
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"master\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels TrainingLoop"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"master\"))\n",
            "\t\tDatasets\n",
            "\t\tTranslationModels\n",
            "\t\tTextModels\n",
            "\t\tModelSupport\n",
            "\t\tSummaryWriter\n",
            "\t\tLangMotionModels\n",
            "\t\tTrainingLoop\n",
            "With SwiftPM flags: ['-c', 'release']\n",
            "Working in: /tmp/tmp3vnnirgb/swift-install\n",
            "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvk1la6a7jqe",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import FoundationXML\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import LangMotionModels\n",
        "import TrainingLoop\n",
        "import PythonKit\n",
        "import x10_optimizers_optimizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJL886gQ56YT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1379434e-290d-47dd-c119-ecfec589790f"
      },
      "source": [
        "import PythonKit\n",
        "\n",
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('inline', 'module://ipykernel.pylab.backend_inline')\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5xCh7jaO7qpA"
      },
      "source": [
        "## What's the GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QF9_tK8p7rPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a67a48df-1c43-4e05-cf76-fd5f43bf6eb8"
      },
      "source": [
        "import Foundation\n",
        "\n",
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}\n",
        "\n",
        "sh(\"\"\"\n",
        "export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
        "export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
        "nvidia-smi\n",
        "\"\"\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep  2 18:47:44 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   74C    P0    33W /  70W |   4401MiB / 15079MiB |      0%      Default |\r\n",
            "|                               |                      |                 ERR! |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5EpGj5Y91PXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "6bb7c1a8-78a8-4ea9-edb3-f0f6ecf1fdc1"
      },
      "source": [
        "// sh(\"ps ax\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "error: <Cell 14>:1:1: error: cannot find 'sh' in scope\nsh(\"ps ax\")\n^~\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Syl5JUVQ1TEl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "633b83e0-ac29-4c97-f7be-4d1181b239a1"
      },
      "source": [
        "// sh(\"kill 2150\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cJ9Q3TOJMVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f9a9aa53-4a11-4a8e-84f5-ca46fd8fbef4"
      },
      "source": [
        "sh(\"ls -l /content/data/runs/Lang2motion/run_17/checkpoints\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 0\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9o7vGDqJfbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d1527c2-f755-4ba8-be98-411a52f24afc"
      },
      "source": [
        "sh(\"mv /content/data/runs/Lang2motion/run_17/checkpoints/* /content/data/runs\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzOE5kHy743R"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee6ivU1w75u2",
        "colab": {}
      },
      "source": [
        "let datasetSize: DatasetSize = .full\n",
        "let dataset_name = \"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pw5R28Eo79vM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "335ffe8f-a06f-464d-e684-9b90595f157f"
      },
      "source": [
        "// sh(\"mkdir -p /content/data/motion_images/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/\\(dataset_name)tgz\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "tar xzvf \\(dataset_name)tgz --skip-old-files\n",
        "\"\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: /content/data/: No such file or directory\n",
            "motion_dataset_v3.1 100%[===================>] 667.41M  35.1MB/s    in 20s     \n",
            "2020-09-02 17:14:21 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/48622c00-d288-11ea-8d95-40d568bbf42a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200902%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200902T171401Z&X-Amz-Expires=300&X-Amz-Signature=9e6cff1be5b297a2e2d6bcb4ea06e7e120a68df249d54302b49f667aee639bf0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.10Hz.tgz&response-content-type=application%2Foctet-stream [699830419/699830419] -> \"motion_dataset_v3.10Hz.tgz\" [1]\n",
            "2020-09-02 17:14:22 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200902%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200902T171421Z&X-Amz-Expires=300&X-Amz-Signature=772319ab510b98b96adefded402f2079ad834aafbb88716f85d21e67aaf074ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream [231508/231508] -> \"vocab.txt\" [1]\n",
            "motion_dataset_v3.10Hz.plist\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWSw_J1I1sFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2b498f27-1617-4164-f961-8a05571aab11"
      },
      "source": [
        "//https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/run_17.model.e35.tgz\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/run_17.model.e35.tgz\n",
        "tar xzvf run_17.model.e35.tgz --skip-old-files -C runs/Lang2motion/run_17/checkpoints\n",
        "\"\"\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run_17.model.e35.tg 100%[===================>]  99.54M  29.1MB/s    in 3.4s    \n",
            "2020-09-02 17:23:25 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/3c6afd80-ed51-11ea-813f-f121f19102d6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200902%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200902T172321Z&X-Amz-Expires=300&X-Amz-Signature=a211e5e345e8cbfef1437dc0665b06eb9b03ee24d8f8ba5fde6b502ce7a4788d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Drun_17.model.e35.tgz&response-content-type=application%2Foctet-stream [104374886/104374886] -> \"run_17.model.e35.tgz\" [1]\n",
            "tar: model.e35.data-00000-of-00001: skipping existing file\n",
            "tar: model.e35.index: skipping existing file\n",
            "model.e35.data-00000-of-00001\n",
            "model.e35.index\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "anldphJN8lL_"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lcru9CBe8nbs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3bdac0c8-cee9-440a-a18f-bb70eafbe90c"
      },
      "source": [
        "let runName = \"run_17\"\n",
        "// let batchSize = 4\n",
        "let batchSize = 50\n",
        "let maxTextSequenceLength =  20\n",
        "let maxMotionLength =  100\n",
        "let nEpochs = 10\n",
        "// let peakLearningRate: Float = 5e-4\n",
        "let peakLearningRate: Float = 2e-5\n",
        "\n",
        "let stepsPerEpoch = 127 // function of training set size and batching configuration\n",
        "\n",
        "let beta1: Float = 0.9\n",
        "let beta2: Float = 0.999\n",
        "let useBiasCorrection = false\n",
        "\n",
        "// let datasetSize: DatasetSize = .midi\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
        "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"peakLearningRate: \\(peakLearningRate)\")\n",
        "print(\"datasetSize: \\(datasetSize)\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runName: run_17\r\n",
            "batchSize: 50\r\n",
            "maxTextSequenceLength: 20\r\n",
            "maxMotionLength: 100\r\n",
            "nEpochs: 10\r\n",
            "peakLearningRate: 2e-05\r\n",
            "datasetSize: full\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PX11yzVyye4O",
        "colab": {}
      },
      "source": [
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
        "let checkpointURL = logdirURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
        "try! FileManager().createDirectory(at: checkpointURL, withIntermediateDirectories: true)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lts7GgHE8pS3"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Obl55068up1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d94bf03d-a92f-4d12-a866-91fac5584107"
      },
      "source": [
        "// let device = Device.defaultXLA\n",
        "let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device(kind: .CPU, ordinal: 0, backend: .TF_EAGER)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACBJHSaA8u7z"
      },
      "source": [
        "## X10 warm-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "luvidtBy8wXd",
        "colab": {}
      },
      "source": [
        "// let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "// let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "// let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "// print(eagerTensorSum)\n",
        "// print(eagerTensor1.device)\n",
        "// let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "// print(x10Tensor2.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y_XNP-hV8w0o"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Hrsx_O-9cyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "006911bc-92eb-45f2-b6a2-86e1e7489f35"
      },
      "source": [
        "/// instantiate text processor\n",
        "print(\"instantiate text processor\")\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)\n",
        "\n",
        "/// instantiate model\n",
        "print(\"instantiate model\")\n",
        "let config = LangMotionTransformerConfig(\n",
        "    vocabSize: vocabulary.count,\n",
        "    nbJoints: 47, // TODO: get value from dataset\n",
        "    nbMixtures: 20,\n",
        "    layerCount: 6,\n",
        "    modelSize: 256,\n",
        "    feedForwardSize: 1024,\n",
        "    headCount: 8,\n",
        "    dropoutProbability:  0.1,\n",
        "    sentenceMaxPositionalLength: 100,\n",
        "    motionMaxPositionalLength: 500\n",
        ")\n",
        "\n",
        "/// create new model\n",
        "// var model = LangMotionTransformer(config: config)\n",
        "\n",
        "/// load model checkpoint\n",
        "print(\"checkpointURL: \\(checkpointURL.path)\")\n",
        "let start_epoch = 35\n",
        "var model = try! LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(start_epoch)\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "instantiate text processor\n",
            "instantiate model\n",
            "checkpointURL: /content/data/runs/Lang2motion/run_17/checkpoints\n",
            "Loading model \"model.e35\" from \"/content/data/runs/Lang2motion/run_17/checkpoints\"...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1jZXyKzG-fVp"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-L0QTV0-fwa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3f816275-7ba1-4331-d31f-a63e0c657034"
      },
      "source": [
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Lang2Motion(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    batchSize: batchSize,\n",
        "    minMotionLength: 10,\n",
        "    maxMotionLength: 100,\n",
        "    trainTestSplit: 1.0,\n",
        "    demultiplyMotions: true,\n",
        "    device: device\n",
        ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
        "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
        "    let (target2, motionPart) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
        "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
        "    let singleBatch = LangMotionBatch(data: source,label: target2)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Loading dataset...\n",
            "MotionDataset(motionSamples: 39728)\n",
            "Keeping 30404 annotated motions.\n",
            "Keeping 30209 longer motions, with minimum 10 frames.\n",
            "Keeping 25560 shorter motions, with maximum 100 frames.\n",
            "Demultiplaying motions back to 3911.\n",
            "Scaling motions...\n",
            "Motions scaled.\n",
            "Having 6353 annotations with motions.\n",
            "Dataset acquired.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dI44Cnn9BAdl"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjIc0x5uBAyh",
        "colab": {}
      },
      "source": [
        "var optimizer = x10_optimizers_optimizer.GeneralOptimizer(\n",
        "    for: model,\n",
        "    TensorVisitorPlan(model.differentiableVectorView),\n",
        "    defaultOptimizer: makeWeightDecayedAdam(\n",
        "      learningRate: peakLearningRate,\n",
        "      beta1: beta1,\n",
        "      beta2: beta2\n",
        "    )\n",
        ")\n",
        "\n",
        "var scheduledLearningRate = LinearlyDecayedParameter(\n",
        "  baseParameter: LinearlyWarmedUpParameter(\n",
        "      baseParameter: FixedParameter<Float>(peakLearningRate),\n",
        "      warmUpStepCount: 20,\n",
        "      warmUpOffset: 0),\n",
        "  slope: -(peakLearningRate / Float(stepsPerEpoch * nEpochs)),  // The LR decays linearly to zero.\n",
        "  startStep: 10\n",
        ")\n",
        "\n",
        "public func learningRateUpdater<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "    if event == .updateStart {\n",
        "        let optimizer: GeneralOptimizer<LangMotionTransformer> = loop.optimizer as! GeneralOptimizer<LangMotionTransformer>\n",
        "        let step = optimizer.step + 1 // for scheduled rates and bias correction, steps start at 1\n",
        "        optimizer.learningRate = scheduledLearningRate(forStep: UInt64(step))\n",
        "        if useBiasCorrection {\n",
        "          let f_step = Float(step)\n",
        "          optimizer.learningRate *= sqrtf(1 - powf(beta2, f_step)) / (1 - powf(beta1, f_step))\n",
        "        }\n",
        "        // print(\"\\noptimizer: step: \\(optimizer.step), learningRate: \\(optimizer.learningRate)\")\n",
        "    }\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zmE1sfvpAqrQ"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hlq5bSE0Arg3",
        "colab": {}
      },
      "source": [
        "// Loss function\n",
        "let args = LossArgs(\n",
        "        nb_joints: config.nbJoints,\n",
        "        nb_mixtures: config.nbMixtures,\n",
        "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
        "        mixture_regularizer: 0.0,\n",
        "        device: device\n",
        ")\n",
        "\n",
        "@differentiable\n",
        "func embeddedNormalMixtureSurrogateLoss(y_pred: MixtureModelPreds, y_target: LangMotionBatch.Target) -> Tensor<Float> {\n",
        "    // TODO: create tensor on device\n",
        "    let y_true = TargetTruth(copying: TargetTruth(motion: y_target.targetTruth, stops: y_target.targetTruthStop), to: device)\n",
        "    let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
        "    let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
        "    let avg_loss = loss.sum() / n_items\n",
        "    return avg_loss\n",
        "}\n",
        "\n",
        "public func saveCheckpoint<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "    if event == .epochEnd {\n",
        "        guard let epochIndex = loop.epochIndex else {\n",
        "            return\n",
        "        }\n",
        "        let transformer: LangMotionTransformer = loop.model as! LangMotionTransformer\n",
        "        try! transformer.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1)\")\n",
        "    }\n",
        "}\n",
        "\n",
        "public class StatsRecorder {\n",
        "    let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)\n",
        "    public var trainingStepCount = 0\n",
        "    public var trainingBatchCount = 0\n",
        "    public var trainingLossSum: Float = 0.0\n",
        "    public var epochIndex = 0 // FIXME: Workaround\n",
        "\n",
        "    public func writeStats<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "        if event == .batchEnd {\n",
        "            guard \n",
        "            // let batchIndex = loop.batchIndex, \n",
        "            let trainingLoss = loop.lastLoss else {\n",
        "                return\n",
        "            }\n",
        "            // print(\"\\nbatch stats: batchIndex: \\(batchIndex), trainingStepCount: \\(trainingStepCount), trainingLoss: \\(trainingLoss)\")\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value:trainingLoss.scalar!)\n",
        "            trainingStepCount += 1\n",
        "            trainingBatchCount += 1\n",
        "            trainingLossSum += Float(trainingLoss.scalar!)\n",
        "        }\n",
        "        if event == .epochStart {\n",
        "            trainingBatchCount = 0\n",
        "            trainingLossSum = 0.0\n",
        "        }\n",
        "        if event == .epochEnd {\n",
        "            // guard let epochIndex = loop.epochIndex else {\n",
        "            //     return\n",
        "            // }\n",
        "            let current_epoch = epochIndex + 1\n",
        "            let epochTrainingLoss = trainingLossSum / Float(trainingBatchCount)\n",
        "            // print(\"\\nepoch stats: current_epoch: \\(current_epoch), epochTrainingLoss: \\(epochTrainingLoss)\")\n",
        "            summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: current_epoch, value: epochTrainingLoss)\n",
        "        }\n",
        "        if event == .fitEnd {\n",
        "            summaryWriter.flush()\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBELE-EpBJVd"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNX6TvywBN9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "7a467e28-5116-4da1-aca1-ca8cab952c21"
      },
      "source": [
        "let statsRecorder = StatsRecorder()\n",
        "\n",
        "// Training loop\n",
        "print(\"\\nSetting up the training loop\")\n",
        "let trainingProgress = TrainingProgress(metrics: [.loss])\n",
        "var trainingLoop = TrainingLoop(\n",
        "  training: dataset.trainEpochs,\n",
        "  validation: dataset.testBatches,\n",
        "  optimizer: optimizer,\n",
        "  lossFunction: embeddedNormalMixtureSurrogateLoss,\n",
        "  callbacks: [trainingProgress.update, statsRecorder.writeStats, learningRateUpdater])\n",
        "\n",
        "print(\"\\nTraining Transformer for the Lang2motion task!\")\n",
        "// FIXME: epoch loop workaround for checkpoint saving\n",
        "for epochIndex in start_epoch..<start_epoch+nEpochs {\n",
        "    print(\"epoch \\(epochIndex+1)/\\(start_epoch + nEpochs)\")\n",
        "    statsRecorder.epochIndex = epochIndex\n",
        "    try! trainingLoop.fit(&model, epochs: 1, on: device)\n",
        "    try! model.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1)\")\n",
        "}\n",
        "\n",
        "try! model.writeCheckpoint(to: checkpointURL, name: \"model.final\")\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Setting up the training loop\r\n",
            "\r\n",
            "Training Transformer for the Lang2motion task!\r\n",
            "epoch 36/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -41.4040\n",
            "\n",
            "epoch 37/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -42.3482\n",
            "\n",
            "epoch 38/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -42.6262\n",
            "\n",
            "epoch 39/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -42.8256\n",
            "\n",
            "epoch 40/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -42.9875\n",
            "\n",
            "epoch 41/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -43.0831\n",
            "\n",
            "epoch 42/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -43.1785\n",
            "\n",
            "epoch 43/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -43.2661\n",
            "\n",
            "epoch 44/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -43.3429\n",
            "\n",
            "epoch 45/45\n",
            "Epoch 1/1\n",
            "127/127 [==============================] - loss: -43.3588\n",
            "\n",
            "\n",
            "Finished training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AsQKu2Bpuyfa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}