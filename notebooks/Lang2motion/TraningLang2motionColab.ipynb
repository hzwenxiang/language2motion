{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TraningLang2motionColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QJwHDGwK7aGN"
      },
      "source": [
        "# Train Transformer for the Lang2motion task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XucZWfhQ6rtA",
        "colab": {}
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"master\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels TrainingLoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvk1la6a7jqe",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import FoundationXML\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import LangMotionModels\n",
        "import TrainingLoop\n",
        "import PythonKit\n",
        "import x10_optimizers_optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vJL886gQ56YT",
        "colab": {}
      },
      "source": [
        "import PythonKit\n",
        "\n",
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5xCh7jaO7qpA"
      },
      "source": [
        "## What's the GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QF9_tK8p7rPS",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "\n",
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}\n",
        "\n",
        "sh(\"\"\"\n",
        "export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
        "export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
        "nvidia-smi\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5EpGj5Y91PXV",
        "colab": {}
      },
      "source": [
        "// sh(\"ps ax\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Syl5JUVQ1TEl",
        "colab": {}
      },
      "source": [
        "// sh(\"kill 2150\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cJ9Q3TOJMVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sh(\"ls -l /content/data/runs/Lang2motion/run_17/checkpoints\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9o7vGDqJfbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sh(\"mv /content/data/runs/Lang2motion/run_17/checkpoints/* /content/data/runs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PzOE5kHy743R"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee6ivU1w75u2",
        "colab": {}
      },
      "source": [
        "let datasetSize: DatasetSize = .full\n",
        "let dataset_name = \"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pw5R28Eo79vM",
        "colab": {}
      },
      "source": [
        "// sh(\"mkdir -p /content/data/motion_images/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/\\(dataset_name)tgz\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "tar xzvf \\(dataset_name)tgz --skip-old-files\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWSw_J1I1sFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/run_17.model.e35.tgz\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/run_17.model.e35.tgz\n",
        "tar xzvf run_17.model.e35.tgz --skip-old-files -C runs/Lang2motion/run_18/checkpoints\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "anldphJN8lL_"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lcru9CBe8nbs",
        "colab": {}
      },
      "source": [
        "let runName = \"run_18\"\n",
        "// let batchSize = 4\n",
        "let batchSize = 50\n",
        "let maxTextSequenceLength =  20\n",
        "let maxMotionLength =  100\n",
        "let nEpochs = 10\n",
        "// let peakLearningRate: Float = 5e-4\n",
        "let peakLearningRate: Float = 2e-5\n",
        "\n",
        "let stepsPerEpoch = 127 // function of training set size and batching configuration\n",
        "\n",
        "let beta1: Float = 1.0 //0.9\n",
        "let beta2: Float = 1.0 //0.999\n",
        "let useBiasCorrection = false\n",
        "\n",
        "// let datasetSize: DatasetSize = .midi\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
        "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"peakLearningRate: \\(peakLearningRate)\")\n",
        "print(\"datasetSize: \\(datasetSize)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PX11yzVyye4O",
        "colab": {}
      },
      "source": [
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"runs/Lang2motion/\\(runName)\", isDirectory: true)\n",
        "let checkpointURL = logdirURL.appendingPathComponent(\"checkpoints\", isDirectory: true)\n",
        "try! FileManager().createDirectory(at: checkpointURL, withIntermediateDirectories: true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lts7GgHE8pS3"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Obl55068up1",
        "colab": {}
      },
      "source": [
        "// let device = Device.defaultXLA\n",
        "let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ACBJHSaA8u7z"
      },
      "source": [
        "## X10 warm-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "luvidtBy8wXd",
        "colab": {}
      },
      "source": [
        "// let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "// let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "// let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "// print(eagerTensorSum)\n",
        "// print(eagerTensor1.device)\n",
        "// let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "// print(x10Tensor2.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y_XNP-hV8w0o"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Hrsx_O-9cyb",
        "colab": {}
      },
      "source": [
        "/// instantiate text processor\n",
        "print(\"instantiate text processor\")\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer)\n",
        "\n",
        "/// instantiate model\n",
        "print(\"instantiate model\")\n",
        "let config = LangMotionTransformerConfig(\n",
        "    vocabSize: vocabulary.count,\n",
        "    nbJoints: 47, // TODO: get value from dataset\n",
        "    nbMixtures: 20,\n",
        "    layerCount: 6,\n",
        "    modelSize: 256,\n",
        "    feedForwardSize: 1024,\n",
        "    headCount: 8,\n",
        "    dropoutProbability:  0.1,\n",
        "    sentenceMaxPositionalLength: 100,\n",
        "    motionMaxPositionalLength: 500\n",
        ")\n",
        "\n",
        "/// create new model\n",
        "// var model = LangMotionTransformer(config: config)\n",
        "\n",
        "/// load model checkpoint\n",
        "print(\"checkpointURL: \\(checkpointURL.path)\")\n",
        "let start_epoch = 35\n",
        "var model = try! LangMotionTransformer(checkpoint: checkpointURL, config: config, name: \"model.e\\(start_epoch)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1jZXyKzG-fVp"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-L0QTV0-fwa",
        "colab": {}
      },
      "source": [
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Lang2Motion(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    batchSize: batchSize,\n",
        "    minMotionLength: 10,\n",
        "    maxMotionLength: 100,\n",
        "    trainTestSplit: 1.0,\n",
        "    demultiplyMotions: true,\n",
        "    device: device\n",
        ") { (motionSample: MotionSample) -> LangMotionBatch in    \n",
        "    let sentence = textProcessor.preprocess(sentence: motionSample.annotations[0], maxTextSequenceLength: maxTextSequenceLength)\n",
        "    let (target2, motionPart) = LangMotionBatch.preprocessTargetMotion(sampleID: motionSample.sampleID, motion: motionSample.motion, maxMotionLength: maxMotionLength)\n",
        "    let source = LangMotionBatch.Source(sentence: sentence, motionPart: motionPart)\n",
        "    let singleBatch = LangMotionBatch(data: source,label: target2)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dI44Cnn9BAdl"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zjIc0x5uBAyh",
        "colab": {}
      },
      "source": [
        "var optimizer = x10_optimizers_optimizer.GeneralOptimizer(\n",
        "    for: model,\n",
        "    TensorVisitorPlan(model.differentiableVectorView),\n",
        "    defaultOptimizer: makeWeightDecayedAdam(\n",
        "      learningRate: peakLearningRate,\n",
        "      beta1: beta1,\n",
        "      beta2: beta2\n",
        "    )\n",
        ")\n",
        "\n",
        "var scheduledLearningRate = LinearlyDecayedParameter(\n",
        "  baseParameter: LinearlyWarmedUpParameter(\n",
        "      baseParameter: FixedParameter<Float>(peakLearningRate),\n",
        "      warmUpStepCount: 20,\n",
        "      warmUpOffset: 0),\n",
        "  slope: -(peakLearningRate / Float(stepsPerEpoch * nEpochs)),  // The LR decays linearly to zero.\n",
        "  startStep: 10\n",
        ")\n",
        "\n",
        "public func learningRateUpdater<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "    if event == .updateStart {\n",
        "        let optimizer: GeneralOptimizer<LangMotionTransformer> = loop.optimizer as! GeneralOptimizer<LangMotionTransformer>\n",
        "        let step = optimizer.step + 1 // for scheduled rates and bias correction, steps start at 1\n",
        "        optimizer.learningRate = scheduledLearningRate(forStep: UInt64(step))\n",
        "        if useBiasCorrection {\n",
        "          let f_step = Float(step)\n",
        "          optimizer.learningRate *= sqrtf(1 - powf(beta2, f_step)) / (1 - powf(beta1, f_step))\n",
        "        }\n",
        "        // print(\"\\noptimizer: step: \\(optimizer.step), learningRate: \\(optimizer.learningRate)\")\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zmE1sfvpAqrQ"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hlq5bSE0Arg3",
        "colab": {}
      },
      "source": [
        "// Loss function\n",
        "let args = LossArgs(\n",
        "        nb_joints: config.nbJoints,\n",
        "        nb_mixtures: config.nbMixtures,\n",
        "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
        "        mixture_regularizer: 0.0,\n",
        "        device: device\n",
        ")\n",
        "\n",
        "@differentiable\n",
        "func embeddedNormalMixtureSurrogateLoss(y_pred: MixtureModelPreds, y_target: LangMotionBatch.Target) -> Tensor<Float> {\n",
        "    // TODO: create tensor on device\n",
        "    let y_true = TargetTruth(copying: TargetTruth(motion: y_target.targetTruth, stops: y_target.targetTruthStop), to: device)\n",
        "    let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
        "    let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
        "    let avg_loss = loss.sum() / n_items\n",
        "    return avg_loss\n",
        "}\n",
        "\n",
        "public func saveCheckpoint<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "    if event == .epochEnd {\n",
        "        guard let epochIndex = loop.epochIndex else {\n",
        "            return\n",
        "        }\n",
        "        let transformer: LangMotionTransformer = loop.model as! LangMotionTransformer\n",
        "        try! transformer.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1)\")\n",
        "    }\n",
        "}\n",
        "\n",
        "public class StatsRecorder {\n",
        "    let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)\n",
        "    public var trainingStepCount = 0\n",
        "    public var trainingBatchCount = 0\n",
        "    public var trainingLossSum: Float = 0.0\n",
        "    public var epochIndex = 0 // FIXME: Workaround\n",
        "\n",
        "    public func writeStats<L: TrainingLoopProtocol>(_ loop: inout L, event: TrainingLoopEvent) throws {\n",
        "        if event == .batchEnd {\n",
        "            guard \n",
        "            // let batchIndex = loop.batchIndex, \n",
        "            let trainingLoss = loop.lastLoss else {\n",
        "                return\n",
        "            }\n",
        "            // print(\"\\nbatch stats: batchIndex: \\(batchIndex), trainingStepCount: \\(trainingStepCount), trainingLoss: \\(trainingLoss)\")\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value:trainingLoss.scalar!)\n",
        "            trainingStepCount += 1\n",
        "            trainingBatchCount += 1\n",
        "            trainingLossSum += Float(trainingLoss.scalar!)\n",
        "        }\n",
        "        if event == .epochStart {\n",
        "            trainingBatchCount = 0\n",
        "            trainingLossSum = 0.0\n",
        "        }\n",
        "        if event == .epochEnd {\n",
        "            // guard let epochIndex = loop.epochIndex else {\n",
        "            //     return\n",
        "            // }\n",
        "            let current_epoch = epochIndex + 1\n",
        "            let epochTrainingLoss = trainingLossSum / Float(trainingBatchCount)\n",
        "            // print(\"\\nepoch stats: current_epoch: \\(current_epoch), epochTrainingLoss: \\(epochTrainingLoss)\")\n",
        "            summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: current_epoch, value: epochTrainingLoss)\n",
        "        }\n",
        "        if event == .fitEnd {\n",
        "            summaryWriter.flush()\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TBELE-EpBJVd"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QNX6TvywBN9P",
        "colab": {}
      },
      "source": [
        "let statsRecorder = StatsRecorder()\n",
        "\n",
        "// Training loop\n",
        "print(\"\\nSetting up the training loop\")\n",
        "let trainingProgress = TrainingProgress(metrics: [.loss])\n",
        "var trainingLoop = TrainingLoop(\n",
        "  training: dataset.trainEpochs,\n",
        "  validation: dataset.testBatches,\n",
        "  optimizer: optimizer,\n",
        "  lossFunction: embeddedNormalMixtureSurrogateLoss,\n",
        "  callbacks: [trainingProgress.update, statsRecorder.writeStats, learningRateUpdater])\n",
        "\n",
        "print(\"\\nTraining Transformer for the Lang2motion task!\")\n",
        "// FIXME: epoch loop workaround for checkpoint saving\n",
        "for epochIndex in start_epoch..<start_epoch+nEpochs {\n",
        "    print(\"epoch \\(epochIndex+1)/\\(start_epoch + nEpochs)\")\n",
        "    statsRecorder.epochIndex = epochIndex\n",
        "    try! trainingLoop.fit(&model, epochs: 1, on: device)\n",
        "    try! model.writeCheckpoint(to: checkpointURL, name: \"model.e\\(epochIndex+1)\")\n",
        "}\n",
        "\n",
        "try! model.writeCheckpoint(to: checkpointURL, name: \"model.final\")\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AsQKu2Bpuyfa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}