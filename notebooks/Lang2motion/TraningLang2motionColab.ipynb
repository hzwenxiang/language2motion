{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TraningLang2motionColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJwHDGwK7aGN",
        "colab_type": "text"
      },
      "source": [
        "# Train Transformer for the Lang2motion task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XucZWfhQ6rtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"master\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter LangMotionModels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvk1la6a7jqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import LangMotionModels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xCh7jaO7qpA",
        "colab_type": "text"
      },
      "source": [
        "## What's the GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF9_tK8p7rPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "\n",
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}\n",
        "\n",
        "sh(\"\"\"\n",
        "export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
        "export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
        "nvidia-smi\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EpGj5Y91PXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// sh(\"ps ax\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syl5JUVQ1TEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// sh(\"kill 2051\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzOE5kHy743R",
        "colab_type": "text"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee6ivU1w75u2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let datasetSize: DatasetSize = .full\n",
        "let dataset_name = \"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw5R28Eo79vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sh(\"mkdir -p /content/data/motion_images/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/\\(dataset_name)tgz\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "tar xzvf \\(dataset_name)tgz --skip-old-files\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anldphJN8lL_",
        "colab_type": "text"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcru9CBe8nbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let runName = \"run_1\"\n",
        "// let batchSize = 4\n",
        "let batchSize = 150\n",
        "let maxTextSequenceLength =  20\n",
        "let maxMotionLength =  100\n",
        "let nEpochs = 5\n",
        "let learningRate: Float = 5e-4\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
        "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"learningRate: \\(learningRate)\")\n",
        "\n",
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"\\(dataset_name)plist\")\n",
        "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lts7GgHE8pS3",
        "colab_type": "text"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Obl55068up1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let device = Device.defaultXLA\n",
        "let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACBJHSaA8u7z",
        "colab_type": "text"
      },
      "source": [
        "## X10 warm-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luvidtBy8wXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "// let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "// let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "// print(eagerTensorSum)\n",
        "// print(eagerTensor1.device)\n",
        "// let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "// print(x10Tensor2.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_XNP-hV8w0o",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hrsx_O-9cyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// instantiate text processor\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor2(vocabulary: vocabulary, tokenizer: tokenizer, maxTextSequenceLength: maxTextSequenceLength, maxMotionLength: maxMotionLength)\n",
        "\n",
        "/// instantiate model\n",
        "let vocabSize = vocabulary.count\n",
        "let nbJoints = 47 // TODO: get value from dataset\n",
        "let layerCount: Int = 6\n",
        "let modelSize: Int = 256\n",
        "let feedForwardSize: Int = 1024\n",
        "let headCount: Int = 8\n",
        "let dropoutProbability: Double = 0.1\n",
        "\n",
        "var transformer = LangMotionTransformer(\n",
        "    vocabSize: vocabSize, \n",
        "    nbJoints: nbJoints,\n",
        "    layerCount: layerCount, \n",
        "    modelSize: modelSize, \n",
        "    feedForwardSize: feedForwardSize, \n",
        "    headCount: headCount, \n",
        "    dropoutProbability: dropoutProbability\n",
        ")\n",
        "\n",
        "let nbMixtures = 20\n",
        "// TODO: integrate MotionGaussianMixtureModel with Generator\n",
        "var mixtureModel = MotionGaussianMixtureModel(inputSize: nbJoints, nbJoints: nbJoints, nbMixtures: nbMixtures)\n",
        "// mixtureModel.move(to: device)\n",
        "\n",
        "var model = LangMotionModel(transformer: transformer, mixtureModel: mixtureModel)\n",
        "model.move(to: device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jZXyKzG-fVp",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-L0QTV0-fwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Lang2Motion(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    langDatasetURL: langDatasetURL,\n",
        "    batchSize: batchSize\n",
        ") { (example: Lang2Motion.Example) -> LangMotionBatch in    \n",
        "    let singleBatch = textProcessor.preprocess(example: example)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ3ECtyY-rtw",
        "colab_type": "text"
      },
      "source": [
        "## Test model with one batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEQuEHy9-wK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// one example to single batch\n",
        "// print(\"\\nSingle batch\")\n",
        "// print(\"============\")\n",
        "// let example = dataset.trainExamples[0]\n",
        "// print(\"example.sentence: \\\"\\(example.sentence)\\\"\")\n",
        "\n",
        "// let singleBatch = textProcessor.preprocess(example: example)\n",
        "// printBatch(singleBatch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_T-xnih-yf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// get a batch\n",
        "// print(\"\\nOne batch:\")\n",
        "// print(\"=========\")\n",
        "// var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
        "// let epoch = epochIterator.next()\n",
        "// let batches = Array(epoch!.1)\n",
        "// let batch: LangMotionBatch = batches[0]\n",
        "// printBatch(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l5Rgudq-0w8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// run one batch\n",
        "// print(\"\\nRun one batch:\")\n",
        "// print(\"==============\")\n",
        "// let deviceBatch = LangMotionBatch(copying: batch, to: device)\n",
        "// let batch_generated = model.generate(input: deviceBatch)\n",
        "// print(\"batch_generated.shape: \\(batch_generated.shape)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reg6NcYt-5wu",
        "colab_type": "text"
      },
      "source": [
        "## Set up decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CfnBQGW-6Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public func greedyDecodeMotion(sentence: String, prefix: String = \"prefix\") {\n",
        "    // FIXME: for generation don't supply motion in a batch, maybe neutral motion frame only\n",
        "    let randomMotionSample = dataset.trainExamples[0].motionSample\n",
        "    let example = Lang2Motion.Example(sampleID: -1, sentence: sentence, motionSample: randomMotionSample)\n",
        "    print(\"\\ngreedyDecodeMotion(sentence: \\\"\\(sentence)\\\")\")\n",
        "\n",
        "    let singleBatch = textProcessor.preprocess(example: example)\n",
        "    LangMotionBatch.printBatch(singleBatch)\n",
        "\n",
        "    print(\"\\nGenerate:\")\n",
        "    print(\"=========\")\n",
        "    Context.local.learningPhase = .inference\n",
        "    let singlePreds = model.generate(input: LangMotionBatch(copying: singleBatch, to: device))//.squeezingShape(at: 0)\n",
        "    singlePreds.printPreds()\n",
        "\n",
        "    let (motion, log_probs, done) = MotionDecoder.performNormalMixtureSampling(\n",
        "        preds: singlePreds, nb_joints: nbJoints, nb_mixtures: nbMixtures, maxMotionLength: maxMotionLength)\n",
        "\n",
        "    let descaled_motion = dataset.scaler.inverse_transform(motion)\n",
        "\n",
        "    print(\"\\nmotion.shape: \\(motion.shape)\")\n",
        "    print(\"log_probs.count: \\(log_probs.count)\")\n",
        "    print(\"done.shape: \\(done.shape)\")\n",
        "    print(\"done: \\(done)\")\n",
        "    // print(\"log_probs: \\(log_probs)\")\n",
        "    // print(\"descaled_motion: \\(descaled_motion)\")\n",
        "\n",
        "    let imageURL = dataURL.appendingPathComponent(\"motion_images/\\(prefix).png\")\n",
        "    motionToImg(url: imageURL, motion: descaled_motion, motionFlag: done, padTo: maxMotionLength, descr: \"\\(prefix), \\(example.sentence)\")\n",
        "    print(\"Saved image: \\(imageURL.path)\")\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI44Cnn9BAdl",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIc0x5uBAyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var optimizer = Adam(for: model, learningRate: learningRate)\n",
        "optimizer = Adam(copying: optimizer, to: device)\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"tboard/Lang2motion/\\(runName)\", isDirectory: true)\n",
        "let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmE1sfvpAqrQ",
        "colab_type": "text"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlq5bSE0Arg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let args = LossArgs(\n",
        "        nb_joints: nbJoints,\n",
        "        nb_mixtures: nbMixtures,\n",
        "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
        "        mixture_regularizer: 0.0\n",
        ")\n",
        "\n",
        "func update(model: inout LangMotionModel, using optimizer: inout Adam<LangMotionModel>, for batch: LangMotionBatch) -> Float {\n",
        "    let y_true = TargetTruth(motion: batch.targetTruth, stops: batch.targetTruthStop)\n",
        "    let result = withLearningPhase(.training) { () -> Float in\n",
        "        let (loss, grad) = valueWithGradient(at: model) {\n",
        "            (model) -> Tensor<Float> in\n",
        "            let y_pred = model.generate(input: batch)\n",
        "            let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
        "            let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
        "            // let ones = Tensor<Float>(ones: loss.shape)\n",
        "            // let nans = loss.isNaN\n",
        "            // let loss_notNaN = loss.replacing(with:ones, where:nans)\n",
        "            // let avg_loss = loss_notNaN.sum() / n_items\n",
        "            let avg_loss = loss.sum() / n_items\n",
        "            // print(\"avg_loss: \\(avg_loss)\")\n",
        "            return avg_loss\n",
        "        }\n",
        "        optimizer.update(&model, along: grad)\n",
        "        LazyTensorBarrier()\n",
        "        return loss.scalarized()\n",
        "    }\n",
        "    return result\n",
        "}\n",
        "\n",
        "/// returns validation loss\n",
        "func validate(model: inout LangMotionModel, for batch: LangMotionBatch) -> Float {\n",
        "    let y_true = TargetTruth(motion: batch.targetTruth, stops: batch.targetTruthStop)\n",
        "    let result = withLearningPhase(.inference) { () -> Float in\n",
        "        let y_pred = model.generate(input: batch)\n",
        "        let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
        "        let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
        "        let avg_loss = loss.sum() / n_items\n",
        "        return avg_loss.scalarized()\n",
        "    }\n",
        "    LazyTensorBarrier()\n",
        "    return result\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBELE-EpBJVd",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57_H2KhUBJsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let nEpochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNX6TvywBN9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/// Training loop\n",
        "print(\"\\nTraining Transformer for the Lang2motion task!\")\n",
        "var trainingStepCount = 0\n",
        "let print_every = 10\n",
        "let limit_print_to_step = 5\n",
        "time() {\n",
        "    LazyTensorBarrier()\n",
        "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(nEpochs).enumerated() {\n",
        "        print(\"[Epoch \\(epoch + 1)]\")\n",
        "        Context.local.learningPhase = .training\n",
        "        var trainingLossSum: Float = 0\n",
        "        var trainingBatchCount = 0\n",
        "        if epoch == 0 {\n",
        "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
        "        }\n",
        "\n",
        "        for eagerBatch in epochBatches {\n",
        "            if (trainingStepCount < limit_print_to_step || trainingStepCount % print_every == 0) {\n",
        "                print(\"==> step \\(trainingStepCount)\")\n",
        "            }\n",
        "            let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = update(model: &model, using: &optimizer, for: batch)\n",
        "            if (trainingStepCount < limit_print_to_step || trainingStepCount % print_every == 0) {\n",
        "                print(\"current loss at step \\(trainingStepCount): \\(loss)\")\n",
        "            }\n",
        "            trainingLossSum += loss\n",
        "            trainingBatchCount += 1\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
        "            trainingStepCount += 1\n",
        "        }\n",
        "        print(\n",
        "            \"\"\"\n",
        "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch+1, value: trainingLossSum / Float(trainingBatchCount))\n",
        "\n",
        "        if epoch == 0 {\n",
        "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
        "        }\n",
        "        Context.local.learningPhase = .inference\n",
        "        var devLossSum: Float = 0\n",
        "        var devBatchCount = 0\n",
        "        var totalGuessCount = 0\n",
        "\n",
        "        for eagerBatch in dataset.validationBatches {\n",
        "            let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = validate(model: &model, for: batch)\n",
        "            let valBatchSize = batch.targetMotion.shape[0]\n",
        "\n",
        "            devLossSum += loss\n",
        "            devBatchCount += 1\n",
        "            totalGuessCount += valBatchSize\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            \"\"\"\n",
        "            totalGuessCount: \\(totalGuessCount) \\\n",
        "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch+1, value: devLossSum / Float(devBatchCount))\n",
        "        greedyDecodeMotion(sentence: \"human is walking\", prefix: \"epoch_\\(epoch+1)\")\n",
        "    }\n",
        "    summaryWriter.flush()\n",
        "}\n",
        "\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODISB-IWBUof",
        "colab_type": "text"
      },
      "source": [
        "## Generate motion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bbmqcOHBU_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// TODO: show motion inline\n",
        "greedyDecodeMotion(sentence: \"human is walking\", prefix: \"foo9\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}