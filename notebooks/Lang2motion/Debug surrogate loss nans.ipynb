{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJwHDGwK7aGN"
   },
   "source": [
    "# Train Transformer for the Lang2motion task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "// for local development\n",
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XucZWfhQ6rtA"
   },
   "outputs": [],
   "source": [
    "// for colab\n",
    "// %install-location $cwd/swift-install\n",
    "// %install-swiftpm-flags -c release\n",
    "// %install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"master\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvk1la6a7jqe"
   },
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import TextModels\n",
    "import TranslationModels\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "import SummaryWriter\n",
    "import MotionModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xCh7jaO7qpA"
   },
   "source": [
    "## What's the GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF9_tK8p7rPS"
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "\n",
    "func shell(_ command: String) -> String {\n",
    "    let task = Process()\n",
    "    let pipe = Pipe()\n",
    "\n",
    "    task.standardOutput = pipe\n",
    "    task.arguments = [\"-c\", command]\n",
    "    task.launchPath = \"/bin/bash\"\n",
    "    task.launch()\n",
    "\n",
    "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
    "    return String(data: data, encoding: .utf8)!\n",
    "}\n",
    "\n",
    "func sh(_ command: String) {\n",
    "    print(shell(command))\n",
    "}\n",
    "\n",
    "// sh(\"\"\"\n",
    "// export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
    "// export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
    "// nvidia-smi\n",
    "// \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzOE5kHy743R"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee6ivU1w75u2"
   },
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .mini\n",
    "let dataset_name = \"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pw5R28Eo79vM"
   },
   "outputs": [],
   "source": [
    "// sh(\"mkdir -p /content/data/motion_images/\")\n",
    "// sh(\"\"\"\n",
    "// cd /content/data/\n",
    "// wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.3.0/\\(dataset_name)tgz\n",
    "// wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
    "// wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
    "// tar xzvf \\(dataset_name)tgz --skip-old-files\n",
    "// \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "anldphJN8lL_"
   },
   "source": [
    "## Set training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lcru9CBe8nbs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runName: run_1\n",
      "batchSize: 1\n",
      "maxTextSequenceLength: 20\n",
      "maxMotionLength: 100\n",
      "nEpochs: 5\n",
      "learningRate: 0.0005\n"
     ]
    }
   ],
   "source": [
    "let runName = \"run_1\"\n",
    "let batchSize = 1\n",
    "// let batchSize = 150\n",
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  100\n",
    "let nEpochs = 5\n",
    "let learningRate: Float = 5e-4\n",
    "\n",
    "print(\"runName: \\(runName)\")\n",
    "print(\"batchSize: \\(batchSize)\")\n",
    "print(\"maxTextSequenceLength: \\(maxTextSequenceLength)\")\n",
    "print(\"maxMotionLength: \\(maxMotionLength)\")\n",
    "print(\"nEpochs: \\(nEpochs)\")\n",
    "print(\"learningRate: \\(learningRate)\")\n",
    "\n",
    "// let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"\\(dataset_name)plist\")\n",
    "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lts7GgHE8pS3"
   },
   "source": [
    "## Select eager or X10 backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Obl55068up1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device(kind: .CPU, ordinal: 0, backend: .TF_EAGER)\n"
     ]
    }
   ],
   "source": [
    "// let device = Device.defaultXLA\n",
    "let device = Device.defaultTFEager\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACBJHSaA8u7z"
   },
   "source": [
    "## X10 warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luvidtBy8wXd"
   },
   "outputs": [],
   "source": [
    "// let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
    "// let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
    "// let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
    "// print(eagerTensorSum)\n",
    "// print(eagerTensor1.device)\n",
    "// let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
    "// print(x10Tensor2.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_XNP-hV8w0o"
   },
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Hrsx_O-9cyb"
   },
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor2(vocabulary: vocabulary, tokenizer: tokenizer, maxTextSequenceLength: maxTextSequenceLength, maxMotionLength: maxMotionLength)\n",
    "\n",
    "/// instantiate model\n",
    "let vocabSize = vocabulary.count\n",
    "let nbJoints = 47 // TODO: get value from dataset\n",
    "let layerCount: Int = 6\n",
    "let modelSize: Int = 256\n",
    "let feedForwardSize: Int = 1024\n",
    "let headCount: Int = 8\n",
    "let dropoutProbability: Double = 0.1\n",
    "\n",
    "var transformer = LangMotionTransformer(\n",
    "    vocabSize: vocabSize, \n",
    "    nbJoints: nbJoints,\n",
    "    layerCount: layerCount, \n",
    "    modelSize: modelSize, \n",
    "    feedForwardSize: feedForwardSize, \n",
    "    headCount: headCount, \n",
    "    dropoutProbability: dropoutProbability\n",
    ")\n",
    "\n",
    "let nbMixtures = 20\n",
    "// TODO: integrate MotionGaussianMixtureModel with Generator\n",
    "var mixtureModel = MotionGaussianMixtureModel(inputSize: nbJoints, nbJoints: nbJoints, nbMixtures: nbMixtures)\n",
    "// mixtureModel.move(to: device)\n",
    "\n",
    "var model = LangMotionModel(transformer: transformer, mixtureModel: mixtureModel)\n",
    "model.move(to: device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jZXyKzG-fVp"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-L0QTV0-fwa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset...\n",
      "MotionDataset2(motionSamples: 1030)\n",
      "keeping 834 annotatated motions\n",
      "keeping 834 longer motions, with minimum 10 frames\n",
      "Scaling motions...\n",
      "Motions scaled.\n",
      "Dataset acquired.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    langDatasetURL: langDatasetURL,\n",
    "    batchSize: batchSize\n",
    ") { (example: Lang2Motion.Example) -> LangMotionBatch in    \n",
    "    let singleBatch = textProcessor.preprocess(example: example)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZ3ECtyY-rtw"
   },
   "source": [
    "## Test model with one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sue2p9RU-sF6"
   },
   "outputs": [],
   "source": [
    "func printBatch(_ batch: LangMotionBatch) {\n",
    "    print(\"type: \\(type(of:batch))\")\n",
    "    print(\"sampleID: shape \\(batch.sampleID.shape), value \\(batch.sampleID)\")\n",
    "\n",
    "    print(\"source\")\n",
    "    print(\"  tokenIds.shape: \\(batch.tokenIds.shape)\")\n",
    "    print(\"  mask.shape: \\(batch.mask.shape)\")\n",
    "    print(\"  tokenCount: shape \\(batch.tokenCount.shape), value \\(batch.tokenCount)\")\n",
    "\n",
    "    print(\"target\")\n",
    "    print(\"  targetMotionFrames.shape: \\(batch.targetMotionFrames.shape)\")\n",
    "    print(\"  targetMask.shape: \\(batch.targetMask.shape)\")\n",
    "    print(\"  targetTruth.shape: \\(batch.targetTruth.shape)\")\n",
    "    print(\"  origMotionFramesCount: shape \\(batch.origMotionFramesCount.shape), value \\(batch.origMotionFramesCount)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vEQuEHy9-wK0"
   },
   "outputs": [],
   "source": [
    "/// one example to single batch\n",
    "// print(\"\\nSingle batch\")\n",
    "// print(\"============\")\n",
    "// let example = dataset.trainExamples[0]\n",
    "// print(\"example.sentence: \\\"\\(example.sentence)\\\"\")\n",
    "\n",
    "// let singleBatch = textProcessor.preprocess(example: example)\n",
    "// printBatch(singleBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_T-xnih-yf2"
   },
   "outputs": [],
   "source": [
    "/// get a batch\n",
    "// print(\"\\nOne batch:\")\n",
    "// print(\"=========\")\n",
    "// var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
    "// let epoch = epochIterator.next()\n",
    "// let batches = Array(epoch!.1)\n",
    "// let batch: LangMotionBatch = batches[0]\n",
    "// printBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1l5Rgudq-0w8"
   },
   "outputs": [],
   "source": [
    "/// run one batch\n",
    "// print(\"\\nRun one batch:\")\n",
    "// print(\"==============\")\n",
    "// let deviceBatch = LangMotionBatch(copying: batch, to: device)\n",
    "// let batch_generated = model.generate(input: deviceBatch)\n",
    "// print(\"batch_generated.shape: \\(batch_generated.shape)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "reg6NcYt-5wu"
   },
   "source": [
    "## Set up decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CfnBQGW-6Ho"
   },
   "outputs": [],
   "source": [
    "public func greedyDecodeMotion(sentence: String, prefix: String = \"prefix\") {\n",
    "    // FIXME: for generation don't supply motion in a batch, maybe neutral motion frame only\n",
    "    let randomMotionSample = dataset.trainExamples[0].motionSample\n",
    "    let example = Lang2Motion.Example(sampleID: -1, sentence: sentence, motionSample: randomMotionSample)\n",
    "    print(\"sentence: \\\"\\(sentence)\\\"\")\n",
    "\n",
    "    let singleBatch = textProcessor.preprocess(example: example)\n",
    "    printBatch(singleBatch)\n",
    "\n",
    "    print(\"\\nDecode single batch:\")\n",
    "    print(\"====================\")\n",
    "    Context.local.learningPhase = .inference\n",
    "    let single_generated = model.generate(input: LangMotionBatch(copying: singleBatch, to: device)).squeezingShape(at: 0)\n",
    "    print(\"generated.shape: \\(single_generated.shape)\")\n",
    "\n",
    "    let (motion, log_probs, done) = performNormalMixtureSampling(\n",
    "        preds: single_generated, nb_joints: nbJoints, nb_mixtures: nbMixtures, maxMotionLength: maxMotionLength)\n",
    "\n",
    "    let descaled_motion = dataset.scaler.inverse_transform(motion)\n",
    "\n",
    "    print(\"motion.shape: \\(motion.shape)\")\n",
    "    print(\"log_probs.count: \\(log_probs.count)\")\n",
    "    print(\"done.shape: \\(done.shape)\")\n",
    "    print(\"done: \\(done)\")\n",
    "    // print(\"log_probs: \\(log_probs)\")\n",
    "    // print(\"descaled_motion: \\(descaled_motion)\")\n",
    "\n",
    "    let imageURL = dataURL.appendingPathComponent(\"motion_images/\\(prefix).png\")\n",
    "    motionToImg(url: imageURL, motion: descaled_motion, motionFlag: done, padTo: maxMotionLength, descr: \"\\(prefix), \\(example.sentence)\")\n",
    "    print(\"Saved image: \\(imageURL.path)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dI44Cnn9BAdl"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjIc0x5uBAyh"
   },
   "outputs": [],
   "source": [
    "var optimizer = Adam(for: model, learningRate: learningRate)\n",
    "optimizer = Adam(copying: optimizer, to: device)\n",
    "\n",
    "let logdirURL = dataURL.appendingPathComponent(\"tboard/Lang2motion/\\(runName)\", isDirectory: true)\n",
    "let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmE1sfvpAqrQ"
   },
   "source": [
    "## Training helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlq5bSE0Arg3"
   },
   "outputs": [],
   "source": [
    "let args = LossArgs(\n",
    "        nb_joints: nbJoints,\n",
    "        nb_mixtures: nbMixtures,\n",
    "        mixture_regularizer_type: \"None\",  // [\"cv\", \"l2\", \"None\"]\n",
    "        mixture_regularizer: 0.0\n",
    ")\n",
    "\n",
    "func update(model: inout LangMotionModel, using optimizer: inout Adam<LangMotionModel>, for batch: LangMotionBatch) -> Float {\n",
    "    let y_true = batch.targetTruth\n",
    "    let result = withLearningPhase(.training) { () -> Float in\n",
    "        let (loss, grad) = valueWithGradient(at: model) {\n",
    "            (model) -> Tensor<Float> in\n",
    "            let y_pred = model.generate(input: batch)\n",
    "            let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
    "            let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
    "            // let ones = Tensor<Float>(ones: loss.shape)\n",
    "            // let nans = loss.isNaN\n",
    "            // let loss_notNaN = loss.replacing(with:ones, where:nans)\n",
    "            // let avg_loss = loss_notNaN.sum() / n_items\n",
    "            let avg_loss = loss.sum() / n_items\n",
    "            // print(\"avg_loss: \\(avg_loss)\")\n",
    "            return avg_loss\n",
    "        }\n",
    "        optimizer.update(&model, along: grad)\n",
    "        LazyTensorBarrier()\n",
    "        return loss.scalarized()\n",
    "    }\n",
    "    return result\n",
    "}\n",
    "\n",
    "/// returns validation loss\n",
    "func validate(model: inout LangMotionModel, for batch: LangMotionBatch) -> Float {\n",
    "    let y_true = batch.targetTruth\n",
    "    let result = withLearningPhase(.inference) { () -> Float in\n",
    "        let y_pred = model.generate(input: batch)\n",
    "        let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
    "        let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
    "        let avg_loss = loss.sum() / n_items\n",
    "        return avg_loss.scalarized()\n",
    "    }\n",
    "    LazyTensorBarrier()\n",
    "    return result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug surrogate loss nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Bool {\n",
    "    var intValue: Int {\n",
    "        return self ? 1 : 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// get a batch\n",
    "print(\"\\nOne batch:\")\n",
    "print(\"=========\")\n",
    "var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
    "let epoch = epochIterator.next()\n",
    "let batches = Array(epoch!.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: LangMotionBatch\n",
      "sampleID: shape [1], value [2098]\n",
      "source\n",
      "  tokenIds.shape: [1, 20]\n",
      "  mask.shape: [1, 1, 20]\n",
      "  tokenCount: shape [1], value [9]\n",
      "target\n",
      "  targetMotionFrames.shape: [1, 99, 47]\n",
      "  targetMask.shape: [1, 99, 99]\n",
      "  targetTruth.shape: [1, 99, 47]\n",
      "  origMotionFramesCount: shape [1], value [49]\n"
     ]
    }
   ],
   "source": [
    "let eagerBatch: LangMotionBatch = batches[1]\n",
    "printBatch(eagerBatch)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "47\n",
      "current loss: nan(0x1fffff)\n",
      "avg_loss_notNaN: 343.77454\n",
      "[[nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff),      656.5909, nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "      678.62244,     679.30273,     665.77325,     663.08453,      640.1204,     660.07465,\n",
      "       669.6528,      672.4334,      655.6682,     685.94696,      683.8687,     653.43085,\n",
      "          668.1,      670.1233,     678.68463,      673.3776,      630.8347,      656.2923,\n",
      "      676.92114,     669.16516,       667.612,      657.4228,      671.8508,      661.1358,\n",
      "       642.7764,     675.81805,      676.0202,      662.9737,      677.6536,      669.0433,\n",
      "      667.27563,     646.90106,      667.0759,      654.9263,       680.054,      674.2156,\n",
      "       670.0168,      668.1334,     664.87054,      661.9571,      644.6537,      664.2705,\n",
      "       667.3284,     666.34247,     669.89655,     673.82605,     678.21674,      667.8891,\n",
      "       676.7696,      671.6846,           0.0]]\n"
     ]
    }
   ],
   "source": [
    "let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
    "\n",
    "let y_true = batch.targetTruth\n",
    "\n",
    "let y_pred = model.generate(input: batch)\n",
    "let loss = normalMixtureSurrogateLoss(y_true: y_true, y_pred: y_pred, args: args)\n",
    "let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
    "let ones = Tensor<Float>(ones: loss.shape)\n",
    "let nans: Tensor<Bool> = loss.isNaN\n",
    "print(nans.scalars.count)\n",
    "print(nans.scalars.reduce(0, {(x: Int, y: Bool) in x+y.intValue}))\n",
    "let loss_notNaN = loss.replacing(with:ones, where:nans)\n",
    "let avg_loss_notNaN = loss_notNaN.sum() / n_items\n",
    "let avg_loss = loss.sum() / n_items\n",
    "\n",
    "print(\"current loss: \\(avg_loss.scalarized())\")\n",
    "print(\"avg_loss_notNaN: \\(avg_loss_notNaN.scalarized())\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [1, 99, 1901]\n",
       "  ▿ dimensions : 3 elements\n",
       "    - 0 : 1\n",
       "    - 1 : 99\n",
       "    - 2 : 1901\n"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "let y_pred_nans: Tensor<Bool> = y_pred.isNaN\n",
    "print(y_pred_nans.scalars.reduce(0, {(x: Int, y: Bool) in x+y.intValue}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 2 elements\n",
       "  - .0 : -26.429714\n",
       "  - .1 : 28.42573\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred.min(), y_pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@differentiable\n",
    "public func normalMixtureSurrogateLoss2(y_true: Tensor<Float>, y_pred: Tensor<Float>, args: LossArgs) -> Tensor<Float> {\n",
    "    let TINY: Float = 1e-8\n",
    "    let pi: Float = 3.1415\n",
    "    let nb_mixtures = args.nb_mixtures\n",
    "    let nb_joints = args.nb_joints\n",
    "\n",
    "    let all_means = y_pred[0..., 0..., 0..<nb_joints * nb_mixtures]\n",
    "    let all_variances = y_pred[0..., 0..., nb_joints *\n",
    "                           nb_mixtures..<2 * nb_joints * nb_mixtures] + TINY\n",
    "    let weights = y_pred[0..., 0..., 2 * nb_joints * nb_mixtures..<2 *\n",
    "                     nb_joints * nb_mixtures + nb_mixtures]\n",
    "    let stop = y_pred[0..., 0..., -1]\n",
    "    let y_true_motion = y_true[0..., 0..., 0..<nb_joints]\n",
    "    let y_true_stop = y_true[0..., 0..., -1]\n",
    "\n",
    "    var log_mixture_pdf: Tensor<Float> = Tensor<Float>(zeros: [weights.shape[0], weights.shape[1]]) \n",
    "    for mixture_idx in 0..<nb_mixtures {\n",
    "        let start_idx = mixture_idx * nb_joints\n",
    "        let means = all_means[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "        let variances = all_variances[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "        let diff = y_true_motion - means\n",
    "        let pdf1 = 1.0 / sqrt(variances * 2.0 * pi)\n",
    "        let pdf2a = diff.squared()\n",
    "        let pdf2 = exp(-(pdf2a) / (2.0 * variances))\n",
    "        let pdf = pdf1 * pdf2\n",
    "        let weighted_pdf = weights[0..., 0..., mixture_idx] * \n",
    "            log(pdf + TINY).sum(alongAxes:2).squeezingShape(at: 2)\n",
    "        log_mixture_pdf = log_mixture_pdf + weighted_pdf\n",
    "    }\n",
    "\n",
    "    let b_pdf1 = Float(1.0) - y_true_stop\n",
    "    let b_pdf2 = Float(1.0) - stop\n",
    "    let bernoulli_pdf = y_true_stop * stop + b_pdf1 * b_pdf2\n",
    "    let log_bernoulli_pdf = log(bernoulli_pdf + TINY)\n",
    "\n",
    "    var mixture_reg: Float = 0.0\n",
    "    if args.mixture_regularizer_type == \"cv\" {\n",
    "        // We want to use (std / mean)^2 = std^2 / mean^2 = var / mean^2.\n",
    "        mixture_reg = weights.variance().scalarized() / \n",
    "            weights.mean().squared().scalarized()\n",
    "    } else if args.mixture_regularizer_type == \"l2\" {\n",
    "        mixture_reg = weights.squared().sum().scalarized()\n",
    "    } else {\n",
    "        mixture_reg = 0.0\n",
    "    }\n",
    "\n",
    "    let loss = -(log_mixture_pdf + log_bernoulli_pdf) +\n",
    "        args.mixture_regularizer * mixture_reg\n",
    "    return loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[[1, 99]]: [[nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "  nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff), nan(0x1fffff),\n",
      "       682.8594,     663.61786,      668.6721,      672.0308,      670.3072,     658.59924,\n",
      "       673.7678,      655.6654,       678.099,      672.0724,      663.0092,       675.479,\n",
      "       669.8846,      648.9531,     677.10016,      657.6282,      675.0118,     673.81494,\n",
      "       675.8322,     679.08484,      668.3582,      674.7251,     676.97943,      669.0876,\n",
      "      667.57806,      658.5623,      657.1442,      672.5001,      670.9762,      666.7299,\n",
      "      671.40656,      662.3288,      675.7638,     676.42206,      673.3985,      682.8363,\n",
      "       664.2792,      657.1672,      677.6026,      665.7315,      671.3036,     671.69806,\n",
      "      691.91486,      666.2312,      674.8895,      671.1398,      654.6276,      673.4115,\n",
      "       666.3677,      672.2267,           0.0]]\n"
     ]
    }
   ],
   "source": [
    "let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
    "let y_true = batch.targetTruth\n",
    "let y_pred = model.generate(input: batch)\n",
    "// let loss = normalMixtureSurrogateLoss2(y_true: y_true, y_pred: y_pred, args: args)\n",
    "\n",
    "let TINY: Float = 1e-8\n",
    "let pi: Float = 3.1415\n",
    "let nb_mixtures = args.nb_mixtures\n",
    "let nb_joints = args.nb_joints\n",
    "\n",
    "let all_means = y_pred[0..., 0..., 0..<nb_joints * nb_mixtures]\n",
    "let all_variances = y_pred[0..., 0..., nb_joints *\n",
    "                       nb_mixtures..<2 * nb_joints * nb_mixtures] + TINY\n",
    "let weights = y_pred[0..., 0..., 2 * nb_joints * nb_mixtures..<2 *\n",
    "                 nb_joints * nb_mixtures + nb_mixtures]\n",
    "let stop = y_pred[0..., 0..., -1]\n",
    "let y_true_motion = y_true[0..., 0..., 0..<nb_joints]\n",
    "let y_true_stop = y_true[0..., 0..., -1]\n",
    "\n",
    "var log_mixture_pdf: Tensor<Float> = Tensor<Float>(zeros: [weights.shape[0], weights.shape[1]]) \n",
    "for mixture_idx in 0..<nb_mixtures {\n",
    "    let start_idx = mixture_idx * nb_joints\n",
    "    let means = all_means[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "    let variances = all_variances[0..., 0..., start_idx..<start_idx + nb_joints]\n",
    "    let diff = y_true_motion - means\n",
    "    let pdf1 = 1.0 / sqrt(variances * 2.0 * pi)\n",
    "    let pdf2a = diff.squared()\n",
    "    let pdf2 = exp(-(pdf2a) / (2.0 * variances))\n",
    "    let pdf = pdf1 * pdf2\n",
    "    let weighted_pdf = weights[0..., 0..., mixture_idx] * \n",
    "        log(pdf + TINY).sum(alongAxes:2).squeezingShape(at: 2)\n",
    "    log_mixture_pdf = log_mixture_pdf + weighted_pdf\n",
    "}\n",
    "\n",
    "let b_pdf1 = Float(1.0) - y_true_stop\n",
    "let b_pdf2 = Float(1.0) - stop\n",
    "let bernoulli_pdf = y_true_stop * stop + b_pdf1 * b_pdf2\n",
    "let log_bernoulli_pdf = log(bernoulli_pdf + TINY)\n",
    "\n",
    "var mixture_reg: Float = 0.0\n",
    "if args.mixture_regularizer_type == \"cv\" {\n",
    "    // We want to use (std / mean)^2 = std^2 / mean^2 = var / mean^2.\n",
    "    mixture_reg = weights.variance().scalarized() / \n",
    "        weights.mean().squared().scalarized()\n",
    "} else if args.mixture_regularizer_type == \"l2\" {\n",
    "    mixture_reg = weights.squared().sum().scalarized()\n",
    "} else {\n",
    "    mixture_reg = 0.0\n",
    "}\n",
    "\n",
    "let loss = -(log_mixture_pdf + log_bernoulli_pdf) +\n",
    "    args.mixture_regularizer * mixture_reg\n",
    "\n",
    "print(\"loss[\\(loss.shape)]: \\(loss)\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
    "let y_true = batch.targetTruth\n",
    "let y_pred = model.generate(input: batch)\n",
    "let loss = normalMixtureSurrogateLoss2(y_true: y_true, y_pred: y_pred, args: args)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "48\n",
      "current loss: nan(0x1fffff)\n",
      "avg_loss_notNaN: 337.681\n"
     ]
    }
   ],
   "source": [
    "let n_items: Float = Float(loss.shape[0] * loss.shape[1])\n",
    "let ones = Tensor<Float>(ones: loss.shape)\n",
    "let nans: Tensor<Bool> = loss.isNaN\n",
    "print(nans.scalars.count)\n",
    "print(nans.scalars.reduce(0, {(x: Int, y: Bool) in x+y.intValue}))\n",
    "let loss_notNaN = loss.replacing(with:ones, where:nans)\n",
    "let avg_loss_notNaN = loss_notNaN.sum() / n_items\n",
    "let avg_loss = loss.sum() / n_items\n",
    "\n",
    "print(\"current loss: \\(avg_loss.scalarized())\")\n",
    "print(\"avg_loss_notNaN: \\(avg_loss_notNaN.scalarized())\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBELE-EpBJVd"
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57_H2KhUBJsY"
   },
   "outputs": [],
   "source": [
    "// let nEpochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNX6TvywBN9P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Transformer for the Lang2motion task!\n",
      "[Epoch 1]\n",
      "epochBatches.count: 161\n",
      "==> step 0\n",
      "current loss at step 0: nan(0x1fffff)\n",
      "==> step 1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "execution_count": 14,
     "output_type": "error",
     "status": "error",
     "traceback": [
      "Current stack trace:",
      "\tframe #24: 0x00007f20cfa73fd1 libjupyterInstalledPackages.so`AD__$s17TranslationModels18MultiHeadAttentionV14callAsFunctiony10TensorFlow0I0VySfGAA0E5InputVySfGF__vjp_src_0_wrt_0_1 [inlined] AD__$s10TensorFlow6matmul_10transposed_AcA0A0VyxGAF_SbAFSbtSjRzAA0aB6ScalarRzlF__vjp_src_0_wrt_0_2_10TensorFlow0aB13FloatingPointRzlpartial apply forwarder with unmangled suffix \".75\" at <compiler-generated>:0 [opt]",
      "\tframe #25: 0x00007f20cfa73fb2 libjupyterInstalledPackages.so`AD__$s17TranslationModels18MultiHeadAttentionV14callAsFunctiony10TensorFlow0I0VySfGAA0E5InputVySfGF__vjp_src_0_wrt_0_1(input=<unavailable>, self=TranslationModels.MultiHeadAttention @ 0x00007ffed3fece08) at Attention.swift:179 [opt]",
      "\tframe #26: 0x00007f20cfad4fed libjupyterInstalledPackages.so`AD__orig_$s17TranslationModels18MultiHeadAttentionV14callAsFunctiony10TensorFlow0I0VySfGAA0E5InputVySfGF_$s17TranslationModels14AttentionInputVySfGAA09MultiHeadC0V10TensorFlow0G0VySfGAjC13TangentVectorVySf_GAfKVIeggoo_IetMggoo_Adf2jMIeggo_IetMggoo_TR_src_0_wrt_0_vjp_subset_parameters_thunk at <compiler-generated>:0 [opt]",
      "\tframe #27: 0x00007f20cfab79cb libjupyterInstalledPackages.so`AD__$s17TranslationModels23TransformerDecoderLayerV14callAsFunctiony10TensorFlow0I0VySfGAA0D5InputVySfGFA2H_AKtcfU___vjp_src_0_wrt_0_1($0=\n[[[      0.3326192,       1.5893282,     -0.44422472, ...,      0.65871376,\n        0.19504535,       1.2931701],\n  [     0.61733365,       0.6826892,     -0.23539254, ...,    -0.015824167,\n        0.36086568,       1.0562179],\n  [      0.3271611,     -0.24522139,     -0.10880697, ...,      0.34029126,\n        0.22429352,       0.7887093],\n  ...,\n  [     0.16907653,      0.60236895,     -0.07763929, ...,      0.41937646,\n        0.55884534,      0.90705544],\n  [   -0.102463864,      0.56005675,      0.22286192, ...,       0.8242744,\n        0.59113234,       1.0381025],\n  [    -0.16742542,      0.99568105,     -0.40194356, ...,     -0.04823326,\n       -0.06994968,       1.1432617]],\n\n [[     -0.6411932,       1.7928431,      -0.7274142, ...,      0.22842622,\n        0.34956077,        1.091598],\n  [    -0.21025294,       1.4225454,     0.048541296, ...,     -0.08037305,\n        0.23419723,       1.1990857],\n  [    -0.13476372,       1.5222135,      -0.4636848, ...,      0.14977995,\n        0.24122587,       0.6318094],\n  ...,\n  [    -0.27452287,       1.4595716,     -0.37514472, ...,       0.8140156,\n        0.11084512,       1.3929319],\n  [     -0.3974109,      0.30976668,         0.51441, ...,       0.6493031,\n        0.15932828,       1.0355208],\n  [     -0.5236945,       1.2367342,      -0.5615625, ...,      0.00261626,\n         0.0758051,       1.1677742]],\n\n [[    -0.74206877,      0.96154034,       0.1264302, ...,       0.8913116,\n         0.3495242,       2.1919706],\n  [      0.3463837,      0.32272586,      0.39561602, ...,      0.94506913,\n        0.44179136,         2.14303],\n  [     -0.6694664,       0.3996999,    -0.059255183, ...,       1.0043033,\n        0.28412318,       2.0726378],\n  ...,\n  [     0.12311544,      0.93237793,      0.38279215, ...,       0.7505507,\n       -0.28416136,      0.42768735],\n  [     -0.6975809,        1.142895,     -0.09463951, ...,       0.2908629,\n       0.037577543,       1.6568723],\n  [      -1.190632,      0.82994586,      -0.7133936, ...,       0.8258697,\n        0.15074734,       2.3824947]],\n\n ...,\n\n [[    -0.06590213,       2.1735287,     -0.18461277, ...,      -0.6588494,\n       0.032426834,       0.8492133],\n  [    -0.16339369,       1.9032768,      -0.4160596, ...,      0.16897234,\n        0.25768209,       0.4432726],\n  [     0.31117442,       1.4384629,     -0.26311007, ...,     0.014861525,\n        0.28826153,      0.76899385],\n  ...,\n  [    -0.39673018,       1.7700404,     -0.24481505, ...,       0.2978564,\n       -0.13549863,      0.87151515],\n  [    -0.25461087,       1.5803287,      -0.2287701, ...,    -0.083814524,\n        0.13437192,       1.0529294],\n  [     -0.9345582,       1.8541834,      -0.5235779, ...,      0.21985644,\n      0.0077064503,       1.2492499]],\n\n [[     0.19092216,        1.473655,     -0.33080947, ...,     -0.25922394,\n       -0.48511815,       1.0156186],\n  [      0.1334194,       1.6763133,      -0.2751311, ...,       0.2448203,\n      -0.052915998,       0.8528381],\n  [    -0.34978178,       1.3657798,      -0.5891553, ...,     -0.05741204,\n       0.084522255,         0.73226],\n  ...,\n  [    -0.18025194,       1.3513341,    -0.039748438, ...,       0.5097869,\n       -0.07842298,      0.31278518],\n  [     -0.3163691,      0.09607026,      -0.1469057, ...,       0.7232651,\n      0.0010993208,      0.71457934],\n  [    -0.67550546,       1.1500472,       -0.810845, ...,      0.48903567,\n       -0.21157996,       0.9625838]],\n\n [[     0.12969778,        1.655839,       0.1476378, ...,      0.61949337,\n        0.17397048,       1.5699704],\n  [     0.63831836,       1.3218725,      0.40847093, ...,      0.68190867,\n        0.08519399,      0.63288045],\n  [     0.22202128,      0.63439953,      0.45380983, ...,      0.80412894,\n         0.3485671,       1.0296305],\n  ...,\n  [     0.08345185,      0.88181305,       0.7233726, ...,     0.104148775,\n       -0.48381773,       1.4262662],\n  [    -0.41682884,      0.83277315,      0.27275985, ...,      0.61163646,\n       0.037784576,       1.2257718],\n  [     0.13594374,      0.75595915,        0.142482, ...,     -0.17479408,\n       -0.21268854,       1.3567754]]], $1=<unavailable>, selfNoDerivative=<unavailable>, batchSize=<unavailable>) at Decoder.swift:36:43 [opt]",
      "\tframe #28: 0x00007f20cfafbd1a libjupyterInstalledPackages.so`AD__$s17TranslationModels18SublayerConnectionV14decoderForwardy10TensorFlow0G0VySfGAA20DecoderSubLayerInputVySfGF__vjp_src_0_wrt_0_1(input=TranslationModels.DecoderSubLayerInput<Swift.Float> @ 0x00007ffed3fed380, self=<unavailable>) at Utilities.swift:119:52 [opt]",
      "\tframe #29: 0x00007f20cfaa53c0 libjupyterInstalledPackages.so`AD__$s17TranslationModels23TransformerDecoderLayerV14callAsFunctiony10TensorFlow0I0VySfGAA0D5InputVySfGF__vjp_src_0_wrt_0_1(input=<unavailable>, self=TranslationModels.TransformerDecoderLayer @ 0x00007ffed3fed6b8) at Decoder.swift:35:36 [opt]",
      "\tframe #30: 0x00007f20cfaaef9a libjupyterInstalledPackages.so`AD__$s17TranslationModels7DecoderV14callAsFunctiony10TensorFlow0G0VySfGAA0C5InputVySfGF__vjp_src_0_wrt_0_1(input=<unavailable>, self=<unavailable>) at Decoder.swift:68:50 [opt]",
      "\tframe #31: 0x00007f20cf819856 libjupyterInstalledPackages.so`AD__$s12MotionModels04LangA11TransformerV6decode5input6memory10TensorFlow0H0VySfG8Datasets0cA5BatchV_AJtF__vjp_src_0_wrt_1_2(input=<unavailable>, memory=<unavailable>, self=MotionModels.LangMotionTransformer @ 0x00007ffed3fee0d0) at LangMotionTransformer.swift:72:28 [opt]",
      "\tframe #32: 0x00007f20cf818352 libjupyterInstalledPackages.so`AD__$s12MotionModels04LangA11TransformerV14callAsFunctiony10TensorFlow0H0VySfG8Datasets0cA5BatchVF__vjp_src_0_wrt_1(input=Datasets.LangMotionBatch @ 0x0000000051094570, self=MotionModels.LangMotionTransformer @ 0x00007ffed3fee0d0) at LangMotionTransformer.swift:46:21 [opt]",
      "\tframe #33: 0x00007f20cf804a43 libjupyterInstalledPackages.so`AD__$s12MotionModels04LangA5ModelV8generate5input10TensorFlow0G0VySfG8Datasets0cA5BatchV_tF__vjp_src_0_wrt_1 [inlined] callAsFunction(input=Datasets.LangMotionBatch @ 0x0000000051094570, self=<unavailable>) at LangMotionModel.swift:16:32 [opt]",
      "\tframe #34: 0x00007f20cf804a28 libjupyterInstalledPackages.so`AD__$s12MotionModels04LangA5ModelV8generate5input10TensorFlow0G0VySfG8Datasets0cA5BatchV_tF__vjp_src_0_wrt_1(input=<unavailable>, self=<unavailable>) at LangMotionModel.swift:21 [opt]",
      "\tframe #35: 0x00007f2080a44e6e $__lldb_expr96`partial apply for AD__$s14__lldb_expr_956update5model5using3forSf12MotionModels04LangG5ModelVz_10TensorFlow4AdamCyAHGz8Datasets0iG5BatchVtFSfyXEfU_AI0K0VySfGAHcfU___vjp_src_0_wrt_0 at <Cell 13>:13:32",
      "\tframe #44: 0x00007f2080a41537 $__lldb_expr96`partial apply for closure #1 in update(model:using:for:) at <Cell 13>:11:28",
      "\tframe #50: 0x00007f2080a4115f $__lldb_expr96`update(model=<unavailable>, optimizer=<unavailable>, batch=<unavailable>) at <Cell 13>:10:18",
      "\tframe #51: 0x00007f207c00e811 $__lldb_expr102`closure #1 in  at <Cell 14>:20:31",
      "\tframe #52: 0x00007f20cf7cd347 libjupyterInstalledPackages.so`time(repeating=1, f=0x00007f207c00d230 $__lldb_expr102`closure #1 () -> () in __lldb_expr_101 at <Cell 14>:4) at timing.swift:15:9 [opt]",
      "\tframe #53: 0x00007f207c00d14b $__lldb_expr102`main at <Cell 14>:4:1"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining Transformer for the Lang2motion task!\")\n",
    "var trainingStepCount = 0\n",
    "let print_every = 10\n",
    "time() {\n",
    "    LazyTensorBarrier()\n",
    "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(nEpochs).enumerated() {\n",
    "        print(\"[Epoch \\(epoch + 1)]\")\n",
    "        Context.local.learningPhase = .training\n",
    "        var trainingLossSum: Float = 0\n",
    "        var trainingBatchCount = 0\n",
    "        if epoch == 0 {\n",
    "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
    "        }\n",
    "\n",
    "        for eagerBatch in epochBatches {\n",
    "            if (trainingStepCount < 5 || trainingStepCount % print_every == 0) {\n",
    "                print(\"==> step \\(trainingStepCount)\")\n",
    "            }\n",
    "            let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
    "            let loss: Float = update(model: &model, using: &optimizer, for: batch)\n",
    "            if (trainingStepCount < 5 || trainingStepCount % print_every == 0) {\n",
    "                print(\"current loss at step \\(trainingStepCount): \\(loss)\")\n",
    "            }\n",
    "            trainingLossSum += loss\n",
    "            trainingBatchCount += 1\n",
    "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
    "            trainingStepCount += 1\n",
    "        }\n",
    "        print(\n",
    "            \"\"\"\n",
    "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
    "            \"\"\"\n",
    "        )\n",
    "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch+1, value: trainingLossSum / Float(trainingBatchCount))\n",
    "\n",
    "        if epoch == 0 {\n",
    "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
    "        }\n",
    "        Context.local.learningPhase = .inference\n",
    "        var devLossSum: Float = 0\n",
    "        var devBatchCount = 0\n",
    "        var totalGuessCount = 0\n",
    "\n",
    "        for eagerBatch in dataset.validationBatches {\n",
    "            let batch = LangMotionBatch(copying: eagerBatch, to: device)\n",
    "            let loss: Float = validate(model: &model, for: batch)\n",
    "            let valBatchSize = batch.targetMotionFrames.shape[0]\n",
    "\n",
    "            devLossSum += loss\n",
    "            devBatchCount += 1\n",
    "            totalGuessCount += valBatchSize\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            \"\"\"\n",
    "            totalGuessCount: \\(totalGuessCount) \\\n",
    "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
    "            \"\"\"\n",
    "        )\n",
    "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch+1, value: devLossSum / Float(devBatchCount))\n",
    "        greedyDecodeMotion(sentence: \"human is walking\", prefix: \"epoch_\\(epoch+1)\")\n",
    "    }\n",
    "    summaryWriter.flush()\n",
    "}\n",
    "\n",
    "print(\"\\nFinished training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODISB-IWBUof"
   },
   "source": [
    "## Generate motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1bbmqcOHBU_j"
   },
   "outputs": [],
   "source": [
    "// TODO: show motion inline\n",
    "greedyDecodeMotion(sentence: \"human is walking\", prefix: \"foo9\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TraningLang2motionColab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
