{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/notebooks/language2motion.gt\")\n",
      "\t\tDatasets\n",
      "\t\tModelSupport\n",
      "\t\tTextModels\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmpvqieush7/swift-install\n",
      "[1/2] Compiling Datasets ArrayUtils.swift\n",
      "[2/3] Compiling TextModels Attention.swift\n",
      "/notebooks/language2motion.gt/Sources/Models/Text/BERT.swift:776:32: warning: 'TensorFlowCheckpointReader' is deprecated: TensorFlowCheckpointReader will be removed in S4TF v0.11. Please use CheckpointReader from swift-models\n",
      "(https://github.com/tensorflow/swift-models/blob/master/Support/Checkpoints/CheckpointReader.swift)\n",
      "instead.\n",
      "        let checkpointReader = TensorFlowCheckpointReader(checkpointPath: fileURL.path)\n",
      "                               ^\n",
      "[3/4] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[4/4] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets ModelSupport TextModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import Foundation\n",
    "import Datasets\n",
    "import ModelSupport\n",
    "import TextModels\n",
    "import PythonKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "// %include \"EnableIPythonDisplay.swift\"\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "// IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "let datasetSize: DatasetSize = .mini\n",
    "\n",
    "let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "// motion_dataset2.10Hz.39728.plist\n",
    "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.10Hz.\\(datasetSize.rawValue)plist\")\n",
    "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "let batchSize = 4\n",
    "let maxTextSequenceLength =  20\n",
    "let maxMotionLength =  100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// instantiate text processor\n",
    "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "let textProcessor = TextProcessor2(vocabulary: vocabulary, tokenizer: tokenizer, maxTextSequenceLength: maxTextSequenceLength, maxMotionLength: maxMotionLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset...\n",
      "MotionDataset2(motionSamples: 1030)\n",
      "keeping 834 annotatated motions\n",
      "keeping 834 longer motions, with minimum 10 frames\n",
      "Scaling motions...\n",
      "Motions scaled.\n",
      "Dataset acquired.\n"
     ]
    }
   ],
   "source": [
    "/// load dataset\n",
    "print(\"\\nLoading dataset...\")\n",
    "\n",
    "var dataset = try Lang2Motion(\n",
    "    motionDatasetURL: motionDatasetURL,\n",
    "    langDatasetURL: langDatasetURL,\n",
    "    batchSize: batchSize\n",
    ") { (example: Lang2Motion.Example) -> LangMotionBatch in    \n",
    "    let singleBatch = textProcessor.preprocess(example: example)\n",
    "    return singleBatch\n",
    "}\n",
    "\n",
    "print(\"Dataset acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot motion sample"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "func plotMotionSample(motionSample: MotionSample, grouppedJoints: Bool) {\n",
    "    let position = motionSample.getJointPositions(grouppedJoints: grouppedJoints, normalized: true).makeNumpyArray()    \n",
    "    let x = plt.subplots()\n",
    "    let ax = x[1]\n",
    "    // cmaps: viridis, gist_rainbow, bwr, seismic, coolwarm, hsv, plasma*, PRGn, twilight_shifted, Spectral...\n",
    "    ax.imshow(position.T, interpolation: \"nearest\", extent: [0, 1, 0, 1], cmap: \"Spectral\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"\\(motionSample.describe()) \\(motionSample.annotations[0])\")\n",
    "\n",
    "    plt.show()\n",
    "}\n",
    "// plotMotionSample(motionSample: m186, grouppedJoints: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "let ms = dataset.motionDataset.motionSamples[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let motion = ms.motion.paddedAndCropped(to: maxMotionLength).motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Tensor where Scalar: NumpyScalarCompatible, Scalar: Numeric {\n",
    "    public func motionToImg(url: URL, padTo: Int = 500, descr: String) {\n",
    "        let motion = self.paddedAndCropped(to: padTo).motion\n",
    "        let x = plt.subplots()\n",
    "        let ax = x[1]\n",
    "        // cmaps: viridis, gist_rainbow, bwr, seismic, coolwarm, hsv, plasma*, PRGn, twilight_shifted, Spectral...\n",
    "        ax.imshow(motion.makeNumpyArray().T, extent: [0, padTo, 0, motion.shape[1]], cmap: \"Spectral\")\n",
    "        ax.set_title(\"\\(descr)\")\n",
    "        plt.savefig(url.path)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.motion.motionToImg2(url: dataURL.appendingPathComponent(\"motion_images/foo4.png\"), padTo: maxMotionLength, descr: \"\\(ms.description) \\(ms.annotations[0])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Tensor where Scalar: NumpyScalarCompatible, Scalar: Numeric {\n",
    "    public func paddedTo(padTo: Int = 500) -> Tensor {\n",
    "        let rank = self.shape.count\n",
    "        let currentWidth = self.shape[0]\n",
    "        let paddingSize = Swift.max(padTo - currentWidth, 0)\n",
    "        print(\"self.shape: \\(self.shape)\")\n",
    "        var sizes: [(before: Int, after: Int)] = [(before: 0, after: paddingSize)]\n",
    "        if rank > 1 {\n",
    "            sizes.append((before: 0, after: 0))\n",
    "        }        \n",
    "        let tensor = self.padded(forSizes: sizes, with: 0)\n",
    "        return tensor\n",
    "    }\n",
    "}\n",
    "\n",
    "public func motionToImg4(url: URL, motion: Tensor<Float>, motionFlag: Tensor<Int32>, padTo: Int = 500, descr: String = \"\") {\n",
    "    let currentWidth = motion.shape[0]\n",
    "    let paddingSize = Swift.max(padTo - currentWidth, 0)\n",
    "    let motion = motion.paddedTo(padTo: padTo)\n",
    "    let motionFlag = motionFlag.paddedTo(padTo: padTo)\n",
    "    print(\"motion.shape: \\(motion.shape)\")\n",
    "    print(\"motionFlag.shape: \\(motionFlag.shape)\")\n",
    "    print(\"max: \\(motion.max())\")\n",
    "    let motionFlag2 = Tensor<Float>(motionFlag).expandingShape(at: 1)*motion.max()\n",
    "    let joined = Tensor(concatenating: [motionFlag2, motion], alongAxis: 1)\n",
    "    print(\"joined.shape: \\(joined.shape)\")\n",
    "    \n",
    "    let x = plt.subplots()\n",
    "    let ax = x[1]\n",
    "    // cmaps: viridis, gist_rainbow, bwr, seismic, coolwarm, hsv, plasma*, PRGn, twilight_shifted, Spectral...\n",
    "    ax.imshow(joined.makeNumpyArray().T, extent: [0, padTo, 0, joined.shape[1]], cmap: \"Spectral\")\n",
    "    ax.set_title(\"\\(descr)\")\n",
    "    plt.savefig(url.path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.shape: [61, 47]\n",
      "self.shape: [55]\n",
      "motion.shape: [100, 47]\n",
      "motionFlag.shape: [100]\n",
      "max: 2.55286\n",
      "joined.shape: [100, 48]\n"
     ]
    }
   ],
   "source": [
    "var motionFlag = Tensor<Int32>(repeating: 1, shape: [55])\n",
    "motionToImg4(url: dataURL.appendingPathComponent(\"motion_images/foo7.png\"), \n",
    "             motion: ms.motion, motionFlag: motionFlag, padTo:maxMotionLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
