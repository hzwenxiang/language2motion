{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    },
    "colab": {
      "name": "Train Motion2lang.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOiO12PtN-LD",
        "colab_type": "text"
      },
      "source": [
        "# Train Transformer for the Motion2lang task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEwgnAxOYNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "5db43212-b676-4414-f1e3-722f826e6031"
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"koszalin-dl-9\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"koszalin-dl-9\"))\n",
            "\t\tDatasets\n",
            "\t\tTranslationModels\n",
            "\t\tTextModels\n",
            "\t\tModelSupport\n",
            "\t\tSummaryWriter\n",
            "\t\tMotionModels\n",
            "With SwiftPM flags: ['-c', 'release']\n",
            "Working in: /tmp/tmp7785pfzo/swift-install\n",
            "Fetching https://github.com/wojtekcz/language2motion.git\n",
            "Fetching https://github.com/apple/swift-protobuf.git\n",
            "Cloning https://github.com/apple/swift-protobuf.git\n",
            "Resolving https://github.com/apple/swift-protobuf.git at 1.10.2\n",
            "Cloning https://github.com/wojtekcz/language2motion.git\n",
            "Resolving https://github.com/wojtekcz/language2motion.git at koszalin-dl-9\n",
            "[1/5] Compiling SummaryWriter SummaryWriter.swift\n",
            "[2/6] Compiling ImageClassificationModels ResNet-extractFeatures.swift\n",
            "[3/7] Compiling Batcher Backend.swift\n",
            "[4/7] Compiling STBImage stb_image_write.c\n",
            "[5/7] Compiling STBImage stb_image.c\n",
            "[6/7] Compiling SwiftProtobuf AnyMessageStorage.swift\n",
            "[7/8] Compiling ModelSupport BijectiveDictionary.swift\n",
            "[8/9] Compiling Datasets ArrayUtils.swift\n",
            "[9/11] Compiling TranslationModels Attention.swift\n",
            "[10/11] Compiling TextModels Attention.swift\n",
            "/content/swift-install/package/.build/checkouts/language2motion/Sources/Models/Text/BERT.swift:776:32: warning: 'TensorFlowCheckpointReader' is deprecated: TensorFlowCheckpointReader will be removed in S4TF v0.11. Please use CheckpointReader from swift-models\n",
            "(https://github.com/tensorflow/swift-models/blob/master/Support/Checkpoints/CheckpointReader.swift)\n",
            "instead.\n",
            "        let checkpointReader = TensorFlowCheckpointReader(checkpointPath: fileURL.path)\n",
            "                               ^\n",
            "[11/12] Compiling MotionModels DenseMotionClassifier.swift\n",
            "[12/13] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[13/13] Linking libjupyterInstalledPackages.so\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3X_ngFaN-LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// for local development\n",
        "// %install-location /notebooks/language2motion.gt/swift-install\n",
        "// %install-swiftpm-flags -c release\n",
        "// %install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YCslW2KN-LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import MotionModels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxIOsZLRUTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a413bd10-4abb-40ef-b06d-4df7c24a2e0f"
      },
      "source": [
        "import Foundation\n",
        "\n",
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}\n",
        "\n",
        "sh(\"\"\"\n",
        "export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
        "export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
        "nvidia-smi\n",
        "\"\"\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul 11 21:09:35 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
            "|                               |                      |                 ERR! |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDtBlXnRaT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d2563ac-ed03-4da4-da26-7d87382f4460"
      },
      "source": [
        "sh(\"mkdir -p /content/data/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.2.0/motion_dataset_v3.norm.10Hz.tgz\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.balanced.515.csv\n",
        "tar xzvf motion_dataset_v3.norm.10Hz.tgz\n",
        "\"\"\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "--2020-07-11 21:09:35--  https://github.com/wojtekcz/language2motion/releases/download/v0.2.0/motion_dataset_v3.norm.10Hz.tgz\r\n",
            "Resolving github.com (github.com)... 140.82.118.3\r\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/0c5c8700-b172-11ea-97ff-87f806ccfe78?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210935Z&X-Amz-Expires=300&X-Amz-Signature=e75a926cdfb357d8d3a0dd7698af321956bfa08d24673a6281869eda40b1bcd1&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.norm.10Hz.tgz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-11 21:09:35--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/0c5c8700-b172-11ea-97ff-87f806ccfe78?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210935Z&X-Amz-Expires=300&X-Amz-Signature=e75a926cdfb357d8d3a0dd7698af321956bfa08d24673a6281869eda40b1bcd1&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.norm.10Hz.tgz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.113.75\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.113.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 628051485 (599M) [application/octet-stream]\n",
            "Saving to: ‘motion_dataset_v3.norm.10Hz.tgz’\n",
            "\n",
            "motion_dataset_v3.n 100%[===================>] 598.96M  32.4MB/s    in 19s     \n",
            "\n",
            "2020-07-11 21:09:55 (30.9 MB/s) - ‘motion_dataset_v3.norm.10Hz.tgz’ saved [628051485/628051485]\n",
            "\n",
            "--2020-07-11 21:09:55--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/16bcbb80-95dd-11ea-8fed-886381d8bee7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210955Z&X-Amz-Expires=300&X-Amz-Signature=970206d40a6bee48406cbcf4b8ec6fa1c7a80ec298b900a65e5663598269c7af&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-11 21:09:55--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/16bcbb80-95dd-11ea-8fed-886381d8bee7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210955Z&X-Amz-Expires=300&X-Amz-Signature=970206d40a6bee48406cbcf4b8ec6fa1c7a80ec298b900a65e5663598269c7af&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.185.139\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.185.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 297583 (291K) [application/octet-stream]\n",
            "Saving to: ‘labels_ds_v2.csv’\n",
            "\n",
            "labels_ds_v2.csv    100%[===================>] 290.61K   784KB/s    in 0.4s    \n",
            "\n",
            "2020-07-11 21:09:56 (784 KB/s) - ‘labels_ds_v2.csv’ saved [297583/297583]\n",
            "\n",
            "--2020-07-11 21:09:56--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210956Z&X-Amz-Expires=300&X-Amz-Signature=3efe9d384eb7fa0410e951a09fffd46b6ac73d7fe7000054b963db3176e79663&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-11 21:09:56--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210956Z&X-Amz-Expires=300&X-Amz-Signature=3efe9d384eb7fa0410e951a09fffd46b6ac73d7fe7000054b963db3176e79663&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.185.139\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.185.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [application/octet-stream]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 226.08K   804KB/s    in 0.3s    \n",
            "\n",
            "2020-07-11 21:09:57 (804 KB/s) - ‘vocab.txt’ saved [231508/231508]\n",
            "\n",
            "--2020-07-11 21:09:57--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.balanced.515.csv\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/7839b800-af04-11ea-890c-7c71276a6df8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210957Z&X-Amz-Expires=300&X-Amz-Signature=abe3a65c9cf96a4d2dfe4db8d92e33212ad5d02f605d316d3ca462a4732601b4&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.balanced.515.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-11 21:09:57--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/7839b800-af04-11ea-890c-7c71276a6df8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200711%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200711T210957Z&X-Amz-Expires=300&X-Amz-Signature=abe3a65c9cf96a4d2dfe4db8d92e33212ad5d02f605d316d3ca462a4732601b4&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.balanced.515.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.185.139\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.185.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50537 (49K) [application/octet-stream]\n",
            "Saving to: ‘labels_ds_v2.balanced.515.csv’\n",
            "\n",
            "labels_ds_v2.balanc 100%[===================>]  49.35K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-07-11 21:09:58 (532 KB/s) - ‘labels_ds_v2.balanced.515.csv’ saved [50537/50537]\n",
            "\n",
            "motion_dataset_v3.norm.10Hz.plist\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbmXosmTN-LM",
        "colab_type": "text"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sum7wmL6N-LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bcfda561-59b6-4230-a6da-4330db802b78"
      },
      "source": [
        "let runName = \"run_1\"\n",
        "let batchSize = 6000\n",
        "// let batchSize = 3000\n",
        "let maxSequenceLength =  50\n",
        "let nEpochs = 1\n",
        "// let learningRate: Float = 2e-5\n",
        "let learningRate: Float = 5e-4\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxSequenceLength: \\(maxSequenceLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"learningRate: \\(learningRate)\")\n",
        "\n",
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.norm.10Hz.plist\")\n",
        "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runName: run_1\r\n",
            "batchSize: 6000\r\n",
            "maxSequenceLength: 50\r\n",
            "nEpochs: 1\r\n",
            "learningRate: 0.0005\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHyhFi49N-LP",
        "colab_type": "text"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUyfo7oZN-LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "9696ec7a-ed5f-423b-d159-2c7165c2f6ce"
      },
      "source": [
        "let device = Device.defaultXLA\n",
        "// let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-11 21:12:25.750092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-11 21:12:25.851913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:25.852481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-07-11 21:12:25.866757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-11 21:12:28.533113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-11 21:12:32.490273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-11 21:12:34.094958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-11 21:12:39.144284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-11 21:12:39.226401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-11 21:12:51.517377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-11 21:12:51.517512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:51.518138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:51.518621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-11 21:12:51.521319: I tensorflow/compiler/xla/xla_client/xrt_local_service.cc:54] Peer localservice 1 {localhost:30841}\n",
            "2020-07-11 21:12:51.525841: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "2020-07-11 21:12:51.560171: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2000165000 Hz\n",
            "2020-07-11 21:12:51.560691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x151ca60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-11 21:12:51.560719: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-11 21:12:51.564949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:51.565533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n",
            "2020-07-11 21:12:51.565594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-11 21:12:51.565613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-11 21:12:51.565634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-11 21:12:51.565651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-11 21:12:51.565665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-11 21:12:51.565678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-11 21:12:51.565692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-11 21:12:51.565746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:51.566273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:12:51.566768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-07-11 21:13:00.128221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-11 21:13:00.128263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-07-11 21:13:00.128273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-07-11 21:13:00.128414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:13:00.129031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:13:00.129553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-11 21:13:00.130050: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-11 21:13:00.130092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localservice/replica:0/task:0/device:GPU:0 with 14960 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "2020-07-11 21:13:00.132193: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x125b9230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-11 21:13:00.132223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-07-11 21:13:00.161135: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localservice -> {0 -> localhost:30841}\n",
            "2020-07-11 21:13:00.162493: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:30841\n",
            "Device(kind: .GPU, ordinal: 0, backend: .XLA)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZrpeweN-LS",
        "colab_type": "text"
      },
      "source": [
        "## X10 warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX4GecfN-LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a51f7e50-100a-4554-9cfe-081483b209b2"
      },
      "source": [
        "let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "print(eagerTensorSum)\n",
        "print(eagerTensor1.device)\n",
        "let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "print(x10Tensor2.device)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-11 21:13:00.951929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-11 21:13:00.952902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\n",
            "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\r\n",
            "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\r\n",
            "2020-07-11 21:13:00.952985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
            "2020-07-11 21:13:00.953008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n",
            "2020-07-11 21:13:00.953028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n",
            "2020-07-11 21:13:00.953045: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n",
            "2020-07-11 21:13:00.953061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n",
            "2020-07-11 21:13:00.953078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n",
            "2020-07-11 21:13:00.953093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n",
            "2020-07-11 21:13:00.953820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-11 21:13:00.955904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-11 21:13:00.958186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n",
            "2020-07-11 21:13:00.959154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
            "2020-07-11 21:13:00.959199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n",
            "2020-07-11 21:13:00.959222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n",
            "2020-07-11 21:13:00.959511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-11 21:13:00.960080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-11 21:13:00.960578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14960 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\r\n",
            "[1.5, 3.5, 5.5]\r\n",
            "Device(kind: .CPU, ordinal: 0, backend: .TF_EAGER)\r\n",
            "Device(kind: .GPU, ordinal: 0, backend: .XLA)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHwl5J2LN-LV",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp5-Mh2TN-LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// instantiate text processor\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer, maxSequenceLength: maxSequenceLength)\n",
        "\n",
        "// instantiate model\n",
        "let sourceVocabSize = vocabulary.count\n",
        "let inputSize = 48 // TODO: get value from dataset\n",
        "let targetVocabSize = vocabulary.count\n",
        "let layerCount: Int = 6\n",
        "let modelSize: Int = 256\n",
        "let feedForwardSize: Int = 1024\n",
        "let headCount: Int = 8\n",
        "let dropoutProbability: Double = 0.1\n",
        "\n",
        "var model = MotionLangTransformer(\n",
        "    sourceVocabSize: sourceVocabSize, \n",
        "    inputSize: inputSize,\n",
        "    targetVocabSize: targetVocabSize,\n",
        "    layerCount: layerCount, \n",
        "    modelSize: modelSize, \n",
        "    feedForwardSize: feedForwardSize, \n",
        "    headCount: headCount, \n",
        "    dropoutProbability: dropoutProbability\n",
        ")\n",
        "\n",
        "model.move(to: device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysEn7gicN-LZ",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFwP-zu-N-LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4ef4ea52-0064-4e8f-9651-ddd75adc539a"
      },
      "source": [
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Motion2Lang(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    langDatasetURL: langDatasetURL,\n",
        "    maxSequenceLength: maxSequenceLength,\n",
        "    batchSize: batchSize\n",
        ") { (example: Motion2Lang.Example) -> MotionLangBatch in    \n",
        "    let singleBatch = textProcessor.preprocess(example: example)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Loading dataset...\n",
            "MotionDataset(motionSamples: 39102)\n",
            "keeping 30120 annotatated motions\n",
            "keeping 29970 longer motions, with minimum 10 frames\n",
            "Dataset acquired.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzeal8UdN-Lb",
        "colab_type": "text"
      },
      "source": [
        "## Check model on a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxIdHymZN-Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// get a batch\n",
        "// print(\"\\nOne batch (MotionLangBatch):\")\n",
        "// var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
        "// let epoch = epochIterator.next()\n",
        "// let batches = Array(epoch!.1)\n",
        "// let batch: MotionLangBatch = batches[0]\n",
        "// print(\"type: \\(type(of:batch))\")\n",
        "// print(\"motionFrames.shape: \\(batch.motionFrames.shape)\")\n",
        "// // print(\"motionFlag.shape: \\(batch.motionFlag.shape)\")\n",
        "// print(\"mask.shape: \\(batch.mask.shape)\")\n",
        "// print(\"origMotionFramesCount.shape: \\(batch.origMotionFramesCount.shape)\")\n",
        "// print(\"origMotionFramesCount: \\(batch.origMotionFramesCount)\")\n",
        "// print(\"targetTokenIds.shape: \\(batch.targetTokenIds.shape)\")\n",
        "// print(\"targetMask.shape: \\(batch.targetMask.shape)\")\n",
        "// print(\"targetTruth.shape: \\(batch.targetTruth.shape)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb3enWa55kr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// run one batch\n",
        "// print(\"\\nRun one batch:\")\n",
        "// print(\"==============\")\n",
        "// let deviceBatch = MotionLangBatch(copying: batch, to: device)\n",
        "// let output = model(deviceBatch)\n",
        "// print(\"output.shape: \\(output.shape)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGL_PkLMN-Lf",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jon3S7pPN-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var optimizer = Adam(for: model, learningRate: learningRate)\n",
        "optimizer = Adam(copying: optimizer, to: device)\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"tboard/Motion2lang/\\(runName)\", isDirectory: true)\n",
        "let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQGXiJB1N-Li",
        "colab_type": "text"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g22npgZN-Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func update(model: inout MotionLangTransformer, using optimizer: inout Adam<MotionLangTransformer>, for batch: MotionLangBatch) -> Float {\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    let padIndex = textProcessor.padId\n",
        "    let result = withLearningPhase(.training) { () -> Float in\n",
        "        let (loss, grad) = valueWithGradient(at: model) {\n",
        "            (model) -> Tensor<Float> in\n",
        "            let logits = model.generate(input: batch).reshaped(to: [resultSize, -1])\n",
        "            let sce = softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "            return sce\n",
        "        }\n",
        "        optimizer.update(&model, along: grad)\n",
        "        LazyTensorBarrier()\n",
        "        return loss.scalarized()\n",
        "    }\n",
        "    return result\n",
        "}\n",
        "\n",
        "/// returns validation loss\n",
        "func validate(model: inout MotionLangTransformer, for batch: MotionLangBatch) -> Float {\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    let padIndex = textProcessor.padId\n",
        "    let result = withLearningPhase(.inference) { () -> Float in\n",
        "        softmaxCrossEntropy(logits: model.generate(input: batch).reshaped(to: [resultSize, -1]), labels: labels).scalarized()\n",
        "    }\n",
        "    LazyTensorBarrier()\n",
        "    return result\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr2TXD10N-Lk",
        "colab_type": "text"
      },
      "source": [
        "## setup decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWM7srrpN-Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func greedyDecode(model: MotionLangTransformer, input: MotionLangBatch, maxLength: Int, startSymbol: Int32) -> Tensor<Int32> {\n",
        "    let memory = model.encode(input: input)\n",
        "    var ys = Tensor(repeating: startSymbol, shape: [1,1])\n",
        "    // ys = Tensor(copying: ys, to: device)\n",
        "    for _ in 0..<maxLength {\n",
        "        let decoderInput = MotionLangBatch(motionFrames: input.motionFrames,\n",
        "                                     mask: input.mask,\n",
        "                                     origMotionFramesCount: input.origMotionFramesCount,\n",
        "                                     targetTokenIds: ys,\n",
        "                                     targetMask: Tensor<Float>(subsequentMask(size: ys.shape[1])),\n",
        "                                     targetTruth: input.targetTruth)\n",
        "        // decoderInput = MotionLangBatch(copying: decoderInput, to: device)\n",
        "        let out = model.decode(input: decoderInput, memory: memory)\n",
        "        let prob = model.generate(input: out[0...,-1])\n",
        "        let nextWord = Int32(prob.argmax().scalarized())\n",
        "        ys = Tensor(concatenating: [ys, Tensor(repeating: nextWord, shape: [1,1])], alongAxis: 1) // , on: device\n",
        "        // ys = Tensor(copying: ys, to: device)\n",
        "    }\n",
        "    return ys\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s73XJlq5U7NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c5009767-df94-4203-dc25-5cfb8cf77e23"
      },
      "source": [
        "// get example\n",
        "let example = dataset.trainExamples[0]\n",
        "print(\"example.id: \\(example.id)\")\n",
        "print(\"example.motionSample.timestepsArray.last: \\(example.motionSample.timestepsArray.last!)\")\n",
        "print(\"example.motionSample.motionFramesArray.shape: \\(example.motionSample.motionFramesArray.shape)\")\n",
        "print(\"example.targetSentence: \\(example.targetSentence)\")\n",
        "\n",
        "let singleExampleBatch = textProcessor.preprocess(example: example)\n",
        "var source = Motion2Lang.reduceDataBatches([singleExampleBatch])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example.id: 3311\r\n",
            "example.motionSample.timestepsArray.last: 24.6667\r\n",
            "example.motionSample.motionFramesArray.shape: [297, 48]\r\n",
            "example.targetSentence: A person is dancing and making backflips.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4T4N8xN-Lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ab523262-892f-4330-d92d-cbfaed0587ba"
      },
      "source": [
        "var outputStr = textProcessor.decode(tensor: source.targetTokenIds)\n",
        "print(\"decode(source.targetTokenIds): \\(outputStr)\")\n",
        "\n",
        "Context.local.learningPhase = .inference\n",
        "source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "model.move(to: Device.defaultTFEager)\n",
        "let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "outputStr = textProcessor.decode(tensor: out)\n",
        "print(\"greedyDecode(): \\\"\\(outputStr)\\\"\")\n",
        "model.move(to: device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decode(source.targetTokenIds): [CLS] a person is dancing and making back ##fl ##ip ##s .\n",
            "2020-07-11 21:14:01.202886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "greedyDecode(): \"[CLS] joan joan joan joan joan joan joan joan joan joan joan joan joan joan joan joan joan garlic garlic կ կ կ կ կ կ joan joan joan joan կ կ կ կ joan joan joan joan joan joan joan joan joan joan joan կ կ կ կ կ կ\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22deJipJN-Lr",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPJMsdTN-Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "8308569a-871f-4a94-f49b-22f683cbc85d"
      },
      "source": [
        "print(\"\\nTraining Transformer for the Motion2lang task!\")\n",
        "var trainingStepCount = 0\n",
        "time() {\n",
        "    LazyTensorBarrier()\n",
        "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(nEpochs).enumerated() {\n",
        "        print(\"[Epoch \\(epoch + 1)]\")\n",
        "        Context.local.learningPhase = .training\n",
        "        var trainingLossSum: Float = 0\n",
        "        var trainingBatchCount = 0\n",
        "        if epoch == 0 {\n",
        "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
        "        }\n",
        "\n",
        "        for eagerBatch in epochBatches {\n",
        "            if (trainingStepCount < 5) {\n",
        "                print(\"==> step \\(trainingStepCount)\")\n",
        "            }\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = update(model: &model, using: &optimizer, for: batch)\n",
        "            if (trainingStepCount < 5) {\n",
        "                print(\"current loss at step \\(trainingStepCount): \\(loss)\")\n",
        "            }\n",
        "            trainingLossSum += loss\n",
        "            trainingBatchCount += 1\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
        "            trainingStepCount += 1\n",
        "        }\n",
        "        print(\n",
        "            \"\"\"\n",
        "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch+1, value: trainingLossSum / Float(trainingBatchCount))\n",
        "\n",
        "        if epoch == 0 {\n",
        "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
        "        }\n",
        "        Context.local.learningPhase = .inference\n",
        "        var devLossSum: Float = 0\n",
        "        var devBatchCount = 0\n",
        "        var totalGuessCount = 0\n",
        "\n",
        "        for eagerBatch in dataset.validationBatches {\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = validate(model: &model, for: batch)\n",
        "            let valBatchSize = batch.motionFrames.shape[0]\n",
        "\n",
        "            devLossSum += loss\n",
        "            devBatchCount += 1\n",
        "            totalGuessCount += valBatchSize\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            \"\"\"\n",
        "            totalGuessCount: \\(totalGuessCount) \\\n",
        "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch+1, value: devLossSum / Float(devBatchCount))\n",
        "\n",
        "        print(\"\\nEncoding/decoding one example\") // on eager device\n",
        "        Context.local.learningPhase = .inference\n",
        "        source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "        model.move(to: Device.defaultTFEager)\n",
        "        let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "        outputStr = textProcessor.decode(tensor: out)\n",
        "        print(\"greedyDecode(): \\\"\\(outputStr)\\\"\")\n",
        "        model.move(to: device)\n",
        "    }\n",
        "    summaryWriter.flush()\n",
        "}\n",
        "\n",
        "\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Training Transformer for the Motion2lang task!\n",
            "[Epoch 1]\n",
            "epochBatches.count: 199\n",
            "==> step 0\n",
            "current loss at step 0: 0.30599204\n",
            "==> step 1\n",
            "current loss at step 1: 0.38141268\n",
            "==> step 2\n",
            "current loss at step 2: 0.34376034\n",
            "==> step 3\n",
            "current loss at step 3: 0.32518402\n",
            "==> step 4\n",
            "current loss at step 4: 0.30158445\n",
            "Training loss: 0.30939233\n",
            "dataset.validationBatches.count: 50\n",
            "totalGuessCount: 5990 Eval loss: 0.5096631\n",
            "\n",
            "Encoding/decoding one example\n",
            "greedyDecode(): \"[CLS] person is is is is is is is is is is is is is is is is is [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"\n",
            "average: 182485.243758 ms,   min: 182485.243758 ms,   max: 182485.243758 ms\n",
            "\n",
            "Finished training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NRg5U_N-Lt",
        "colab_type": "text"
      },
      "source": [
        "## Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzOLXpBuy8A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct LangRec {\n",
        "    let sampleID: Int\n",
        "    let text: String\n",
        "    let label: String\n",
        "}\n",
        "\n",
        "func transformDF(df: PythonObject) -> [LangRec] {\n",
        "    return Python.list(df.iterrows()).map {\n",
        "        (rowObj: PythonObject) -> LangRec in \n",
        "        let row = rowObj.tuple2.1\n",
        "        let sample_id: Int = Int(row.sample_id)!\n",
        "        let text: String = String(row.text)!\n",
        "        let label: String = String(row.label)!\n",
        "        return LangRec(sampleID: sample_id, text: text, label: label)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWxrCbuJxEZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import PythonKit\n",
        "let pd = Python.import(\"pandas\")\n",
        "\n",
        "let df = pd.read_csv(langDatasetURL.path)\n",
        "\n",
        "// create LangRecs\n",
        "let langRecs = transformDF(df: df)\n",
        "\n",
        "// [sampleID:LangRec] mapping\n",
        "var _langRecsDict: [Int: LangRec] = [:]\n",
        "for langRec in langRecs {\n",
        "    _langRecsDict[langRec.sampleID] = langRec\n",
        "}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEbgpgdJyHKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// [sampleID:MotionSample] mapping\n",
        "var _motionSampleDict: [Int: MotionSample] = [:]\n",
        "for ms in dataset.motionDataset.motionSamples {\n",
        "    _motionSampleDict[ms.sampleID] = ms\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlNdTGwD0B0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func getExample(motionSample: MotionSample, langRec: LangRec) -> Motion2Lang.Example {\n",
        "    let sample_id: String = \"\\(langRec.sampleID)\" // Int to String\n",
        "    return Motion2Lang.Example(id: sample_id, motionSample: motionSample, targetSentence: langRec.text)\n",
        "}"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUoXa70uzoTL",
        "colab_type": "text"
      },
      "source": [
        "## Generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2XXZEupyHHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func greedyDecodeSample(_ sample_id: Int) {\n",
        "    // get example\n",
        "    let ms = _motionSampleDict[sample_id]!\n",
        "    let langRec = _langRecsDict[sample_id]!\n",
        "    let example = getExample(motionSample: ms, langRec: langRec)\n",
        "    print(\"example.id: \\(example.id)\")\n",
        "    print(\"example.motionSample.timestepsArray.last: \\(example.motionSample.timestepsArray.last!)\")\n",
        "    print(\"example.motionSample.motionFramesArray.shape: \\(example.motionSample.motionFramesArray.shape)\")\n",
        "    print(\"example.targetSentence: \\(example.targetSentence)\")\n",
        "\n",
        "    let singleExampleBatch = textProcessor.preprocess(example: example)\n",
        "    var source = Motion2Lang.reduceDataBatches([singleExampleBatch])\n",
        "    print(\"\\nEncoding/decoding one example\") // on eager device\n",
        "    Context.local.learningPhase = .inference\n",
        "    source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "    model.move(to: Device.defaultTFEager)\n",
        "    let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "    outputStr = textProcessor.decode(tensor: out)\n",
        "    print(\"greedyDecode(): \\\"\\(outputStr)\\\"\")\n",
        "    model.move(to: device)\n",
        "}"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMY-iAwaN-Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1c460f23-ef96-4a7a-d583-b0814670489a"
      },
      "source": [
        "let sample_id = 446\n",
        "greedyDecodeSample(sample_id)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example.id: 446\r\n",
            "example.motionSample.timestepsArray.last: 4.69\r\n",
            "example.motionSample.motionFramesArray.shape: [47, 48]\r\n",
            "example.targetSentence: A person runs and stops.\n",
            "\n",
            "Encoding/decoding one example\n",
            "greedyDecode(): \"[CLS] person is is is is is is is is is is is is is is is is is [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_M2Jjz5wBn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}