{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    },
    "colab": {
      "name": "Train Motion2lang.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOiO12PtN-LD",
        "colab_type": "text"
      },
      "source": [
        "# Train Motion 2 language transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEwgnAxOYNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "42c8bdd7-d812-472e-c074-2c58951c7098"
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"koszalin-dl-9\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"koszalin-dl-9\"))\n",
            "\t\tDatasets\n",
            "\t\tTranslationModels\n",
            "\t\tTextModels\n",
            "\t\tModelSupport\n",
            "\t\tSummaryWriter\n",
            "\t\tMotionModels\n",
            "With SwiftPM flags: ['-c', 'release']\n",
            "Working in: /tmp/tmp3kgfolc1/swift-install\n",
            "Fetching https://github.com/wojtekcz/language2motion.git\n",
            "Fetching https://github.com/apple/swift-protobuf.git\n",
            "Cloning https://github.com/wojtekcz/language2motion.git\n",
            "Resolving https://github.com/wojtekcz/language2motion.git at koszalin-dl-9\n",
            "Cloning https://github.com/apple/swift-protobuf.git\n",
            "Resolving https://github.com/apple/swift-protobuf.git at 1.10.0\n",
            "[1/5] Compiling SummaryWriter SummaryWriter.swift\n",
            "[2/6] Compiling ImageClassificationModels ResNet-extractFeatures.swift\n",
            "[3/7] Compiling Batcher Backend.swift\n",
            "[4/7] Compiling STBImage stb_image_write.c\n",
            "[5/7] Compiling STBImage stb_image.c\n",
            "[6/7] Compiling SwiftProtobuf AnyMessageStorage.swift\n",
            "[7/8] Compiling ModelSupport BijectiveDictionary.swift\n",
            "[8/9] Compiling Datasets ArrayUtils.swift\n",
            "[9/11] Compiling TranslationModels Attention.swift\n",
            "[10/11] Compiling TextModels Attention.swift\n",
            "/content/swift-install/package/.build/checkouts/language2motion/Sources/Models/Text/BERT.swift:776:32: warning: 'TensorFlowCheckpointReader' is deprecated: TensorFlowCheckpointReader will be removed in S4TF v0.11. Please use CheckpointReader from swift-models\n",
            "(https://github.com/tensorflow/swift-models/blob/master/Support/Checkpoints/CheckpointReader.swift)\n",
            "instead.\n",
            "        let checkpointReader = TensorFlowCheckpointReader(checkpointPath: fileURL.path)\n",
            "                               ^\n",
            "[11/12] Compiling MotionModels DenseMotionClassifier.swift\n",
            "[12/13] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[13/13] Linking libjupyterInstalledPackages.so\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3X_ngFaN-LF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "d15968aa-1202-4cae-c6ab-cd341020acfd"
      },
      "source": [
        "// for local development\n",
        "%install-location /notebooks/language2motion.gt/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(path: \"/notebooks/language2motion.gt\")' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(path: \"/notebooks/language2motion.gt\")\n",
            "\t\tDatasets\n",
            "\t\tTranslationModels\n",
            "\t\tTextModels\n",
            "\t\tModelSupport\n",
            "\t\tSummaryWriter\n",
            "\t\tMotionModels\n",
            "With SwiftPM flags: ['-c', 'release']\n",
            "Working in: /tmp/tmp3kgfolc1/swift-install\n",
            "error: /notebooks/language2motion.gt has no Package.swift manifest\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "Install Error: swift-build returned nonzero exit code 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YCslW2KN-LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import MotionModels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxIOsZLRUTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4d19ff33-d4bf-4559-9350-1c0370312bfa"
      },
      "source": [
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}\n",
        "\n",
        "sh(\"\"\"\n",
        "export PATH=\"$PATH:/opt/bin:/swift/toolchain/usr/bin\"\n",
        "export LD_LIBRARY_PATH=\"/usr/lib64-nvidia:$LD_LIBRARY_PATH\"\n",
        "nvidia-smi\n",
        "\"\"\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul  3 15:22:28 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   50C    P0    28W /  70W |    245MiB / 15079MiB |      0%      Default |\r\n",
            "|                               |                      |                 ERR! |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyCB7_WsTKBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "a47141f7-51ff-44f2-fde1-05a490bff58a"
      },
      "source": [
        "sh(\"ls -l /\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8064\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 26 16:19 bin\r\n",
            "drwxr-xr-x   2 root root    4096 Apr 24  2018 boot\r\n",
            "drwxr-xr-x   1 root root    4096 Jul  3 15:27 content\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 30 16:17 datalab\r\n",
            "drwxr-xr-x   5 root root     440 Jul  3 15:07 dev\r\n",
            "-rw-r--r--   1 root root 4078115 Jun 26 16:27 dlib-19.18.0-cp27-cp27mu-linux_x86_64.whl\r\n",
            "-rw-r--r--   1 root root 4068717 Jun 26 16:27 dlib-19.18.0-cp36-cp36m-linux_x86_64.whl\r\n",
            "drwxr-xr-x   1 root root    4096 Jul  3 15:07 etc\r\n",
            "drwxr-xr-x   2 root root    4096 Apr 24  2018 home\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 26 16:21 lib\r\n",
            "drwxr-xr-x   2 root root    4096 Jun 26 16:14 lib32\r\n",
            "drwxr-xr-x   2 root root    4096 Oct 29  2019 lib64\r\n",
            "drwxr-xr-x   2 root root    4096 Oct 29  2019 media\r\n",
            "drwxr-xr-x   2 root root    4096 Oct 29  2019 mnt\r\n",
            "drwxr-xr-x   3 root root    4096 Jul  3 15:27 notebooks\r\n",
            "drwxr-xr-x   1 root root    4096 Jul  3 15:07 opt\r\n",
            "dr-xr-xr-x 130 root root       0 Jul  3 15:07 proc\r\n",
            "drwx------   1 root root    4096 Jul  3 15:27 root\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 26 16:16 run\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 26 16:19 sbin\r\n",
            "drwxr-xr-x   2 root root    4096 Oct 29  2019 srv\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 26 16:55 swift\r\n",
            "dr-xr-xr-x  12 root root       0 Jul  3 15:07 sys\r\n",
            "drwxr-xr-x   4 root root    4096 Jun 26 16:51 tensorflow-1.15.2\r\n",
            "drwxrwxrwt   1 root root    4096 Jul  3 15:32 tmp\r\n",
            "drwxr-xr-x   1 root root    4096 Jun 30 16:17 tools\r\n",
            "drwxr-xr-x   1 root root    4096 Jul  3 15:07 usr\r\n",
            "drwxr-xr-x   1 root root    4096 Jul  3 15:07 var\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDtBlXnRaT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c803a7fc-9e8a-47e7-a528-1f3102927ead"
      },
      "source": [
        "sh(\"mkdir -p /content/data/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.2.0/motion_dataset_v3.norm.10Hz.tgz\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "wget https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.balanced.515.csv\n",
        "tar xzvf motion_dataset_v3.norm.10Hz.tgz\n",
        "\"\"\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "--2020-07-03 15:35:13--  https://github.com/wojtekcz/language2motion/releases/download/v0.2.0/motion_dataset_v3.norm.10Hz.tgz\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/0c5c8700-b172-11ea-97ff-87f806ccfe78?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153431Z&X-Amz-Expires=300&X-Amz-Signature=925492caad3878e919c47d19623089c15da2ca5d89d07e672a7f9d88366b3e3b&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.norm.10Hz.tgz&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-03 15:35:14--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/0c5c8700-b172-11ea-97ff-87f806ccfe78?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153431Z&X-Amz-Expires=300&X-Amz-Signature=925492caad3878e919c47d19623089c15da2ca5d89d07e672a7f9d88366b3e3b&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.norm.10Hz.tgz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.24.196\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.24.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 628051485 (599M) [application/octet-stream]\n",
            "Saving to: ‘motion_dataset_v3.norm.10Hz.tgz’\n",
            "\n",
            "motion_dataset_v3.n 100%[===================>] 598.96M  31.0MB/s    in 20s     \n",
            "\n",
            "2020-07-03 15:35:34 (29.4 MB/s) - ‘motion_dataset_v3.norm.10Hz.tgz’ saved [628051485/628051485]\n",
            "\n",
            "--2020-07-03 15:35:34--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/16bcbb80-95dd-11ea-8fed-886381d8bee7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153451Z&X-Amz-Expires=300&X-Amz-Signature=500fb15e1595885159827a498633481c90d5ec867bf6d9a77c6172a78f8b726f&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-03 15:35:34--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/16bcbb80-95dd-11ea-8fed-886381d8bee7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153451Z&X-Amz-Expires=300&X-Amz-Signature=500fb15e1595885159827a498633481c90d5ec867bf6d9a77c6172a78f8b726f&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.145.99\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.145.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 297583 (291K) [application/octet-stream]\n",
            "Saving to: ‘labels_ds_v2.csv’\n",
            "\n",
            "labels_ds_v2.csv    100%[===================>] 290.61K   775KB/s    in 0.4s    \n",
            "\n",
            "2020-07-03 15:35:35 (775 KB/s) - ‘labels_ds_v2.csv’ saved [297583/297583]\n",
            "\n",
            "--2020-07-03 15:35:35--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153452Z&X-Amz-Expires=300&X-Amz-Signature=e28d51732344e6b739c266437108e09be7b7e7aaea3630f78b2f14588f20b39d&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-03 15:35:35--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153452Z&X-Amz-Expires=300&X-Amz-Signature=e28d51732344e6b739c266437108e09be7b7e7aaea3630f78b2f14588f20b39d&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.145.99\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.145.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [application/octet-stream]\n",
            "Saving to: ‘vocab.txt’\n",
            "\n",
            "vocab.txt           100%[===================>] 226.08K   802KB/s    in 0.3s    \n",
            "\n",
            "2020-07-03 15:35:36 (802 KB/s) - ‘vocab.txt’ saved [231508/231508]\n",
            "\n",
            "--2020-07-03 15:35:36--  https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.balanced.515.csv\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/7839b800-af04-11ea-890c-7c71276a6df8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153453Z&X-Amz-Expires=300&X-Amz-Signature=a2922b56d544d285ef180bda9f3e08b1334817f8efecb80c89280c168b99ecb5&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.balanced.515.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-07-03 15:35:36--  https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/7839b800-af04-11ea-890c-7c71276a6df8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200703T153453Z&X-Amz-Expires=300&X-Amz-Signature=a2922b56d544d285ef180bda9f3e08b1334817f8efecb80c89280c168b99ecb5&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.balanced.515.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.145.99\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.145.99|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50537 (49K) [application/octet-stream]\n",
            "Saving to: ‘labels_ds_v2.balanced.515.csv’\n",
            "\n",
            "labels_ds_v2.balanc 100%[===================>]  49.35K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2020-07-03 15:35:36 (527 KB/s) - ‘labels_ds_v2.balanced.515.csv’ saved [50537/50537]\n",
            "\n",
            "motion_dataset_v3.norm.10Hz.plist\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbmXosmTN-LM",
        "colab_type": "text"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sum7wmL6N-LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4bfa86c7-9ea0-4511-9788-b717a643eae7"
      },
      "source": [
        "let runName = \"run_1\"\n",
        "// let batchSize = 6000\n",
        "// let batchSize = 3000\n",
        "let batchSize = 200\n",
        "let maxSequenceLength =  50\n",
        "let nEpochs = 40\n",
        "// let learningRate: Float = 2e-5\n",
        "let learningRate: Float = 5e-4\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxSequenceLength: \\(maxSequenceLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"learningRate: \\(learningRate)\")\n",
        "\n",
        "// let dataURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset_v3.norm.10Hz.plist\")\n",
        "// let motionDatasetURL = dataURL.appendingPathComponent(\"motion_dataset.motion_flag.normalized.downsampled.sampled.490.plist\")\n",
        "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runName: run_1\r\n",
            "batchSize: 200\r\n",
            "maxSequenceLength: 50\r\n",
            "nEpochs: 40\r\n",
            "learningRate: 0.0005\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHyhFi49N-LP",
        "colab_type": "text"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUyfo7oZN-LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c157db2-edd3-4300-c1e2-156a3c18a380"
      },
      "source": [
        "let device = Device.defaultXLA\n",
        "// let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device(kind: .GPU, ordinal: 0, backend: .XLA)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZrpeweN-LS",
        "colab_type": "text"
      },
      "source": [
        "## X10 warmup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX4GecfN-LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "6fb6b3eb-f091-4f2d-a0eb-34a809dd2f7d"
      },
      "source": [
        "/// X10 warmup\n",
        "let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "print(eagerTensorSum)\n",
        "print(eagerTensor1.device)\n",
        "let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "print(x10Tensor2.device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-03 15:21:05.004661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-03 15:21:05.005708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \r\n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\r\n",
            "2020-07-03 15:21:05.005845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n",
            "2020-07-03 15:21:05.005869: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n",
            "2020-07-03 15:21:05.005888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n",
            "2020-07-03 15:21:05.005902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n",
            "2020-07-03 15:21:05.005916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n",
            "2020-07-03 15:21:05.005932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n",
            "2020-07-03 15:21:05.005949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n",
            "2020-07-03 15:21:05.007999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-03 15:21:05.010239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-03 15:21:05.011950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n",
            "2020-07-03 15:21:05.011996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
            "2020-07-03 15:21:05.012013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \r\n",
            "2020-07-03 15:21:05.012026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \r\n",
            "2020-07-03 15:21:05.012201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-03 15:21:05.012779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
            "2020-07-03 15:21:05.013262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13947 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\n",
            "[1.5, 3.5, 5.5]\r\n",
            "Device(kind: .CPU, ordinal: 0, backend: .TF_EAGER)\r\n",
            "Device(kind: .GPU, ordinal: 0, backend: .XLA)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHwl5J2LN-LV",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp5-Mh2TN-LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// instantiate text processor\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer, maxSequenceLength: maxSequenceLength)\n",
        "\n",
        "// instantiate model\n",
        "let sourceVocabSize = vocabulary.count\n",
        "let inputSize = 48 // TODO: get value from dataset\n",
        "let targetVocabSize = vocabulary.count\n",
        "let layerCount: Int = 6\n",
        "let modelSize: Int = 256\n",
        "let feedForwardSize: Int = 1024\n",
        "let headCount: Int = 8\n",
        "let dropoutProbability: Double = 0.1\n",
        "\n",
        "var model = MotionLangTransformer(\n",
        "    sourceVocabSize: sourceVocabSize, \n",
        "    inputSize: inputSize,\n",
        "    targetVocabSize: targetVocabSize,\n",
        "    layerCount: layerCount, \n",
        "    modelSize: modelSize, \n",
        "    feedForwardSize: feedForwardSize, \n",
        "    headCount: headCount, \n",
        "    dropoutProbability: dropoutProbability\n",
        ")\n",
        "\n",
        "model.move(to: device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysEn7gicN-LZ",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFwP-zu-N-LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b8266ba8-5d1f-4608-ed3d-4dfb66f55010"
      },
      "source": [
        "// load dataset\n",
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Motion2Lang(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    langDatasetURL: langDatasetURL,\n",
        "    maxSequenceLength: maxSequenceLength,\n",
        "    batchSize: batchSize\n",
        ") { (example: Motion2Lang.Example) -> MotionLangBatch in    \n",
        "    let singleBatch = textProcessor.preprocess(example: example)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Loading dataset...\n",
            "MotionDataset(motionSamples: 39102)\n",
            "keeping 30120 annotatated motions\n",
            "keeping 29970 longer motions, with minimum 10 frames\n",
            "Dataset acquired.\n",
            "example.id: 1279\n",
            "example.motionSample.timestepsArray.last: 6.0\n",
            "example.motionSample.motionFramesArray.shape: [61, 48]\n",
            "example.targetSentence: A person performs a sidekick with the left foot.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzeal8UdN-Lb",
        "colab_type": "text"
      },
      "source": [
        "## Test model on a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxIdHymZN-Lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// get a batch\n",
        "// print(\"\\nOne batch (MotionLangBatch):\")\n",
        "// var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
        "// let epoch = epochIterator.next()\n",
        "// let batches = Array(epoch!.1)\n",
        "// let batch: MotionLangBatch = batches[0]\n",
        "// print(\"type: \\(type(of:batch))\")\n",
        "// print(\"motionFrames.shape: \\(batch.motionFrames.shape)\")\n",
        "// // print(\"motionFlag.shape: \\(batch.motionFlag.shape)\")\n",
        "// print(\"mask.shape: \\(batch.mask.shape)\")\n",
        "// print(\"origMotionFramesCount.shape: \\(batch.origMotionFramesCount.shape)\")\n",
        "// print(\"origMotionFramesCount: \\(batch.origMotionFramesCount)\")\n",
        "// print(\"targetTokenIds.shape: \\(batch.targetTokenIds.shape)\")\n",
        "// print(\"targetMask.shape: \\(batch.targetMask.shape)\")\n",
        "// print(\"targetTruth.shape: \\(batch.targetTruth.shape)\")\n",
        "\n",
        "// run one batch\n",
        "// print(\"\\nRun one batch:\")\n",
        "// print(\"==============\")\n",
        "// let deviceBatch = MotionLangBatch(copying: batch, to: device)\n",
        "// let output = model(deviceBatch)\n",
        "// print(\"output.shape: \\(output.shape)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGL_PkLMN-Lf",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jon3S7pPN-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var optimizer = Adam(for: model, learningRate: learningRate)\n",
        "optimizer = Adam(copying: optimizer, to: device)\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"tboard/Motion2lang/\\(runName)\", isDirectory: true)\n",
        "let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQGXiJB1N-Li",
        "colab_type": "text"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g22npgZN-Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable(wrt: logits)\n",
        "public func softmaxCrossEntropy2(logits: Tensor<Float>, labels: Tensor<Int32>, ignoreIndex: Int32) -> Tensor<Float> {\n",
        "    // print(\"softmaxCrossEntropy2() - start\")\n",
        "    // FIXME: use logits.device, move code back to Utilities.swift\n",
        "    // print(\"  LazyTensorBarrier()\")\n",
        "    // time {\n",
        "    //     LazyTensorBarrier()\n",
        "    // }\n",
        "    // let ids = Tensor<Int32>(rangeFrom: 0, to: Int32(labels.shape.first!), stride: 1, on: device)    \n",
        "    // let indices = ids.gathering(where: labels .!= Tensor(ignoreIndex, on: device))\n",
        "    // let maskedLogits = logits.gathering(atIndices: indices, alongAxis: 0)\n",
        "    // let maskedTargets = labels.gathering(atIndices: indices, alongAxis: 0)\n",
        "    // print(\"  maskedLogits.shape: \\(maskedLogits.shape)\")\n",
        "    // print(\"  maskedTargets.shape: \\(maskedTargets.shape)\")\n",
        "    let sce = softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "    // print(\"sce: \\(sce)\")\n",
        "    // let maskedSCE = softmaxCrossEntropy(logits: maskedLogits, labels: maskedTargets)\n",
        "    // print(\"maskedSCE: \\(maskedSCE)\")\n",
        "    // print(\"softmaxCrossEntropy2() - stop\")\n",
        "    return sce\n",
        "}\n",
        "\n",
        "func update(model: inout MotionLangTransformer, using optimizer: inout Adam<MotionLangTransformer>, for batch: MotionLangBatch) -> Float {\n",
        "    // print(\"update() - start\")\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    // print(\"  resultSize: \\(resultSize)\")\n",
        "    let padIndex = textProcessor.padId\n",
        "    let result = withLearningPhase(.training) { () -> Float in\n",
        "        let (loss, grad) = valueWithGradient(at: model) {\n",
        "            (model) -> Tensor<Float> in\n",
        "            let logits = model.generate(input: batch).reshaped(to: [resultSize, -1])\n",
        "            // print(\"  logits.shape: \\(logits.shape)\")\n",
        "            // print(\"  labels.shape: \\(labels.shape)\")\n",
        "            let sce = softmaxCrossEntropy2(logits: logits, labels: labels,ignoreIndex: padIndex)\n",
        "            return sce\n",
        "        }\n",
        "        optimizer.update(&model, along: grad)\n",
        "        LazyTensorBarrier()\n",
        "        return loss.scalarized()\n",
        "    }\n",
        "    // print(\"update() - stop\")\n",
        "    return result\n",
        "}\n",
        "\n",
        "/// returns validation loss\n",
        "func validate(model: inout MotionLangTransformer, for batch: MotionLangBatch) -> Float {\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    let padIndex = textProcessor.padId\n",
        "    let result = withLearningPhase(.inference) { () -> Float in\n",
        "        softmaxCrossEntropy2(logits: model.generate(input: batch).reshaped(to: [resultSize, -1]), labels: labels,ignoreIndex: padIndex).scalarized()\n",
        "    }\n",
        "    LazyTensorBarrier()\n",
        "    return result\n",
        "}"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr2TXD10N-Lk",
        "colab_type": "text"
      },
      "source": [
        "## setup decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWM7srrpN-Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func greedyDecode(model: MotionLangTransformer, input: MotionLangBatch, maxLength: Int, startSymbol: Int32) -> Tensor<Int32> {\n",
        "    let memory = model.encode(input: input)\n",
        "    var ys = Tensor(repeating: startSymbol, shape: [1,1])\n",
        "    // ys = Tensor(copying: ys, to: device)\n",
        "    for _ in 0..<maxLength {\n",
        "        let decoderInput = MotionLangBatch(motionFrames: input.motionFrames,\n",
        "                                     mask: input.mask,\n",
        "                                     origMotionFramesCount: input.origMotionFramesCount,\n",
        "                                     targetTokenIds: ys,\n",
        "                                     targetMask: Tensor<Float>(subsequentMask(size: ys.shape[1])),\n",
        "                                     targetTruth: input.targetTruth)\n",
        "        // decoderInput = MotionLangBatch(copying: decoderInput, to: device)\n",
        "        let out = model.decode(input: decoderInput, memory: memory)\n",
        "        let prob = model.generate(input: out[0...,-1])\n",
        "        let nextWord = Int32(prob.argmax().scalarized())\n",
        "        ys = Tensor(concatenating: [ys, Tensor(repeating: nextWord, shape: [1,1])], alongAxis: 1) // , on: device\n",
        "        // ys = Tensor(copying: ys, to: device)\n",
        "    }\n",
        "    return ys\n",
        "}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s73XJlq5U7NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "092fdb5b-d174-4de8-c5e2-4c233410ee65"
      },
      "source": [
        "// get example\n",
        "let example = dataset.trainExamples[0]\n",
        "print(\"example.id: \\(example.id)\")\n",
        "print(\"example.motionSample.timestepsArray.last: \\(example.motionSample.timestepsArray.last!)\")\n",
        "print(\"example.motionSample.motionFramesArray.shape: \\(example.motionSample.motionFramesArray.shape)\")\n",
        "print(\"example.targetSentence: \\(example.targetSentence)\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example.id: 1279\r\n",
            "example.motionSample.timestepsArray.last: 6.0\r\n",
            "example.motionSample.motionFramesArray.shape: [61, 48]\r\n",
            "example.targetSentence: A person performs a sidekick with the left foot.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbUStI7N-Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// setup decoding\n",
        "// var epochIterator2 = dataset.trainingEpochs.enumerated().makeIterator()\n",
        "// let epoch2 = epochIterator2.next()\n",
        "// let batches2 = Array(epoch2!.1)\n",
        "// let batch2 = batches2[0]\n",
        "\n",
        "// let exampleIndex = 1 // FIXME: utilize exampleIndex\n",
        "// var source = batch2 //Motion2Lang.reduceDataBatches(batches2)\n",
        "\n",
        "let oneExample = dataset.trainExamples[0]\n",
        "let singleExampleBatch = textProcessor.preprocess(example: oneExample)\n",
        "var source = Motion2Lang.reduceDataBatches([singleExampleBatch])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE4T4N8xN-Lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3999db39-1387-4ae1-b863-9e96c06d2509"
      },
      "source": [
        "var outputStr = textProcessor.decode(tensor: source.targetTokenIds)\n",
        "print(\"decode(source.targetTokenIds): \\(outputStr)\")\n",
        "\n",
        "Context.local.learningPhase = .inference\n",
        "source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "model.move(to: Device.defaultTFEager)\n",
        "let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "outputStr = textProcessor.decode(tensor: out)\n",
        "print(\"greedyDecode(): \\\"\\(outputStr)\\\"\")\n",
        "model.move(to: device)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "decode(source.targetTokenIds): [CLS] a person performs a sidekick with the left foot .\n",
            "2020-07-03 15:40:00.450729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "greedyDecode(): \"[CLS] kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo kangaroo shuffled shuffled shuffled shuffled kangaroo kangaroo kangaroo maneuver shuffled shuffled maneuver maneuver represents represents represents kangaroo shuffled shuffled shuffled shuffled maneuver maneuver represents kangaroo kangaroo kangaroo maneuver maneuver maneuver maneuver maneuver maneuver maneuver maneuver maneuver\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22deJipJN-Lr",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPJMsdTN-Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cced15f-fc8b-4e29-d803-ef982130e8d2"
      },
      "source": [
        "print(\"\\nTraining Transformer for the Motion2lang task!\")\n",
        "var trainingStepCount = 0\n",
        "time() {\n",
        "    LazyTensorBarrier()\n",
        "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(nEpochs).enumerated() {\n",
        "        print(\"[Epoch \\(epoch + 1)]\")\n",
        "        Context.local.learningPhase = .training\n",
        "        var trainingLossSum: Float = 0\n",
        "        var trainingBatchCount = 0\n",
        "        if epoch == 0 {\n",
        "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
        "        }\n",
        "\n",
        "        for eagerBatch in epochBatches {\n",
        "            print(\"==> step \\(trainingStepCount)\")\n",
        "            // print(\"eagerBatch.tokenIds.shape: \\(eagerBatch.tokenIds.shape)\")\n",
        "            // print(\"eagerBatch.targetTokenIds.shape: \\(eagerBatch.targetTokenIds.shape)\")\n",
        "            // print(\"eagerBatch.mask.shape: \\(eagerBatch.mask.shape)\")\n",
        "            // print(\"eagerBatch.targetTruth.shape: \\(eagerBatch.targetTruth.shape)\")\n",
        "            // print(\"eagerBatch.tokenCount: \\(eagerBatch.tokenCount)\")\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = update(model: &model, using: &optimizer, for: batch)\n",
        "            print(\"current loss at step \\(trainingStepCount): \\(loss)\")\n",
        "            trainingLossSum += loss\n",
        "            trainingBatchCount += 1\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
        "            trainingStepCount += 1\n",
        "        }\n",
        "        print(\n",
        "            \"\"\"\n",
        "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch+1, value: trainingLossSum / Float(trainingBatchCount))\n",
        "\n",
        "        if epoch == 0 {\n",
        "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
        "        }\n",
        "        Context.local.learningPhase = .inference\n",
        "        var devLossSum: Float = 0\n",
        "        var devBatchCount = 0\n",
        "        var totalGuessCount = 0\n",
        "\n",
        "        for eagerBatch in dataset.validationBatches {\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = validate(model: &model, for: batch)\n",
        "            let valBatchSize = batch.motionFrames.shape[0]\n",
        "\n",
        "            devLossSum += loss\n",
        "            devBatchCount += 1\n",
        "            totalGuessCount += valBatchSize\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            \"\"\"\n",
        "            totalGuessCount: \\(totalGuessCount) \\\n",
        "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch+1, value: devLossSum / Float(devBatchCount))\n",
        "\n",
        "        print(\"\\nEncoding/decoding one example\") // on eager device\n",
        "        Context.local.learningPhase = .inference\n",
        "        source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "        model.move(to: Device.defaultTFEager)\n",
        "        let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "        outputStr = textProcessor.decode(tensor: out)\n",
        "        print(\"greedyDecode(): \\\"\\(outputStr)\\\"\")\n",
        "        model.move(to: device)\n",
        "    }\n",
        "    summaryWriter.flush()\n",
        "}\n",
        "\n",
        "\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Training Transformer for the Motion2lang task!\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NRg5U_N-Lt",
        "colab_type": "text"
      },
      "source": [
        "## Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX35KcjKN-Lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// encode/decode one example\n",
        "// print(\"\\nEncoding/decoding one example\")\n",
        "// Context.local.learningPhase = .inference\n",
        "// source = MotionLangBatch(copying: source, to: device)\n",
        "// model.move(to: Device.defaultTFEager)\n",
        "// let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "// outputStr = textProcessor.decode(tensor: out)\n",
        "// print(\"greedyDecode(), outputStr: \\(outputStr)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMY-iAwaN-Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}