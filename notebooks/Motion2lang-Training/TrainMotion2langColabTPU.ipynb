{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Swift",
      "language": "swift",
      "name": "swift"
    },
    "language_info": {
      "file_extension": ".swift",
      "mimetype": "text/x-swift",
      "name": "swift",
      "version": ""
    },
    "colab": {
      "name": "TrainMotion2langColabTPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOiO12PtN-LD",
        "colab_type": "text"
      },
      "source": [
        "# Train Transformer for the Motion2lang task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HbPDTy-Zd7P",
        "colab_type": "text"
      },
      "source": [
        "## Get sources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiEwgnAxOYNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c12b58e2-ff1b-4e8c-cb03-f298e87afa34"
      },
      "source": [
        "// for colab\n",
        "%install-location $cwd/swift-install\n",
        "%install-swiftpm-flags -c release\n",
        "%install '.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"colab-tpu-error\"))' Datasets TranslationModels TextModels ModelSupport SummaryWriter MotionModels"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(url: \"https://github.com/wojtekcz/language2motion.git\", .branch(\"colab-tpu-error\"))\n",
            "\t\tDatasets\n",
            "\t\tTranslationModels\n",
            "\t\tTextModels\n",
            "\t\tModelSupport\n",
            "\t\tSummaryWriter\n",
            "\t\tMotionModels\n",
            "With SwiftPM flags: ['-c', 'release']\n",
            "Working in: /tmp/tmp5l0emmpu/swift-install\n",
            "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YCslW2KN-LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import TextModels\n",
        "import TranslationModels\n",
        "import Foundation\n",
        "import ModelSupport\n",
        "import Datasets\n",
        "import SummaryWriter\n",
        "import MotionModels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crE05WTMZNW5",
        "colab_type": "text"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk7QcW_swN-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let dataset_name = \"motion_dataset_v3.norm.10Hz\"\n",
        "let dataset_name = \"motion_dataset_v3.norm.10Hz.mini\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxIOsZLRUTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import Foundation\n",
        "\n",
        "func shell(_ command: String) -> String {\n",
        "    let task = Process()\n",
        "    let pipe = Pipe()\n",
        "\n",
        "    task.standardOutput = pipe\n",
        "    task.arguments = [\"-c\", command]\n",
        "    task.launchPath = \"/bin/bash\"\n",
        "    task.launch()\n",
        "\n",
        "    let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
        "    return String(data: data, encoding: .utf8)!\n",
        "}\n",
        "\n",
        "func sh(_ command: String) {\n",
        "    print(shell(command))\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDtBlXnRaT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a5ca2bbc-6744-4173-b2a7-424580fbf3c1"
      },
      "source": [
        "sh(\"mkdir -p /content/data/\")\n",
        "sh(\"\"\"\n",
        "cd /content/data/\n",
        "wget -nv --show-progress -N https://github.com/wojtekcz/language2motion/releases/download/v0.2.0/\\(dataset_name).tgz\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/labels_ds_v2.csv\n",
        "wget -nv -N https://github.com/wojtekcz/language2motion/releases/download/v0.1.0/vocab.txt\n",
        "tar xzvf \\(dataset_name).tgz --skip-old-files\n",
        "\"\"\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "motion_dataset_v3.n 100%[===================>]  76.87M  70.8MB/s    in 1.1s    \n",
            "2020-07-15 14:49:51 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/24bb8980-c505-11ea-86e7-b8b6236db096?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200715%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200715T144950Z&X-Amz-Expires=300&X-Amz-Signature=d9677b7e7f162127efcd90b99cabda5764e53c3e58fc2d4b7c7cf5f66ddd24ac&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dmotion_dataset_v3.norm.10Hz.mini.tgz&response-content-type=application%2Foctet-stream [80600141/80600141] -> \"motion_dataset_v3.norm.10Hz.mini.tgz\" [1]\n",
            "2020-07-15 14:49:52 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/16bcbb80-95dd-11ea-8fed-886381d8bee7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200715%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200715T144952Z&X-Amz-Expires=300&X-Amz-Signature=114a3ff7536abe3789375c1be23b98bcc6eb3454bd69f238cb8583b3959c5348&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dlabels_ds_v2.csv&response-content-type=application%2Foctet-stream [297583/297583] -> \"labels_ds_v2.csv\" [1]\n",
            "2020-07-15 14:49:52 URL:https://github-production-release-asset-2e65be.s3.amazonaws.com/258798747/d61a0480-a6a7-11ea-9a3e-8c42fc2775cc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200715%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200715T144952Z&X-Amz-Expires=300&X-Amz-Signature=925572e43eb57e86f92d4d1ef4d0cd2521dc49a7d53a43fbf5c0b73d8fa40b2c&X-Amz-SignedHeaders=host&actor_id=0&repo_id=258798747&response-content-disposition=attachment%3B%20filename%3Dvocab.txt&response-content-type=application%2Foctet-stream [231508/231508] -> \"vocab.txt\" [1]\n",
            "motion_dataset_v3.norm.10Hz.mini.plist\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbmXosmTN-LM",
        "colab_type": "text"
      },
      "source": [
        "## Set training params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sum7wmL6N-LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e8bc3ae7-c032-46ee-e96b-ed1d731dda3f"
      },
      "source": [
        "let runName = \"run_1\"\n",
        "let batchSize = 6000\n",
        "// let batchSize = 3000\n",
        "let maxSequenceLength =  50\n",
        "let nEpochs = 10\n",
        "let learningRate: Float = 5e-4\n",
        "\n",
        "print(\"runName: \\(runName)\")\n",
        "print(\"batchSize: \\(batchSize)\")\n",
        "print(\"maxSequenceLength: \\(maxSequenceLength)\")\n",
        "print(\"nEpochs: \\(nEpochs)\")\n",
        "print(\"learningRate: \\(learningRate)\")\n",
        "\n",
        "let dataURL = URL(fileURLWithPath: \"/content/data/\")\n",
        "let motionDatasetURL = dataURL.appendingPathComponent(\"\\(dataset_name).plist\")\n",
        "let langDatasetURL = dataURL.appendingPathComponent(\"labels_ds_v2.csv\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "runName: run_1\r\n",
            "batchSize: 6000\r\n",
            "maxSequenceLength: 50\r\n",
            "nEpochs: 10\r\n",
            "learningRate: 0.0005\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHyhFi49N-LP",
        "colab_type": "text"
      },
      "source": [
        "## Select eager or X10 backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUyfo7oZN-LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "683e8a5e-f9b2-4909-daad-1c2be4151aa4"
      },
      "source": [
        "let device = Device.defaultXLA\n",
        "// let device = Device.defaultTFEager\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device(kind: .TPU, ordinal: 0, backend: .XLA)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZrpeweN-LS",
        "colab_type": "text"
      },
      "source": [
        "## X10 warm-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJX4GecfN-LT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let eagerTensor1 = Tensor([0.0, 1.0, 2.0])\n",
        "// let eagerTensor2 = Tensor([1.5, 2.5, 3.5])\n",
        "// let eagerTensorSum = eagerTensor1 + eagerTensor2\n",
        "// print(eagerTensorSum)\n",
        "// print(eagerTensor1.device)\n",
        "// let x10Tensor2 = Tensor([1.5, 2.5, 3.5], on: Device.defaultXLA)\n",
        "// print(x10Tensor2.device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHwl5J2LN-LV",
        "colab_type": "text"
      },
      "source": [
        "## Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp5-Mh2TN-LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// instantiate text processor\n",
        "let vocabularyURL = dataURL.appendingPathComponent(\"vocab.txt\")\n",
        "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
        "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary, caseSensitive: false, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
        "let textProcessor = TextProcessor(vocabulary: vocabulary, tokenizer: tokenizer, maxSequenceLength: maxSequenceLength)\n",
        "\n",
        "// instantiate model\n",
        "let sourceVocabSize = vocabulary.count\n",
        "let inputSize = 48 // TODO: get value from dataset\n",
        "let targetVocabSize = vocabulary.count\n",
        "let layerCount: Int = 6\n",
        "let modelSize: Int = 256\n",
        "let feedForwardSize: Int = 1024\n",
        "let headCount: Int = 8\n",
        "let dropoutProbability: Double = 0.1\n",
        "\n",
        "var model = MotionLangTransformer(\n",
        "    sourceVocabSize: sourceVocabSize, \n",
        "    inputSize: inputSize,\n",
        "    targetVocabSize: targetVocabSize,\n",
        "    layerCount: layerCount, \n",
        "    modelSize: modelSize, \n",
        "    feedForwardSize: feedForwardSize, \n",
        "    headCount: headCount, \n",
        "    dropoutProbability: dropoutProbability\n",
        ")\n",
        "\n",
        "model.move(to: device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysEn7gicN-LZ",
        "colab_type": "text"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFwP-zu-N-LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "650614ca-b097-466d-f2d6-ffe85ae246c1"
      },
      "source": [
        "print(\"\\nLoading dataset...\")\n",
        "\n",
        "var dataset = try Motion2Lang(\n",
        "    motionDatasetURL: motionDatasetURL,\n",
        "    langDatasetURL: langDatasetURL,\n",
        "    maxSequenceLength: maxSequenceLength,\n",
        "    batchSize: batchSize\n",
        ") { (example: Motion2Lang.Example) -> MotionLangBatch in    \n",
        "    let singleBatch = textProcessor.preprocess(example: example)\n",
        "    return singleBatch\n",
        "}\n",
        "\n",
        "print(\"Dataset acquired.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Loading dataset...\n",
            "MotionDataset(motionSamples: 4860)\n",
            "keeping 3740 annotatated motions\n",
            "keeping 3718 longer motions, with minimum 10 frames\n",
            "Dataset acquired.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzeal8UdN-Lb",
        "colab_type": "text"
      },
      "source": [
        "## Test model with one batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxIdHymZN-Lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "9c09e1db-fe28-491c-a1ab-06176eb979f9"
      },
      "source": [
        "// get a batch\n",
        "print(\"\\nOne batch (MotionLangBatch):\")\n",
        "var epochIterator = dataset.trainingEpochs.enumerated().makeIterator()\n",
        "let epoch = epochIterator.next()\n",
        "let batches = Array(epoch!.1)\n",
        "let batch: MotionLangBatch = batches[0]\n",
        "print(\"type: \\(type(of:batch))\")\n",
        "print(\"motionFrames.shape: \\(batch.motionFrames.shape)\")\n",
        "// print(\"motionFlag.shape: \\(batch.motionFlag.shape)\")\n",
        "print(\"mask.shape: \\(batch.mask.shape)\")\n",
        "print(\"origMotionFramesCount.shape: \\(batch.origMotionFramesCount.shape)\")\n",
        "print(\"origMotionFramesCount: \\(batch.origMotionFramesCount)\")\n",
        "print(\"targetTokenIds.shape: \\(batch.targetTokenIds.shape)\")\n",
        "print(\"targetMask.shape: \\(batch.targetMask.shape)\")\n",
        "print(\"targetTruth.shape: \\(batch.targetTruth.shape)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "One batch (MotionLangBatch):\n",
            "type: MotionLangBatch\n",
            "motionFrames.shape: [120, 50, 48]\n",
            "mask.shape: [120, 1, 50]\n",
            "origMotionFramesCount.shape: [120]\n",
            "origMotionFramesCount: [ 37,  83,  58,  49,  46,  51,  97,  50,  38,  48,  54,  60,  99,  55,  58,  65,  53,  11,  36,  77,  52,  52,  27,  68,  60,  47,\n",
            "  61,  48, 103,  47,  59,  50,  51,  58,  49, 272, 258,  40,  40,  46,  76,  10,  38,  65, 104,  70,  65, 189,  73,  47,  68,  72,\n",
            "  78, 176,  53,  48,  69,  58,  40,  56, 129,  41,  95,  47,  59,  53,  48,  36,  95, 126, 109,  68,  50,  40, 126,  34,  83,  90,\n",
            "  44,  48,  50,  60,  54, 153, 209,  52,  53,  85,  58, 159,  67,  66,  83,  41, 117,  60, 119,  10,  53,  59,  65,  50,  58,  57,\n",
            "  68,  45,  76, 203,  59,  35,  57,  90,  46,  70,  83,  55,  57,  54,  54, 265]\n",
            "targetTokenIds.shape: [120, 49]\n",
            "targetMask.shape: [120, 49, 49]\n",
            "targetTruth.shape: [120, 49]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb3enWa55kr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "74736abc-3c48-459d-ddc9-3844a1b0d122"
      },
      "source": [
        "// run one batch\n",
        "print(\"\\nRun one batch:\")\n",
        "print(\"==============\")\n",
        "let deviceBatch = MotionLangBatch(copying: batch, to: device)\n",
        "let output = model(deviceBatch)\n",
        "print(\"output.shape: \\(output.shape)\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Run one batch:\r\n",
            "==============\n",
            "output.shape: [120, 49, 256]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGL_PkLMN-Lf",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jon3S7pPN-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var optimizer = Adam(for: model, learningRate: learningRate)\n",
        "optimizer = Adam(copying: optimizer, to: device)\n",
        "\n",
        "let logdirURL = dataURL.appendingPathComponent(\"tboard/Motion2lang/\\(runName)\", isDirectory: true)\n",
        "let summaryWriter = SummaryWriter(logdir: logdirURL, flushMillis: 30*1000)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQGXiJB1N-Li",
        "colab_type": "text"
      },
      "source": [
        "## Training helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g22npgZN-Li",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func update(model: inout MotionLangTransformer, using optimizer: inout Adam<MotionLangTransformer>, for batch: MotionLangBatch) -> Float {\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    let result = withLearningPhase(.training) { () -> Float in\n",
        "        let (loss, grad) = valueWithGradient(at: model) {\n",
        "            (model) -> Tensor<Float> in\n",
        "            let logits = model.generate(input: batch).reshaped(to: [resultSize, -1])\n",
        "            let sce = softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "            return sce\n",
        "        }\n",
        "        optimizer.update(&model, along: grad)\n",
        "        LazyTensorBarrier()\n",
        "        return loss.scalarized()\n",
        "    }\n",
        "    return result\n",
        "}\n",
        "\n",
        "/// returns validation loss\n",
        "func validate(model: inout MotionLangTransformer, for batch: MotionLangBatch) -> Float {\n",
        "    let labels = batch.targetTruth.reshaped(to: [-1])\n",
        "    let resultSize = batch.targetTruth.shape.last! * batch.targetTruth.shape.first!\n",
        "    let result = withLearningPhase(.inference) { () -> Float in\n",
        "        softmaxCrossEntropy(logits: model.generate(input: batch).reshaped(to: [resultSize, -1]), labels: labels).scalarized()\n",
        "    }\n",
        "    LazyTensorBarrier()\n",
        "    return result\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr2TXD10N-Lk",
        "colab_type": "text"
      },
      "source": [
        "## Set up decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWM7srrpN-Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func greedyDecode(model: MotionLangTransformer, input: MotionLangBatch, maxLength: Int, startSymbol: Int32) -> Tensor<Int32> {\n",
        "    let memory = model.encode(input: input)\n",
        "    var ys = Tensor(repeating: startSymbol, shape: [1,1])\n",
        "    // ys = Tensor(copying: ys, to: device)\n",
        "    for _ in 0..<maxLength {\n",
        "        let decoderInput = MotionLangBatch(motionFrames: input.motionFrames,\n",
        "                                     mask: input.mask,\n",
        "                                     origMotionFramesCount: input.origMotionFramesCount,\n",
        "                                     targetTokenIds: ys,\n",
        "                                     targetMask: Tensor<Float>(subsequentMask(size: ys.shape[1])),\n",
        "                                     targetTruth: input.targetTruth)\n",
        "        // decoderInput = MotionLangBatch(copying: decoderInput, to: device)\n",
        "        let out = model.decode(input: decoderInput, memory: memory)\n",
        "        let prob = model.generate(input: out[0...,-1])\n",
        "        let nextWord = Int32(prob.argmax().scalarized())\n",
        "        ys = Tensor(concatenating: [ys, Tensor(repeating: nextWord, shape: [1,1])], alongAxis: 1) // , on: device\n",
        "        // ys = Tensor(copying: ys, to: device)\n",
        "    }\n",
        "    return ys\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2XXZEupyHHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func greedyDecodeSample(_ sample_id: Int, verbose: Bool = false) {\n",
        "    // get example\n",
        "    let ms = dataset.motionSampleDict[sample_id]!\n",
        "    let langRec = dataset.langRecsDict[sample_id]!\n",
        "    let example = Motion2Lang.getExample(motionSample: ms, langRec: langRec)\n",
        "    if verbose {\n",
        "        print(\"example.id: \\(example.id)\")\n",
        "        print(\"  motionSample.timestepsArray.last: \\(example.motionSample.timestepsArray.last!)\")\n",
        "        print(\"  motionSample.motionFramesArray.shape: \\(example.motionSample.motionFramesArray.shape)\")\n",
        "    }\n",
        "    let singleExampleBatch = textProcessor.preprocess(example: example)\n",
        "    var source = Motion2Lang.reduceDataBatches([singleExampleBatch])\n",
        "    print(\"\\nDecoding one sample:\") // on eager device\n",
        "    print(\"  targetSentence: \\\"\\(example.targetSentence)\\\"\")\n",
        "    Context.local.learningPhase = .inference\n",
        "    source = MotionLangBatch(copying: source, to: Device.defaultTFEager)\n",
        "    model.move(to: Device.defaultTFEager)\n",
        "    let out = greedyDecode(model: model, input: source, maxLength: 50, startSymbol: textProcessor.bosId)\n",
        "    // TODO: only show one [PAD]\n",
        "    let outputStr = textProcessor.decode(tensor: out)\n",
        "    print(\"  decoded: \\\"\\(outputStr)\\\"\")\n",
        "    model.move(to: device)\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s73XJlq5U7NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8e507e13-6a06-4c5e-9aa7-23efd9fbab1c"
      },
      "source": [
        "// get example\n",
        "let example = dataset.trainExamples[0]\n",
        "greedyDecodeSample(Int(example.id)!, verbose: true)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example.id: 2078\r\n",
            "  motionSample.timestepsArray.last: 5.8\r\n",
            "  motionSample.motionFramesArray.shape: [59, 48]\r\n",
            "\r\n",
            "Decoding one sample:\r\n",
            "  targetSentence: \"a person knees on the floor\"\n",
            "  decoded: \"[CLS] adjusting brodie brodie brodie ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah brodie brodie ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah brodie brodie brodie brodie ##llah ##llah ##llah brodie brodie brodie brodie brodie brodie brodie avon ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah ##llah\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22deJipJN-Lr",
        "colab_type": "text"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U56YYj7i0Bft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// let nEpochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPJMsdTN-Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "ea31b2fe-d173-4664-93f0-70c16227f738"
      },
      "source": [
        "print(\"\\nTraining Transformer for the Motion2lang task!\")\n",
        "var trainingStepCount = 0\n",
        "let print_every = 10\n",
        "time() {\n",
        "    LazyTensorBarrier()\n",
        "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(nEpochs).enumerated() {\n",
        "        print(\"[Epoch \\(epoch + 1)]\")\n",
        "        Context.local.learningPhase = .training\n",
        "        var trainingLossSum: Float = 0\n",
        "        var trainingBatchCount = 0\n",
        "        if epoch == 0 {\n",
        "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
        "        }\n",
        "\n",
        "        for eagerBatch in epochBatches {\n",
        "            if (trainingStepCount < 5 || trainingStepCount % print_every == 0) {\n",
        "                print(\"==> step \\(trainingStepCount)\")\n",
        "            }\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = update(model: &model, using: &optimizer, for: batch)\n",
        "            if (trainingStepCount < 5 || trainingStepCount % print_every == 0) {\n",
        "                print(\"current loss at step \\(trainingStepCount): \\(loss)\")\n",
        "            }\n",
        "            trainingLossSum += loss\n",
        "            trainingBatchCount += 1\n",
        "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
        "            trainingStepCount += 1\n",
        "        }\n",
        "        print(\n",
        "            \"\"\"\n",
        "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch+1, value: trainingLossSum / Float(trainingBatchCount))\n",
        "\n",
        "        if epoch == 0 {\n",
        "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
        "        }\n",
        "        Context.local.learningPhase = .inference\n",
        "        var devLossSum: Float = 0\n",
        "        var devBatchCount = 0\n",
        "        var totalGuessCount = 0\n",
        "\n",
        "        for eagerBatch in dataset.validationBatches {\n",
        "            let batch = MotionLangBatch(copying: eagerBatch, to: device)\n",
        "            let loss: Float = validate(model: &model, for: batch)\n",
        "            let valBatchSize = batch.motionFrames.shape[0]\n",
        "\n",
        "            devLossSum += loss\n",
        "            devBatchCount += 1\n",
        "            totalGuessCount += valBatchSize\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            \"\"\"\n",
        "            totalGuessCount: \\(totalGuessCount) \\\n",
        "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
        "            \"\"\"\n",
        "        )\n",
        "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch+1, value: devLossSum / Float(devBatchCount))\n",
        "        greedyDecodeSample(Int(example.id)!)\n",
        "    }\n",
        "    summaryWriter.flush()\n",
        "}\n",
        "\n",
        "print(\"\\nFinished training.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Training Transformer for the Motion2lang task!\n",
            "[Epoch 1]\n",
            "epochBatches.count: 24\n",
            "==> step 0\n",
            "2020-07-15 14:57:51.319334: F tensorflow/compiler/xla/xla_client/xla_util.cc:90] Invalid argument: From /job:tpu_worker/replica:0/task:0:\n",
            "Computation requires more parameters (333) than supported (limit 237).\n",
            "\t [[{{node XRTCompile}}]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "Current stack trace:",
            "\tframe #17: 0x00007f51a6e9feb2 $__lldb_expr90`partial apply for closure #1 in update(model:using:for:) at <Cell 12>:12:9",
            "\tframe #23: 0x00007f51a6e9f268 $__lldb_expr90`update(model=<unavailable>, optimizer=<unavailable>, batch=<unavailable>) at <Cell 12>:4:18",
            "\tframe #24: 0x00007f5168003483 $__lldb_expr114`closure #1 in  at <Cell 16>:20:31",
            "\tframe #25: 0x00007f51a2ab25b7 libjupyterInstalledPackages.so`time(repeating=1, f=0x00007f5168002230 $__lldb_expr114`closure #1 () -> () in __lldb_expr_113 at <Cell 16>:4) at timing.swift:15:9 [opt]",
            "\tframe #26: 0x00007f516800214b $__lldb_expr114`main at <Cell 16>:4:1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUoXa70uzoTL",
        "colab_type": "text"
      },
      "source": [
        "## Generate motion description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMY-iAwaN-Lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let sample_id = 2410\n",
        "greedyDecodeSample(sample_id, verbose: true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_M2Jjz5wBn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}