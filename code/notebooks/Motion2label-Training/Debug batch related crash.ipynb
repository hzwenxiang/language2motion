{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer-motion2label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/notebooks/language2motion.gt/code\")\n",
      "\t\tDatasets\n",
      "\t\tMotionModels\n",
      "\t\tImageClassificationModels\n",
      "\t\tTextModels\n",
      "\t\tModelSupport\n",
      "\t\tSummaryWriter\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmpvnybirfl/swift-install\n",
      "[1/2] Compiling Datasets ArrayUtils.swift\n",
      "[2/3] Compiling TextModels Attention.swift\n",
      "[3/4] Compiling MotionModels DenseMotionClassifier.swift\n",
      "[4/5] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[5/5] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt/code\")' Datasets MotionModels ImageClassificationModels TextModels ModelSupport SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "import Datasets\n",
    "import MotionModels\n",
    "import ImageClassificationModels\n",
    "import TextModels\n",
    "import ModelSupport\n",
    "import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PythonKit\n",
    "\n",
    "let metrics = Python.import(\"sklearn.metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSize: 4\n",
      "maxSequenceLength: 1000\n",
      "runName: run_9\n",
      "\n",
      "Loading dataset...\n",
      "MotionDataset(motionSamples: 3911)\n",
      "Class balancing...\n",
      "(1216, 480, 120)\n",
      "(644, 480, 120)\n",
      "(103, 480, 21)\n",
      "(400, 480, 80)\n",
      "(649, 480, 120)\n",
      "dataset.trainingExamples.count: 2400\n",
      "dataset.validationExamples.count: 461\n"
     ]
    }
   ],
   "source": [
    "let batchSize = 4\n",
    "let maxSequenceLength =  1000\n",
    "let runName = \"run_9\"\n",
    "let balanceClassSamples: Int? = 600\n",
    "\n",
    "print(\"batchSize: \\(batchSize)\")\n",
    "print(\"maxSequenceLength: \\(maxSequenceLength)\")\n",
    "print(\"runName: \\(runName)\")\n",
    "\n",
    "// let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset_v2.normalized.plist\")\n",
    "// let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.motion_flag.normalized.sampled.500.plist\")\n",
    "let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.motion_flag.normalized.plist\")\n",
    "let labelsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/labels_ds_v2.csv\")\n",
    "\n",
    "print(\"\\nLoading dataset...\")\n",
    "let dataset = try! Motion2Label(\n",
    "    serializedDatasetURL: serializedDatasetURL,\n",
    "    labelsURL: labelsURL,\n",
    "    maxSequenceLength: maxSequenceLength,\n",
    "    batchSize: batchSize,\n",
    "    balanceClassSamples: balanceClassSamples\n",
    ") { \n",
    "    // TODO: move this to dataset class\n",
    "    (example: Motion2LabelExample) -> LabeledMotionBatch in\n",
    "    let motionFrames = Tensor<Float>(example.motionSample.motionFramesArray)\n",
    "    let motionFlag = Tensor<Int32>(motionFrames[0..., 44...44].squeezingShape(at: 1))\n",
    "    let origMotionFramesCount = Tensor<Int32>(Int32(motionFrames.shape[0]))\n",
    "    let motionBatch = MotionBatch(motionFrames: motionFrames, motionFlag: motionFlag, origMotionFramesCount: origMotionFramesCount)\n",
    "    let label = Tensor<Int32>(Int32(example.label!.idx))\n",
    "    return LabeledMotionBatch(data: motionBatch, label: label)\n",
    "}\n",
    "\n",
    "print(\"dataset.trainingExamples.count: \\(dataset.trainingExamples.count)\")\n",
    "print(\"dataset.validationExamples.count: \\(dataset.validationExamples.count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug batch related crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.validationExamples.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(data: MotionBatch, label: Tensor<Int32>)\n"
     ]
    }
   ],
   "source": [
    "print(type(of:dataset.validationExamples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [543, 45]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 543\n",
       "    - 1 : 45\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.validationExamples[0].data.motionFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [801, 45]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 801\n",
       "    - 1 : 45\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.validationExamples[460].data.motionFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.validationBatches.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 114\n",
      "documents.motionFrames.shape: [4, 1000, 45]\n",
      "batch 115\n",
      "documents.motionFrames.shape: [801, 45]\n"
     ]
    }
   ],
   "source": [
    "for (idx, batch) in dataset.validationBatches.enumerated() {\n",
    "    let valBatchSize = batch.data.motionFrames.shape[0]\n",
    "    let (documents, labels) = (batch.data, Tensor<Int32>(batch.label))\n",
    "    if documents.motionFrames.shape.count < 3 || idx==114 {\n",
    "        print(\"batch \\(idx)\")\n",
    "        print(\"documents.motionFrames.shape: \\(documents.motionFrames.shape)\")\n",
    "//         let numFeatures = documents.motionFrames.shape[2]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*114+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5\n"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let examples = dataset.validationExamples[4*114-1..<460]\n",
    "examples.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let batches1 = Array(examples.inBatches(of: batchSize))\n",
    "batches1.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Tensor where Scalar: Numeric {\n",
    "    public func paddedOrCropped(to width: Int) -> Tensor<Scalar> {\n",
    "        // pads or crops one- or two-dimensional tensor along 0-th axis\n",
    "        let rank = self.shape.count\n",
    "        let currentWidth = self.shape[0]\n",
    "        let paddingSize = Swift.max(width - currentWidth, 0)\n",
    "        let maxCropping = Swift.max(currentWidth - width, 0)\n",
    "        let nCropping = (maxCropping>0) ? Int.random(in: 0 ..< maxCropping) : 0\n",
    "        var sizes: [(before: Int, after: Int)] = [(before: 0, after: paddingSize)]\n",
    "        if rank > 1 {\n",
    "            sizes.append((before: 0, after: 0))\n",
    "        }\n",
    "        return self[nCropping..<nCropping+width].padded(forSizes: sizes)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension MotionBatch: Collatable {\n",
    "  /// Creates an instance from collating `samples`.\n",
    "  public init<BatchSamples: Collection>(collating samples: BatchSamples)\n",
    "  where BatchSamples.Element == Self {\n",
    "      if samples.count == 1 {\n",
    "          print(1)\n",
    "      }\n",
    "    self.init(\n",
    "      motionFrames: .init(concatenating: samples.map({$0.motionFrames.expandingShape(at: 0)})), \n",
    "      motionFlag: .init(concatenating: samples.map({$0.motionFlag.expandingShape(at: 0)})),\n",
    "      origMotionFramesCount: .init(concatenating: samples.map({$0.origMotionFramesCount.expandingShape(at: 0)}))\n",
    "    )\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Collection where Element == MotionBatch {\n",
    "  /// Returns the elements of `self`, padded to `maxLength` if specified\n",
    "  /// or the maximum length of the elements in `self` otherwise.\n",
    "  public func paddedAndCollated2(to maxLength: Int? = nil) -> MotionBatch {\n",
    "    let maxLength = maxLength ?? self.map { $0.motionFrames.shape[1] }.max()!\n",
    "    let paddedMotions = self.map { example -> MotionBatch in\n",
    "        return MotionBatch(\n",
    "        motionFrames: example.motionFrames.paddedOrCropped(to: maxLength),\n",
    "        motionFlag: example.motionFlag.paddedOrCropped(to: maxLength),\n",
    "        origMotionFramesCount: example.origMotionFramesCount)\n",
    "    }\n",
    "    if count == 1 { \n",
    "        let pm = paddedMotions[0]\n",
    "        return MotionBatch(\n",
    "            motionFrames: pm.motionFrames.expandingShape(at: 0), \n",
    "            motionFlag: pm.motionFlag.expandingShape(at: 0), \n",
    "            origMotionFramesCount: pm.origMotionFramesCount.expandingShape(at: 0))\n",
    "    } else {\n",
    "        return paddedMotions.collated\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeledMotionBatchSequence: LazyMapSequence<ArraySlice<Motion2LabelExample>, (data: MotionBatch, label: Tensor<Int32>)>\n",
      "labeledMotionBatch: (data: MotionBatch, label: Tensor<Int32>)\n",
      "[667, 45]\n",
      "labeledMotionBatch: (data: MotionBatch, label: Tensor<Int32>)\n",
      "[590, 45]\n",
      "labeledMotionBatch: (data: MotionBatch, label: Tensor<Int32>)\n",
      "[540, 45]\n",
      "labeledMotionBatch: (data: MotionBatch, label: Tensor<Int32>)\n",
      "[926, 45]\n",
      "motionBatch: MotionBatch\n",
      "motionFrames: [4, 1000, 45]\n",
      "motionFlag: [4, 1000]\n",
      "origMotionFramesCount: [4]\n",
      "labeledMotionBatchSequence: LazyMapSequence<ArraySlice<Motion2LabelExample>, (data: MotionBatch, label: Tensor<Int32>)>\n",
      "labeledMotionBatch: (data: MotionBatch, label: Tensor<Int32>)\n",
      "[391, 45]\n",
      "motionBatch: MotionBatch\n",
      "motionFrames: [1, 1000, 45]\n",
      "motionFlag: [1, 1000]\n",
      "origMotionFramesCount: [1]\n"
     ]
    }
   ],
   "source": [
    "for labeledMotionBatchSequence in batches1 {\n",
    "    print(\"labeledMotionBatchSequence: \\(type(of:labeledMotionBatchSequence))\")\n",
    "    for labeledMotionBatch: LabeledMotionBatch in labeledMotionBatchSequence {\n",
    "        print(\"labeledMotionBatch: \\(type(of:labeledMotionBatch))\")\n",
    "        print(labeledMotionBatch.data.motionFrames.shape)\n",
    "    }\n",
    "    let motionBatch: MotionBatch = labeledMotionBatchSequence.map(\\.data).paddedAndCollated2(to: maxSequenceLength)\n",
    "    print(\"motionBatch: \\(type(of:motionBatch))\")\n",
    "    print(\"motionFrames:\", motionBatch.motionFrames.shape)\n",
    "    print(\"motionFlag:\", motionBatch.motionFlag.shape)\n",
    "    print(\"origMotionFramesCount:\", motionBatch.origMotionFramesCount.shape)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "execution_count": 56,
     "output_type": "error",
     "status": "error",
     "traceback": [
      "error: <Cell 56>:1:13: error: value of type 'LazyMapSequence<ArraySlice<Motion2LabelExample>, LabeledMotionBatch>.SubSequence' (aka 'LazyMapSequence<ArraySlice<Motion2LabelExample>, (data: MotionBatch, label: Tensor<Int32>)>') has no member 'data'\nbatches1[0].data\n~~~~~~~~~~~ ^~~~\n\n"
     ]
    }
   ],
   "source": [
    "batches1[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let batches2 = batches1.map { \n",
    "     LabeledMotionBatch(\n",
    "        data: $0.map(\\.data).paddedAndCollated(to: maxSequenceLength),\n",
    "        label: Tensor($0.map(\\.label))\n",
    "    )\n",
    "}\n",
    "batches2.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [4, 1000, 45]\n",
       "  ▿ dimensions : 3 elements\n",
       "    - 0 : 4\n",
       "    - 1 : 1000\n",
       "    - 2 : 45\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches2[0].data.motionFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [391, 45]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 391\n",
       "    - 1 : 45\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches2[1].data.motionFrames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
