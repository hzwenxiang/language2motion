{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (loss, grad) = valueWithGradient(at: model) {\n",
    "            (a: Tensor<Float>) -> Tensor<Float> in\n",
    "            print(2)\n",
    "            return softmaxCrossEntropy2(logits: $0.generate(input: batch).reshaped(to: [resultSize, -1]), labels: labels,ignoreIndex: padIndex)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "let hiddenSize: Int = 10\n",
    "struct IrisModel: Layer {\n",
    "    var layer1 = Dense<Float>(inputSize: 4, outputSize: hiddenSize, activation: relu)\n",
    "    var layer2 = Dense<Float>(inputSize: hiddenSize, outputSize: hiddenSize, activation: relu)\n",
    "    var layer3 = Dense<Float>(inputSize: hiddenSize, outputSize: 3)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: layer1, layer2, layer3)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = IrisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [2, 4]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 2\n",
       "    - 1 : 4\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let firstTrainFeatures = Tensor<Float>([[1, 2, 3, 4], [1, 2, 3, 4]])\n",
    "firstTrainFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.12627576,   0.1441789, 0.025626538],\n",
       " [-0.12627576,   0.1441789, 0.025626538]]\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(firstTrainFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "let firstTrainLabels = Tensor<Int32>([1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "Loss test: 1.1102539\n"
     ]
    }
   ],
   "source": [
    "let untrainedLogits = model(firstTrainFeatures)\n",
    "print(untrainedLogits.shape)\n",
    "let untrainedLoss = softmaxCrossEntropy(logits: untrainedLogits, labels: firstTrainLabels)\n",
    "print(\"Loss test: \\(untrainedLoss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 1.1102539\n"
     ]
    }
   ],
   "source": [
    "let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
    "    let logits = model(firstTrainFeatures)\n",
    "    return softmaxCrossEntropy(logits: logits, labels: firstTrainLabels)\n",
    "}\n",
    "print(\"Current loss: \\(loss)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
