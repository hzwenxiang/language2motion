{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotionDataset2label with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/notebooks/language2motion.gt/code\")\n",
      "\t\tMotionDataset\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmpbl_pgv2q/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "// %install '.package(path: \"/notebooks/language2motion.gt/code\")' Batcher ModelSupport Datasets MotionDataset ImageClassificationModels\n",
    "%install '.package(path: \"/notebooks/language2motion.gt/code\")' MotionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "import MotionDataset\n",
    "\n",
    "// import Batcher\n",
    "// import ModelSupport\n",
    "// import Datasets\n",
    "\n",
    "// import ImageClassificationModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var serializedDatasetURL: URL {\n",
    "    return URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/dataset.100.plist\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "func readBinaryMotionData() throws -> MotionData {\n",
    "    print(\"Reading..., decoding...\")\n",
    "    let date = Date() \n",
    "    let motionData = MotionData(from: serializedDatasetURL)\n",
    "    print(\"Done in \\(abs(date.timeIntervalSinceNow)) sec.\")\n",
    "    print(motionData.description)\n",
    "    return motionData\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading..., decoding...\n",
      "Done in 0.3867959976196289 sec.\n",
      "MotionData(motionSamples: 99)\n"
     ]
    }
   ],
   "source": [
    "let motionData = readBinaryMotionData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MotionSample(timestamp: 3.77, motions: 378, annotations: 1)\"\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let ms = motionData.motionSamples[0]\n",
    "ms.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import TensorFlow\n",
    "\n",
    "// Original Paper:\n",
    "// \"Deep Residual Learning for Image Recognition\"\n",
    "// Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "// https://arxiv.org/abs/1512.03385\n",
    "// This uses shortcut layers to connect residual blocks\n",
    "// (aka Option (B) in https://arxiv.org/abs/1812.01187).\n",
    "//\n",
    "// The structure of this implementation was inspired by the Flax ResNet example:\n",
    "// https://github.com/google/flax/blob/master/examples/imagenet/models.py\n",
    "\n",
    "public struct ConvBN: Layer {\n",
    "    public var conv: Conv2D<Float>\n",
    "    public var norm: BatchNorm<Float>\n",
    "\n",
    "    public init(\n",
    "        filterShape: (Int, Int, Int, Int),\n",
    "        strides: (Int, Int) = (1, 1),\n",
    "        padding: Padding = .valid\n",
    "    ) {\n",
    "        self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding, useBias: false)\n",
    "        self.norm = BatchNorm(featureCount: filterShape.3, momentum: 0.9, epsilon: 1e-5)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: conv, norm)\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualBlock: Layer {\n",
    "    public var projection: ConvBN\n",
    "    @noDerivative public let needsProjection: Bool\n",
    "    public var earlyConvs: [ConvBN] = []\n",
    "    public var lastConv: ConvBN\n",
    "\n",
    "    public init(\n",
    "        inputFilters: Int, filters: Int, strides: (Int, Int), useLaterStride: Bool, isBasic: Bool\n",
    "    ) {\n",
    "        let outFilters = filters * (isBasic ? 1 : 4)\n",
    "        self.needsProjection = (inputFilters != outFilters) || (strides.0 != 1)\n",
    "        // TODO: Replace the following, so as to not waste memory for non-projection cases.\n",
    "        if needsProjection {\n",
    "            projection = ConvBN(filterShape: (1, 1, inputFilters, outFilters), strides: strides)\n",
    "        } else {\n",
    "            projection = ConvBN(filterShape: (1, 1, 1, 1))\n",
    "        }\n",
    "\n",
    "        if isBasic {\n",
    "            earlyConvs = [\n",
    "                (ConvBN(\n",
    "                    filterShape: (3, 3, inputFilters, filters), strides: strides, padding: .same)),\n",
    "            ]\n",
    "            lastConv = ConvBN(filterShape: (3, 3, filters, outFilters), padding: .same)\n",
    "        } else {\n",
    "            if useLaterStride {\n",
    "                // Configure for ResNet V1.5 (the more common implementation).\n",
    "                earlyConvs.append(ConvBN(filterShape: (1, 1, inputFilters, filters)))\n",
    "                earlyConvs.append(\n",
    "                    ConvBN(filterShape: (3, 3, filters, filters), strides: strides, padding: .same))\n",
    "            } else {\n",
    "                // Configure for ResNet V1 (the paper implementation).\n",
    "                earlyConvs.append(\n",
    "                    ConvBN(filterShape: (1, 1, inputFilters, filters), strides: strides))\n",
    "                earlyConvs.append(ConvBN(filterShape: (3, 3, filters, filters), padding: .same))\n",
    "            }\n",
    "            lastConv = ConvBN(filterShape: (1, 1, filters, outFilters))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let residual: Tensor<Float>\n",
    "        // TODO: Find a way for this to be checked only at initialization, not during training or \n",
    "        // inference.\n",
    "        if needsProjection {\n",
    "            residual = projection(input)\n",
    "        } else {\n",
    "            residual = input\n",
    "        }\n",
    "\n",
    "        let earlyConvsReduced = earlyConvs.differentiableReduce(input) { last, layer in\n",
    "            relu(layer(last))\n",
    "        }\n",
    "        let lastConvResult = lastConv(earlyConvsReduced)\n",
    "\n",
    "        return relu(lastConvResult + residual)\n",
    "    }\n",
    "}\n",
    "\n",
    "/// An implementation of the ResNet v1 and v1.5 architectures, at various depths.\n",
    "public struct MyResNet: Layer {\n",
    "    public var initialLayer: ConvBN\n",
    "    public var maxPool: MaxPool2D<Float>\n",
    "    public var residualBlocks: [ResidualBlock] = []\n",
    "    public var avgPool = GlobalAvgPool2D<Float>()\n",
    "    public var flatten = Flatten<Float>()\n",
    "    public var classifier: Dense<Float>\n",
    "\n",
    "    /// Initializes a new ResNet v1 or v1.5 network model.\n",
    "    ///\n",
    "    /// - Parameters:\n",
    "    ///   - classCount: The number of classes the network will be or has been trained to identify.\n",
    "    ///   - depth: A specific depth for the network, chosen from the enumerated values in \n",
    "    ///     ResNet.Depth.\n",
    "    ///   - downsamplingInFirstStage: Whether or not to downsample by a total of 4X among the first\n",
    "    ///     two layers. For ImageNet-sized images, this should be true, but for smaller images like\n",
    "    ///     CIFAR-10, this probably should be false for best results.\n",
    "    ///   - inputFilters: The number of filters at the first convolution.\n",
    "    ///   - useLaterStride: If false, the stride within the residual block is placed at the position\n",
    "    ///     specified in He, et al., corresponding to ResNet v1. If true, the stride is moved to the\n",
    "    ///     3x3 convolution, corresponding to the v1.5 variant of the architecture. \n",
    "    public init(\n",
    "        classCount: Int, depth: Depth, downsamplingInFirstStage: Bool = true,\n",
    "        useLaterStride: Bool = true, channelCount: Int = 3\n",
    "    ) {\n",
    "        let inputFilters: Int\n",
    "        \n",
    "        if downsamplingInFirstStage {\n",
    "            inputFilters = 64\n",
    "            initialLayer = ConvBN(\n",
    "                filterShape: (7, 7, channelCount, inputFilters), strides: (2, 2), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2), padding: .same)\n",
    "        } else {\n",
    "            inputFilters = 16\n",
    "            initialLayer = ConvBN(filterShape: (3, 3, channelCount, inputFilters), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (1, 1), strides: (1, 1))  // no-op\n",
    "        }\n",
    "\n",
    "        var lastInputFilterCount = inputFilters\n",
    "        for (blockSizeIndex, blockSize) in depth.layerBlockSizes.enumerated() {\n",
    "            for blockIndex in 0..<blockSize {\n",
    "                let strides = ((blockSizeIndex > 0) && (blockIndex == 0)) ? (2, 2) : (1, 1)\n",
    "                let filters = inputFilters * Int(pow(2.0, Double(blockSizeIndex)))\n",
    "                let residualBlock = ResidualBlock(\n",
    "                    inputFilters: lastInputFilterCount, filters: filters, strides: strides,\n",
    "                    useLaterStride: useLaterStride, isBasic: depth.usesBasicBlocks)\n",
    "                lastInputFilterCount = filters * (depth.usesBasicBlocks ? 1 : 4)\n",
    "                residualBlocks.append(residualBlock)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        let finalFilters = inputFilters * Int(pow(2.0, Double(depth.layerBlockSizes.count - 1)))\n",
    "        classifier = Dense(\n",
    "            inputSize: depth.usesBasicBlocks ? finalFilters : finalFilters * 4,\n",
    "            outputSize: classCount)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let inputLayer = maxPool(relu(initialLayer(input)))\n",
    "        let blocksReduced = residualBlocks.differentiableReduce(inputLayer) { last, layer in\n",
    "            layer(last)\n",
    "        }\n",
    "        return blocksReduced.sequenced(through: avgPool, flatten, classifier)\n",
    "    }\n",
    "}\n",
    "\n",
    "extension MyResNet {\n",
    "    public enum Depth {\n",
    "        case resNet18\n",
    "        case resNet34\n",
    "        case resNet50\n",
    "        case resNet56\n",
    "        case resNet101\n",
    "        case resNet152\n",
    "\n",
    "        var usesBasicBlocks: Bool {\n",
    "            switch self {\n",
    "            case .resNet18, .resNet34, .resNet56: return true\n",
    "            default: return false\n",
    "            }\n",
    "        }\n",
    "\n",
    "        var layerBlockSizes: [Int] {\n",
    "            switch self {\n",
    "            case .resNet18: return [2, 2, 2, 2]\n",
    "            case .resNet34: return [3, 4, 6, 3]\n",
    "            case .resNet50: return [3, 4, 6, 3]\n",
    "            case .resNet56: return [9, 9, 9]\n",
    "            case .resNet101: return [3, 4, 23, 3]\n",
    "            case .resNet152: return [3, 8, 36, 3]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyResNet(classCount: 5, depth: .resNet18, downsamplingInFirstStage: false, channelCount: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// bs = 4\n",
    "// img size 200x44\n",
    "// channels = 1\n",
    "// class count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [4, 200, 44, 1]\n",
       "  ▿ dimensions : 4 elements\n",
       "    - 0 : 4\n",
       "    - 1 : 200\n",
       "    - 2 : 44\n",
       "    - 3 : 1\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let bs = 4\n",
    "let channelCount = 1\n",
    "let inpSize = (200, 44)\n",
    "let images = Tensor<Float>(shape: [bs, inpSize.0, inpSize.1, channelCount], scalars: (0..<bs*inpSize.0*inpSize.1*channelCount).map { Float($0) } )\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [4, 5]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 4\n",
       "    - 1 : 5\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let logits = model(images)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
