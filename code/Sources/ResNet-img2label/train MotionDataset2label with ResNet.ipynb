{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotionDataset2label with ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt/code\")' Batcher ModelSupport Datasets MotionDataset \n",
    "// ImageClassificationModels\n",
    "// %install '.package(path: \"/notebooks/language2motion.gt/code\")' MotionDataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "import MotionDataset\n",
    "\n",
    "import Batcher\n",
    "import ModelSupport\n",
    "import Datasets\n",
    "\n",
    "// import ImageClassificationModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let np  = Python.import(\"numpy\")\n",
    "let random  = Python.import(\"random\")\n",
    "let sklearn  = Python.import(\"sklearn\")\n",
    "let model_selection  = Python.import(\"sklearn.model_selection\")\n",
    "let subprocess = Python.import(\"subprocess\")\n",
    "let glob = Python.import(\"glob\")\n",
    "let pil = Python.import(\"PIL\")\n",
    "let Image = Python.import(\"PIL.Image\")\n",
    "let pd = Python.import(\"pandas\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "var serializedDatasetURL: URL {\n",
    "    return URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/dataset.100.plist\")\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "func readBinaryMotionData() throws -> MotionData {\n",
    "    print(\"Reading..., decoding...\")\n",
    "    let date = Date() \n",
    "    let motionData = MotionData(from: serializedDatasetURL)\n",
    "    print(\"Done in \\(abs(date.timeIntervalSinceNow)) sec.\")\n",
    "    print(motionData.description)\n",
    "    return motionData\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let motionData = readBinaryMotionData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create motion sample tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let ms = motionData.motionSamples[0]\n",
    "ms.description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ms.motionFrames.count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(type(of:ms.motionFramesArray))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ms.motionFramesArray[0..<100].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ms.motionFramesArray.makeNumpyArray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let t = Tensor(ms.motionFramesArray)\n",
    "t.shape //[0..<200, 0..<44].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Tensor where Scalar: Numeric {\n",
    "    func paddedOrCropped(to width: Int) -> Tensor<Scalar> {\n",
    "        // pads or crops two-dimensional tensor along 0-th axis\n",
    "        assert(self.shape.count == 2)\n",
    "        let currentWidth = self.shape[0]\n",
    "        let nPadding = Swift.max(width - currentWidth, 0)\n",
    "        let maxCropping = Swift.max(currentWidth - width, 0)\n",
    "        let nCropping = (maxCropping>0) ? Int.random(in: 0 ..< maxCropping) : 0\n",
    "        return self[nCropping..<nCropping+width].padded(forSizes: [(before: 0, after: nPadding), (before: 0, after: 0)])\n",
    "    }\n",
    "}\n",
    "// t.paddedOrCropped(to: 100).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-channel ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// import TensorFlow\n",
    "\n",
    "// Original Paper:\n",
    "// \"Deep Residual Learning for Image Recognition\"\n",
    "// Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "// https://arxiv.org/abs/1512.03385\n",
    "// This uses shortcut layers to connect residual blocks\n",
    "// (aka Option (B) in https://arxiv.org/abs/1812.01187).\n",
    "//\n",
    "// The structure of this implementation was inspired by the Flax ResNet example:\n",
    "// https://github.com/google/flax/blob/master/examples/imagenet/models.py\n",
    "\n",
    "public struct ConvBN: Layer {\n",
    "    public var conv: Conv2D<Float>\n",
    "    public var norm: BatchNorm<Float>\n",
    "\n",
    "    public init(\n",
    "        filterShape: (Int, Int, Int, Int),\n",
    "        strides: (Int, Int) = (1, 1),\n",
    "        padding: Padding = .valid\n",
    "    ) {\n",
    "        self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding, useBias: false)\n",
    "        self.norm = BatchNorm(featureCount: filterShape.3, momentum: 0.9, epsilon: 1e-5)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: conv, norm)\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualBlock: Layer {\n",
    "    public var projection: ConvBN\n",
    "    @noDerivative public let needsProjection: Bool\n",
    "    public var earlyConvs: [ConvBN] = []\n",
    "    public var lastConv: ConvBN\n",
    "\n",
    "    public init(\n",
    "        inputFilters: Int, filters: Int, strides: (Int, Int), useLaterStride: Bool, isBasic: Bool\n",
    "    ) {\n",
    "        let outFilters = filters * (isBasic ? 1 : 4)\n",
    "        self.needsProjection = (inputFilters != outFilters) || (strides.0 != 1)\n",
    "        // TODO: Replace the following, so as to not waste memory for non-projection cases.\n",
    "        if needsProjection {\n",
    "            projection = ConvBN(filterShape: (1, 1, inputFilters, outFilters), strides: strides)\n",
    "        } else {\n",
    "            projection = ConvBN(filterShape: (1, 1, 1, 1))\n",
    "        }\n",
    "\n",
    "        if isBasic {\n",
    "            earlyConvs = [\n",
    "                (ConvBN(\n",
    "                    filterShape: (3, 3, inputFilters, filters), strides: strides, padding: .same)),\n",
    "            ]\n",
    "            lastConv = ConvBN(filterShape: (3, 3, filters, outFilters), padding: .same)\n",
    "        } else {\n",
    "            if useLaterStride {\n",
    "                // Configure for ResNet V1.5 (the more common implementation).\n",
    "                earlyConvs.append(ConvBN(filterShape: (1, 1, inputFilters, filters)))\n",
    "                earlyConvs.append(\n",
    "                    ConvBN(filterShape: (3, 3, filters, filters), strides: strides, padding: .same))\n",
    "            } else {\n",
    "                // Configure for ResNet V1 (the paper implementation).\n",
    "                earlyConvs.append(\n",
    "                    ConvBN(filterShape: (1, 1, inputFilters, filters), strides: strides))\n",
    "                earlyConvs.append(ConvBN(filterShape: (3, 3, filters, filters), padding: .same))\n",
    "            }\n",
    "            lastConv = ConvBN(filterShape: (1, 1, filters, outFilters))\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let residual: Tensor<Float>\n",
    "        // TODO: Find a way for this to be checked only at initialization, not during training or \n",
    "        // inference.\n",
    "        if needsProjection {\n",
    "            residual = projection(input)\n",
    "        } else {\n",
    "            residual = input\n",
    "        }\n",
    "\n",
    "        let earlyConvsReduced = earlyConvs.differentiableReduce(input) { last, layer in\n",
    "            relu(layer(last))\n",
    "        }\n",
    "        let lastConvResult = lastConv(earlyConvsReduced)\n",
    "\n",
    "        return relu(lastConvResult + residual)\n",
    "    }\n",
    "}\n",
    "\n",
    "/// An implementation of the ResNet v1 and v1.5 architectures, at various depths.\n",
    "public struct MyResNet: Layer {\n",
    "    public var initialLayer: ConvBN\n",
    "    public var maxPool: MaxPool2D<Float>\n",
    "    public var residualBlocks: [ResidualBlock] = []\n",
    "    public var avgPool = GlobalAvgPool2D<Float>()\n",
    "    public var flatten = Flatten<Float>()\n",
    "    public var classifier: Dense<Float>\n",
    "\n",
    "    /// Initializes a new ResNet v1 or v1.5 network model.\n",
    "    ///\n",
    "    /// - Parameters:\n",
    "    ///   - classCount: The number of classes the network will be or has been trained to identify.\n",
    "    ///   - depth: A specific depth for the network, chosen from the enumerated values in \n",
    "    ///     ResNet.Depth.\n",
    "    ///   - downsamplingInFirstStage: Whether or not to downsample by a total of 4X among the first\n",
    "    ///     two layers. For ImageNet-sized images, this should be true, but for smaller images like\n",
    "    ///     CIFAR-10, this probably should be false for best results.\n",
    "    ///   - inputFilters: The number of filters at the first convolution.\n",
    "    ///   - useLaterStride: If false, the stride within the residual block is placed at the position\n",
    "    ///     specified in He, et al., corresponding to ResNet v1. If true, the stride is moved to the\n",
    "    ///     3x3 convolution, corresponding to the v1.5 variant of the architecture. \n",
    "    public init(\n",
    "        classCount: Int, depth: Depth, downsamplingInFirstStage: Bool = true,\n",
    "        useLaterStride: Bool = true, channelCount: Int = 3\n",
    "    ) {\n",
    "        let inputFilters: Int\n",
    "        \n",
    "        if downsamplingInFirstStage {\n",
    "            inputFilters = 64\n",
    "            initialLayer = ConvBN(\n",
    "                filterShape: (7, 7, channelCount, inputFilters), strides: (2, 2), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2), padding: .same)\n",
    "        } else {\n",
    "            inputFilters = 16\n",
    "            initialLayer = ConvBN(filterShape: (3, 3, channelCount, inputFilters), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (1, 1), strides: (1, 1))  // no-op\n",
    "        }\n",
    "\n",
    "        var lastInputFilterCount = inputFilters\n",
    "        for (blockSizeIndex, blockSize) in depth.layerBlockSizes.enumerated() {\n",
    "            for blockIndex in 0..<blockSize {\n",
    "                let strides = ((blockSizeIndex > 0) && (blockIndex == 0)) ? (2, 2) : (1, 1)\n",
    "                let filters = inputFilters * Int(pow(2.0, Double(blockSizeIndex)))\n",
    "                let residualBlock = ResidualBlock(\n",
    "                    inputFilters: lastInputFilterCount, filters: filters, strides: strides,\n",
    "                    useLaterStride: useLaterStride, isBasic: depth.usesBasicBlocks)\n",
    "                lastInputFilterCount = filters * (depth.usesBasicBlocks ? 1 : 4)\n",
    "                residualBlocks.append(residualBlock)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        let finalFilters = inputFilters * Int(pow(2.0, Double(depth.layerBlockSizes.count - 1)))\n",
    "        classifier = Dense(\n",
    "            inputSize: depth.usesBasicBlocks ? finalFilters : finalFilters * 4,\n",
    "            outputSize: classCount)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let inputLayer = maxPool(relu(initialLayer(input)))\n",
    "        let blocksReduced = residualBlocks.differentiableReduce(inputLayer) { last, layer in\n",
    "            layer(last)\n",
    "        }\n",
    "        return blocksReduced.sequenced(through: avgPool, flatten, classifier)\n",
    "    }\n",
    "}\n",
    "\n",
    "extension MyResNet {\n",
    "    public enum Depth {\n",
    "        case resNet18\n",
    "        case resNet34\n",
    "        case resNet50\n",
    "        case resNet56\n",
    "        case resNet101\n",
    "        case resNet152\n",
    "\n",
    "        var usesBasicBlocks: Bool {\n",
    "            switch self {\n",
    "            case .resNet18, .resNet34, .resNet56: return true\n",
    "            default: return false\n",
    "            }\n",
    "        }\n",
    "\n",
    "        var layerBlockSizes: [Int] {\n",
    "            switch self {\n",
    "            case .resNet18: return [2, 2, 2, 2]\n",
    "            case .resNet34: return [3, 4, 6, 3]\n",
    "            case .resNet50: return [3, 4, 6, 3]\n",
    "            case .resNet56: return [9, 9, 9]\n",
    "            case .resNet101: return [3, 4, 23, 3]\n",
    "            case .resNet152: return [3, 8, 36, 3]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyResNet(classCount: 5, depth: .resNet18, downsamplingInFirstStage: false, channelCount: 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "// bs = 4\n",
    "// img size 200x44\n",
    "// channels = 1\n",
    "// class count = 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let bs = 4\n",
    "let channelCount = 1\n",
    "let inpSize = (200, 44)\n",
    "let images = Tensor<Float>(shape: [bs, inpSize.0, inpSize.1, channelCount], scalars: (0..<bs*inpSize.0*inpSize.1*channelCount).map { Float($0) } )\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let logits = model(images)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let optimizer = SGD(for: model, learningRate: 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let pd = Python.import(\"pandas\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let labelsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/labels_ds_v2.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let df = pd.read_csv(labelsURL.path)\n",
    "let labels = df.label.unique().sorted().map {String($0)!}\n",
    "labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "var labelsDict: [Int: String] = [:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for pythonTuple in df.iterrows() {\n",
    "    labelsDict[Int(pythonTuple[1].sample_id)!] = String(pythonTuple[1].label)!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put dataset together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func getTensorLabel(_ ms: MotionSample, labelsDict: [Int: String], labels: [String], tensorWidth: Int) -> (Tensor<Float>, Int32) {\n",
    "    // TODO: code _unknown_ label\n",
    "//     print(\"a\")\n",
    "    var labelStr = labelsDict[ms.sampleID]\n",
    "    \n",
    "    if labelStr == nil {\n",
    "        labelStr = \"Doing something\"\n",
    "    }\n",
    "    \n",
    "    let label: Int32 = Int32(labels.index(of: labelStr!)!)\n",
    "  \n",
    "    var tensor = Tensor<Float>(ms.motionFramesArray)\n",
    "//     print(tensor.shape)\n",
    "    tensor = tensor.paddedOrCropped(to: tensorWidth).expandingShape(at: 2)\n",
    "//     print(tensor.shape)\n",
    "    return (tensor, label)\n",
    "}\n",
    "\n",
    "// let (tensor, label) = getTensorLabel(ms, labelsDict: labelsDict, labels: labels, tensorWidth: 100)\n",
    "// (tensor.shape, label)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.4000.plist\")\n",
    "let labelsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/labels_ds_v2.csv\")\n",
    "\n",
    "let motionData2 = MotionData(from: serializedDatasetURL)\n",
    "print(motionData2.description)\n",
    "\n",
    "let df = pd.read_csv(labelsURL.path)\n",
    "let labels2 = df.label.unique().sorted().map {String($0)!}\n",
    "\n",
    "var labelsDict: [Int: String] = [:]\n",
    "for pythonTuple in df.iterrows() {\n",
    "    labelsDict[Int(pythonTuple[1].sample_id)!] = String(pythonTuple[1].label)!\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let tensorPairs: [(Tensor<Float>, Int32)] = motionData2.motionSamples.map { getTensorLabel($0, labelsDict: labelsDict, labels: labels2, tensorWidth: 224) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split of collection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let a = [1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension Array { \n",
    "    func trainTestSplit(split: Float) -> (train: Array<Element>, test: Array<Element>) {\n",
    "        let shuffled = self.shuffled()\n",
    "        let splitIdx = Int(roundf(Float(split * Float(self.count))))\n",
    "        let train = Array(shuffled[0..<splitIdx])\n",
    "        let test = Array(shuffled[splitIdx..<self.count])\n",
    "        return (train: train, test: test)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a.trainTestSplit(split: 0.7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "func loadImages(imageList: [String], labels: [String], normalizing: Bool = true) -> [TensorPair<Float, Int32>] {\n",
    "    let tensorLabels = imageList.map {\n",
    "        getTensorLabel(URL(fileURLWithPath: $0), labels: labels)\n",
    "    }\n",
    "    \n",
    "    let imageCount = tensorLabels.count\n",
    "    let labelTensor = Tensor<Int64>(shape: [imageCount], scalars: tensorLabels.map {Int64($0.1)})\n",
    "\n",
    "    var imageTensor = Tensor<Float>(stacking: tensorLabels.map {$0.0}, alongAxis: 0)\n",
    "\n",
    "    // The value of mean and std were calculated with the following Swift code:\n",
    "    // ```\n",
    "    // import TensorFlow\n",
    "    // import Datasets\n",
    "    // import Foundation\n",
    "\n",
    "    // let dsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/img2label_ds_v1\", isDirectory: true)\n",
    "    // let dataset = Img2Label(batchSize: 2500, dsURL: dsURL, normalizing: false)\n",
    "    // print(\"dataset.training.count: \\(dataset.training.count)\")\n",
    "    // for batch in dataset.training.sequenced() {\n",
    "    //     let images = Tensor<Double>(batch.first) / 255.0\n",
    "    //     let mom = images.moments(squeezingAxes: [0,1,2])\n",
    "    //     print(\"mean: \\(mom.mean) std: \\(sqrt(mom.variance))\")\n",
    "    // }\n",
    "    // ```\n",
    "    if normalizing {\n",
    "        let mean = Tensor<Float>(\n",
    "                [0.8836673330105219,\n",
    "                 0.8571306618582774,\n",
    "                 0.5989467475049005])\n",
    "        let std = Tensor<Float>(\n",
    "                [0.1870305997172803,\n",
    "                 0.1698038429051249,\n",
    "                 0.11811759458558127])\n",
    "        imageTensor = ((imageTensor / 255.0) - mean) / std\n",
    "    }\n",
    "    \n",
    "    return (0..<imageCount).map { TensorPair(first: imageTensor[$0], second: Tensor<Int32>(labelTensor[$0])) }\n",
    "        \n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "motionData.motionSamples.count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let tensorPairs = motionData.motionSamples[0..<99].map { getTensorLabel($0, labelsDict: labelsDict, labels: labels, tensorWidth: 224) }\n",
    "tensorPairs.count"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let (trainTensorPairs, testTensorPairs) = tensorPairs.trainTestSplit(split: 0.8)\n",
    "(trainTensorPairs.count, testTensorPairs.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct Motion2Label {\n",
    "    public typealias SourceDataSet = [TensorPair<Float, Int32>]\n",
    "//     public typealias SourceDataSet = [(Tensor<Float>, Int32)]\n",
    "    public let training: Batcher<SourceDataSet>\n",
    "    public let test: Batcher<SourceDataSet>\n",
    "    public let labels: [String]\n",
    "    public let motionData: MotionData\n",
    "\n",
    "    func readBinaryMotionData(_ serializedDatasetURL: URL) throws -> MotionData {\n",
    "        print(\"Reading..., decoding...\")\n",
    "        let date = Date() \n",
    "        let motionData2 = MotionData(from: serializedDatasetURL)\n",
    "        print(\"Done in \\(abs(date.timeIntervalSinceNow)) sec.\")\n",
    "        print(motionData2.description)\n",
    "        return motionData2\n",
    "    }\n",
    "    \n",
    "    public init(batchSize: Int, serializedDatasetURL: URL, labelsURL: URL) {\n",
    "//         let motionData2 = try! readBinaryMotionData(serializedDatasetURL)\n",
    "        let motionData2 = MotionData(from: serializedDatasetURL)\n",
    "        print(motionData2.description)\n",
    "        \n",
    "        print(1)\n",
    "        let df = pd.read_csv(labelsURL.path)\n",
    "        let labels2 = df.label.unique().sorted().map {String($0)!}\n",
    "        print(2)\n",
    "\n",
    "        var labelsDict: [Int: String] = [:]\n",
    "        for pythonTuple in df.iterrows() {\n",
    "            labelsDict[Int(pythonTuple[1].sample_id)!] = String(pythonTuple[1].label)!\n",
    "        }\n",
    "        print(3)\n",
    "        \n",
    "        let tensorPairs: [(Tensor<Float>, Int32)] = motionData2.motionSamples.map { \n",
    "            getTensorLabel($0, labelsDict: labelsDict, labels: labels2, tensorWidth: 224) \n",
    "        }\n",
    "        print(4, \"tensorPairs: \\(tensorPairs.count)\")\n",
    "        let tensorPairs2: SourceDataSet = tensorPairs.map { TensorPair(first: $0.0, second: Tensor<Int32>($0.1)) }\n",
    "        print(5)\n",
    "        let (trainTensorPairs, testTensorPairs) = tensorPairs2.trainTestSplit(split: 0.8)\n",
    "        print(6)\n",
    "        \n",
    "        print(\"trainTensorPairs.count = \\(trainTensorPairs.count)\")\n",
    "        print(\"testTensorPairs.count = \\(testTensorPairs.count)\")\n",
    "        self.training = Batcher(\n",
    "            on: trainTensorPairs,\n",
    "            batchSize: batchSize,\n",
    "            numWorkers: 1, //No need to use parallelism since everything is loaded in memory\n",
    "            shuffle: true)\n",
    "        self.test = Batcher(\n",
    "            on: testTensorPairs,\n",
    "            batchSize: batchSize,\n",
    "            numWorkers: 1,\n",
    "            shuffle: false)\n",
    "        self.labels = labels2\n",
    "        self.motionData = motionData2\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let batchSize = 100\n",
    "\n",
    "let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.4000.plist\")\n",
    "let labelsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/labels_ds_v2.csv\")\n",
    "\n",
    "let dataset = Motion2Label(\n",
    "    batchSize: batchSize, \n",
    "    serializedDatasetURL: serializedDatasetURL,\n",
    "    labelsURL: labelsURL\n",
    ")\n",
    "print(\"dataset.training.count: \\(dataset.training.count)\")\n",
    "print(\"dataset.test.count: \\(dataset.test.count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting motion2label training...\")\n",
    "\n",
    "for epoch in 1...10 {\n",
    "    print(\"epoch \\(epoch)\")\n",
    "    Context.local.learningPhase = .training\n",
    "    var trainingLossSum: Float = 0\n",
    "    var trainingBatchCount = 0\n",
    "    for batch in dataset.training.sequenced() {\n",
    "        print(\"progress \\(100.0*Float(trainingBatchCount)/Float(dataset.training.count))%\")\n",
    "        let (tensors, labels) = (batch.first, batch.second)\n",
    "        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
    "            let logits = model(tensors)\n",
    "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "        }\n",
    "        trainingLossSum += loss.scalarized()\n",
    "        trainingBatchCount += 1\n",
    "        optimizer.update(&model, along: gradients)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    var testLossSum: Float = 0\n",
    "    var testBatchCount = 0\n",
    "    var correctGuessCount = 0\n",
    "    var totalGuessCount = 0\n",
    "    for batch in dataset.test.sequenced() {\n",
    "        print(\"batch\")\n",
    "        let (tensors, labels) = (batch.first, batch.second)\n",
    "        let logits = model(tensors)\n",
    "        testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()\n",
    "        testBatchCount += 1\n",
    "\n",
    "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
    "        correctGuessCount = correctGuessCount\n",
    "            + Int(\n",
    "                Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        totalGuessCount = totalGuessCount + batchSize\n",
    "    }\n",
    "\n",
    "    let accuracy = Float(correctGuessCount) / Float(totalGuessCount)\n",
    "    print(\n",
    "        \"\"\"\n",
    "        [Epoch \\(epoch)] \\\n",
    "        Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(accuracy*100)%) \\\n",
    "        Loss: \\(testLossSum / Float(testBatchCount))\n",
    "        \"\"\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
