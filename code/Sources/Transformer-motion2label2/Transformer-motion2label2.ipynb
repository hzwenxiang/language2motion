{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer-motion2label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/notebooks/language2motion.gt/code\")\n",
      "\t\tDatasets\n",
      "\t\tMotionModels\n",
      "\t\tImageClassificationModels\n",
      "\t\tTextModels\n",
      "\t\tModelSupport\n",
      "\t\tSummaryWriter\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmp4jlxtkrp/swift-install\n",
      "[1/2] Compiling Datasets ArrayUtils.swift\n",
      "[2/3] Compiling TextModels Attention.swift\n",
      "[3/4] Compiling MotionModels MotionClassifier.swift\n",
      "[4/5] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[5/5] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location /notebooks/language2motion.gt/swift-install\n",
    "%install-swiftpm-flags -c release\n",
    "%install '.package(path: \"/notebooks/language2motion.gt/code\")' Datasets MotionModels ImageClassificationModels TextModels ModelSupport SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "import Datasets\n",
    "import MotionModels\n",
    "import ImageClassificationModels\n",
    "import TextModels\n",
    "import ModelSupport\n",
    "import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PythonKit\n",
    "\n",
    "let metrics = Python.import(\"sklearn.metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSize: 10\n",
      "maxSequenceLength: 300\n",
      "runName: run_9\n",
      "\n",
      "Loading dataset...\n",
      "MotionData(motionSamples: 3911)\n",
      "dataset.trainingExamples.count: 2410\n",
      "dataset.validationExamples.count: 602\n"
     ]
    }
   ],
   "source": [
    "let batchSize = 10\n",
    "let maxSequenceLength =  300 //600\n",
    "let runName = \"run_9\"\n",
    "\n",
    "print(\"batchSize: \\(batchSize)\")\n",
    "print(\"maxSequenceLength: \\(maxSequenceLength)\")\n",
    "print(\"runName: \\(runName)\")\n",
    "\n",
    "// let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset_v2.normalized.plist\")\n",
    "// let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.motion_flag.normalized.sampled.500.plist\")\n",
    "let serializedDatasetURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/motion_dataset.motion_flag.normalized.plist\")\n",
    "let labelsURL = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/labels_ds_v2.csv\")\n",
    "\n",
    "print(\"\\nLoading dataset...\")\n",
    "let dataset = try! Motion2Label2(\n",
    "    serializedDatasetURL: serializedDatasetURL,\n",
    "    labelsURL: labelsURL,\n",
    "    maxSequenceLength: maxSequenceLength,\n",
    "    batchSize: batchSize\n",
    ") { \n",
    "    // TODO: move this to dataset class\n",
    "    (example: Motion2LabelExample) -> LabeledMotionBatch in\n",
    "    let motionFrames = Tensor<Float>(example.motionSample.motionFramesArray)\n",
    "    let motionFlag = Tensor<Int32>(motionFrames[0..., 44...44].squeezingShape(at: 1))\n",
    "    let origMotionFramesCount = Tensor<Int32>(Int32(motionFrames.shape[0]))\n",
    "    let motionBatch = MotionBatch(motionFrames: motionFrames, motionFlag: motionFlag, origMotionFramesCount: origMotionFramesCount)\n",
    "    let label = Tensor<Int32>(Int32(example.label!.idx))\n",
    "    return LabeledMotionBatch(data: motionBatch, label: label)\n",
    "}\n",
    "\n",
    "print(\"dataset.trainingExamples.count: \\(dataset.trainingExamples.count)\")\n",
    "print(\"dataset.validationExamples.count: \\(dataset.validationExamples.count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate ResNet\n",
    "var hiddenLayerCount: Int = 6 //12\n",
    "var attentionHeadCount: Int = 6 //12\n",
    "var hiddenSize = 64*attentionHeadCount // 64*12 = 768 // 32*6=192 // 64*6=384\n",
    "let classCount = 5\n",
    "var featureExtractor = ResNet(classCount: hiddenSize, depth: .resNet18, downsamplingInFirstStage: false, channelCount: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate FeatureTransformerEncoder\n",
    "var caseSensitive: Bool = false\n",
    "var subDirectory: String = \"uncased_L-12_H-768_A-12\"\n",
    "let directory = URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/\")\n",
    "let vocabularyURL = directory\n",
    "    .appendingPathComponent(subDirectory)\n",
    "    .appendingPathComponent(\"vocab.txt\")\n",
    "\n",
    "let vocabulary: Vocabulary = try! Vocabulary(fromFile: vocabularyURL)\n",
    "let tokenizer: Tokenizer = BERTTokenizer(vocabulary: vocabulary,\n",
    "    caseSensitive: caseSensitive, unknownToken: \"[UNK]\", maxTokenLength: nil)\n",
    "\n",
    "var variant: BERT.Variant = .bert          \n",
    "var intermediateSize: Int = hiddenSize*4 // 3072/768=4\n",
    "\n",
    "var transformerEncoder = FeatureTransformerEncoder(\n",
    "    variant: variant,\n",
    "    vocabulary: vocabulary,\n",
    "    tokenizer: tokenizer,\n",
    "    caseSensitive: caseSensitive,\n",
    "    hiddenSize: hiddenSize,\n",
    "    hiddenLayerCount: hiddenLayerCount,\n",
    "    attentionHeadCount: attentionHeadCount,\n",
    "    intermediateSize: intermediateSize,\n",
    "    intermediateActivation: gelu,\n",
    "    hiddenDropoutProbability: 0.1,\n",
    "    attentionDropoutProbability: 0.1,\n",
    "    maxSequenceLength: 512,\n",
    "    typeVocabularySize: 2,\n",
    "    initializerStandardDeviation: 0.02,\n",
    "    useOneHotEmbeddings: false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// instantiate MotionClassifier\n",
    "var motionClassifier = MotionClassifier(featureExtractor: featureExtractor, transformerEncoder: transformerEncoder, classCount: classCount, maxSequenceLength: maxSequenceLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let optimizer = SGD(for: motionClassifier, learningRate: 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let summaryWriter = SummaryWriter(logdir: URL(fileURLWithPath: \"/notebooks/language2motion.gt/data/tboard/\").appendingPathComponent(runName), flushMillis: 30*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining MotionClassifier for the motion2Label task!\")\n",
    "var trainingStepCount = 0\n",
    "time() {\n",
    "    for (epoch, epochBatches) in dataset.trainingEpochs.prefix(5).enumerated() {\n",
    "        print(\"[Epoch \\(epoch + 1)]\")\n",
    "        Context.local.learningPhase = .training\n",
    "        var trainingLossSum: Float = 0\n",
    "        var trainingBatchCount = 0\n",
    "        if epoch == 0 {\n",
    "            print(\"epochBatches.count: \\(epochBatches.count)\")\n",
    "        }\n",
    "\n",
    "        for batch in epochBatches {\n",
    "            let (documents, labels) = (batch.data, Tensor<Int32>(batch.label))\n",
    "            // let (eagerDocuments, eagerLabels) = (batch.data, Tensor<Int32>(batch.label))\n",
    "            // let documents = eagerDocuments.copyingTensorsToDevice(to: device)\n",
    "            // let labels = Tensor(copying: eagerLabels, to: device)\n",
    "            let (loss, gradients) = valueWithGradient(at: motionClassifier) { model -> Tensor<Float> in\n",
    "                let logits = model(documents)\n",
    "                return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "            }\n",
    "\n",
    "            trainingLossSum += loss.scalarized()\n",
    "            trainingBatchCount += 1\n",
    "            trainingStepCount += 1\n",
    "            optimizer.update(&motionClassifier, along: gradients)\n",
    "            // LazyTensorBarrier()\n",
    "            summaryWriter.writeScalarSummary(tag: \"TrainingLoss\", step: trainingStepCount, value: trainingLossSum / Float(trainingBatchCount))\n",
    "        }\n",
    "        print(\n",
    "            \"\"\"\n",
    "            Training loss: \\(trainingLossSum / Float(trainingBatchCount))\n",
    "            \"\"\"\n",
    "        )\n",
    "        summaryWriter.writeScalarSummary(tag: \"EpochTrainingLoss\", step: epoch, value: trainingLossSum / Float(trainingBatchCount))\n",
    "\n",
    "        if epoch == 0 {\n",
    "            print(\"dataset.validationBatches.count: \\(dataset.validationBatches.count)\")\n",
    "        }\n",
    "        Context.local.learningPhase = .inference\n",
    "        var devLossSum: Float = 0\n",
    "        var devBatchCount = 0\n",
    "        var correctGuessCount = 0\n",
    "        var totalGuessCount = 0\n",
    "\n",
    "        for batch in dataset.validationBatches {\n",
    "            let valBatchSize = batch.data.motionFrames.shape[0]\n",
    "\n",
    "            let (documents, labels) = (batch.data, Tensor<Int32>(batch.label))\n",
    "            // let (eagerDocuments, eagerLabels) = (batch.data, Tensor<Int32>(batch.label))\n",
    "            // let documents = eagerDocuments.copyingTensorsToDevice(to: device)\n",
    "            // let labels = Tensor(copying: eagerLabels, to: device)\n",
    "\n",
    "            let logits = motionClassifier(documents)\n",
    "            let loss = softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "            // LazyTensorBarrier()\n",
    "            devLossSum += loss.scalarized()\n",
    "            devBatchCount += 1\n",
    "\n",
    "            let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
    "\n",
    "            correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            totalGuessCount += valBatchSize\n",
    "        }\n",
    "        \n",
    "        let testAccuracy = Float(correctGuessCount) / Float(totalGuessCount)\n",
    "        print(\n",
    "            \"\"\"\n",
    "            Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(testAccuracy)) \\\n",
    "            Eval loss: \\(devLossSum / Float(devBatchCount))\n",
    "            \"\"\"\n",
    "        )\n",
    "        summaryWriter.writeScalarSummary(tag: \"EpochTestLoss\", step: epoch, value: devLossSum / Float(devBatchCount))\n",
    "        summaryWriter.writeScalarSummary(tag: \"EpochTestAccuracy\", step: epoch, value: testAccuracy)\n",
    "\n",
    "        let preds = motionClassifier.predict(motionSamples: dataset.testMotionSamples, labels: dataset.labels, batchSize: batchSize)\n",
    "        let y_true = dataset.testMotionSamples.map { dataset.getLabel($0.sampleID)!.label }\n",
    "        let y_pred = preds.map { $0.className }\n",
    "        print(metrics.confusion_matrix(y_pred, y_true, labels: dataset.labels))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let preds = motionClassifier.predict(motionSamples: dataset.testMotionSamples, labels: dataset.labels, batchSize: batchSize)\n",
    "let y_true = dataset.testMotionSamples.map { dataset.getLabel($0.sampleID)!.label }\n",
    "let y_pred = preds.map { $0.className }\n",
    "print(metrics.confusion_matrix(y_pred, y_true, labels: dataset.labels))\n",
    "print(metrics.classification_report(y_true, y_pred, labels: dataset.labels, zero_division: false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
